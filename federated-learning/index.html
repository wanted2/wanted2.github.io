<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<link rel="icon" href="https://wanted2.github.io/assets/images/favicon.ico">

<title>Best practices for Federated Machine Learning (FedML) with Amazon Web Services (AWS) | AiFi</title>

 
    


<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Best practices for Federated Machine Learning (FedML) with Amazon Web Services (AWS) | AiFi</title>
<meta name="generator" content="Jekyll v4.2.1" />
<meta property="og:title" content="Best practices for Federated Machine Learning (FedML) with Amazon Web Services (AWS)" />
<meta name="author" content="tuan" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Federated learning (FL) is a machine learning (ML) scenario with two distinct characteristics. First, training occurs on multiple machines. Second, each machine involved in training keeps training data locally; the only information shared between machines is the ML model and its parameters. FL solves challenges related to data privacy and scalability in scenarios such as mobile devices and IoT. By Amazon Web Service (AWS) Theo định nghĩa của AWS, thì Federated Machine Learning (FedML) là một hình thức (scenario) máy học có 2 đặc trưng nổi bật là: 1. quá trình học diễn ra trên nhiều máy.; 2. mỗi máy thực hiện học (training) sẽ giữ kín dữ liệu training ở local; dữ liệu duy nhất mà các máy chia sẻ với nhau chỉ là mô hình (model) máy học và các thông số model (parameters). Các bạn có thể thấy nếu chỉ có 1. thì FedML chỉ đơn giản là distributed learning (học phân tán) ra nhiều máy thiết bị, cái đặc trưng không kém phần quan trọng của FedML là 2. giấu kín dữ liệu của từng máy, tức là không có chuyện chia sẻ dữ liệu người dùng, và vì vậy nên tính bảo mật và tuân thủ privacy cao hơn. Ngoài ra vì chỉ chia sẻ một “ít” dữ liệu là thông số mô hình nên độ ngốn băng thông là thấp, dẫn đến FedML là 1 hình thức học đang trở nên dần nhận được nhiều sự quan tâm. Tuy nhiên, học đi đôi với hành, nên chúng ta cũng sẽ lấy ví dụ về FedML trong thực tế qua một ví dụ triển khai trên AWS SageMaker. Giới thiệu về FedML Machine Learning truyền thống vs. FedML ML truyền thống (hay là Machine Learning cơ bản) thì chủ yếu dựa vào nguồn dữ liệu, kiến trúc mô hình và thuật toán máy học cơ bản (xem hình dưới). Định nghĩa lý thuyết của ML tôi xin phép không bàn tới, mà điểm focus của bài viết là từ góc nhìn kỹ thuật, kiến trúc vận hành thực tế của ML. Machine Learning cơ bản Các bạn có thể thấy ngay, với kiến trúc ML cơ bản như trên, dữ liệu học (training data) sẽ được gửi về 1 địa điểm tập trung để thực hiện quá trình học. Và đây chính là vấn đề: việc gửi dữ liệu qua đường truyền mạng sẽ có khá nhiều vấn đề về tuân thủ dữ liệu người dùng cũng như bảo mật. Ngoài ra, cái gọi là địa điểm tập trung ấy cũng có vấn đề: nếu địa điểm đó nằm ngoài phạm vi đất nước, tức là dữ liệu người dùng 1 quốc gia, ví dụ như Việt Nam, sẽ bị gửi sang 1 server ở Trung Quốc? Các bạn thấy đấy, ML cơ bản có khá nhiều giới hạn và vấn đề, đòi hỏi researcher lẫn kỹ sư máy học phải có sự cân nhắc kỹ càng khi thiết kế triển khai vận hành 1 hệ thống ML cơ bản. Ngoài ra, nhu cầu về bảo mật dữ liệu cấp công nghiệp ngày càng cao, dẫn đến các hệ thống ML cơ bản chỉ dừng ở mức độ lý thuyết chứ khó triển khai vào sản phẩm thực tế. Khi triển khai vận hành vào sản phẩm thực tế, chúng ta cần 1 mô hình kiến trúc học tối tân hơn, và đó chính là lúc chúng ta cần FedML. FedML [6, 6, 6, 6, 6, 6] giải quyết một phát cả 2 vấn đề trên, thậm chí còn cải thiện cả băng thông (vì không phải chia sẻ data nữa). Dưới đây là biểu đồ luồng thông tin của 1 hệ thống FedML (cũng cơ bản thôi). FedML Luồng FedML ở trên đây có 2 nhóm thiết bị chính: devices (thiết bị) và coordinators (người điều phối). Devices có thể là các thiết bị IoT, smartphones, sensors, PCs, .v.v… Người điều phối (co-ordinator) là nhóm những servers thực hiện aggregate thông số mô hình và phát tán cho các thiết bị. Chú ý: Người điều phối không cần truy cập hay tiếp xúc với dữ liệu, việc duy nhất của người điều phối là phát tán mô hình (bao gồm cả thông số), nhận mô hình được train ở các thiết bị local và aggregate. Người điều phối cũng không train gì cả, mà đó là việc của thiết bị (devices). Thiết bị cũng thu thập dữ liệu luôn, và người điều phối cũng không cần quan tâm tới dữ liệu ở local của thiết bị. Luồng xử lý của FedML cơ bản bao gồm: Người điều phối gửi dữ liệu mô hình đến các thiết bị để khởi tạo mô hình trên từng thiết bị. Về cơ bản, ở bước này, mô hình ở mọi thiết bị sẽ là đồng bộ. Khi các thiết bị đã “sẵn sàng”, người điều phối gửi tín hiệu bắt đầu train. Sau hiệu lệnh này, các thiết bị bắt đầu chuyển sang trạng thái training, tức là bắt đầu thu thập dữ liệu và cập nhật thông số mô hình. Việc train được các thiết bị thực hiện với dữ liệu được thu thập ở local và không chia sẻ đi đâu cả. Bộ dữ liệu local có thể có sẵn (và được cung cấp bởi bên thứ 3), hoặc có thể được thu thập online (ví dụ như camera giao thông). Khi việc học (train) kết thúc, các thiết bị tổng hợp dữ liệu mô hình (thông số và trọng số weights) để gửi về cho người điều phối. Ở đây có vấn đề là độ trễ giữa các thiết bị, nên người điều phối có thể xem xét để thực hiện bước tiếp theo khi chờ đủ khoảng bao nhiều % mô hình chứ không nhất thiết chờ tới 100%. Người điều phối thực hiện thuật toán aggregate các thông tin mô hình được gửi về từ các thiết bị local. Thuật toán đơn giản nhất là FedAvg tức là đơn thuần là lấy trung bình mọi thông số làm thông số mới. Quay lại 1. tức là lại phát tán lại thông số mô hình cho các thiết bị. Vai trò của người điều phối tưởng đơn giản nhưng lại khá quan trọng. Thường thì sẽ phải kết hợp với weight monitoring tức là giám sát trọng số, phát hiện trọng số bất thường, … Ưu nhược điểm của FedML Ưu điểm Nâng cao tính bảo mật, bảo vệ dữ liệu người dùng tốt hơn. Cải thiện băng thông dữ liệu. Nhược điểm Tính bất định trong tập thiết bị: số lượng thiết bị lên tới hàng triệu, chục triệu và bất cứ lúc nào cũng có thiết bị thêm vào hoặc bỏ ra. Nói nôm na là người ra người vào liên tục. Liên lạc bất đồng bộ: các thiết bị giao tiếp với người điều phối thông qua giao thức bất đồng bộ (dựa trên pub/sub messaging) như MQTT1. Ví dụ như khi người điều phối muốn yêu cầu các thiết bị nộp thông số mô hình, thì call đó có thể không đồng bộ và xuất hiện độ trễ. Như đã nói ở trên, nếu chờ hết 100% thiết bị nộp bài sẽ rất lâu, người điều phối có thể phải set timeout. Băng thông mô hình: mặc dù việc không phải truyền tải dữ liệu là đã tiết kiệm rất lớn băng thông, dữ liệu mô hình vẫn có thể từ vài MB tới vài trăm MB/lần. Frameworks: cái này cũng là vấn đề vì những framework máy học truyền thống như PyTorch2 hay Tensorflow3 vẫn chưa chịu hỗ trợ FedML tối đa. Phần lớn các framework này vẫn đang dừng ở mức hỗ trợ EdgeML hơn là FedML. Mọi kiến trúc máy học đều có ưu nhược điểm riêng, kể cả ML cơ bản lẫn FedML. FedML giải quyết các vấn đề của ML cơ bản, và chúng ta lại tiếp tục giải quyết các vấn đề của FedML. Vấn đề người ra người vào liên tục thì có chuyện gì ở đây là cấu hình của tập thiết bị sẽ thay đổi, chúng ta không thể kỳ vọng thiết bị mới vào sẽ lại có cấu hình và năng lực tương tự như các thiết bị đang có và đã bỏ ra. Và vấn đề là không chỉ năng lực không đồng bộ mà còn là những thiết bị mới tuyển vào có thể “lái” việc huấn luyện mô hình đi theo hướng mà chúng mong muốn. Tức là những thiết bị “xấu”: vào chỉ để ảnh hưởng xấu đến mô hình, hoặc vào một tí lại bỏ việc chả đóng góp gì cho việc học của mô hình, hoặc vào chỉ để nghe ngóng chứ không phải để đóng góp vào việc tính toán huấn luyện mô hình. Vấn đề liên lạc bất đồng bộ thì chủ yếu là giao tiếp giữa thiết bị và người điều phối: thiết bị do không đồng bộ nên có thể bắt người điều phối chờ. Thì nói chung 2 cái vấn đề này tôi nghĩ cũng là những vấn đề “muôn thuở” của FedML. Bây giờ cũng có nhiều hướng giải quyết. Vấn đề băng thông mô hình thì chủ yếu là tối ưu size của mô hình thì giờ cũng nhiều hướng giải quyết mở ra như Distillation, Prunning, Binary Neural Nets, Quantization, … Vấn đề frameworks thì cũng dần dần có những phát triển mới như PySyft4 hay Flower5. Flower là một frameworks hoàn thiện cho FedML với hỗ trợ dành cho cả PyTorch và Tensorflow. Khá nhiều thuật toán tối ưu hóa (optimization algorithms) dành cho FedML được implement. Các thuật toán tối ưu hóa được hỗ trợ trong Flower. Tôi nghĩ khi mới bắt đầu nghiên cứu theo hướng này, việc lên stack công nghệ cho giả lập là quan trọng. Trong đó việc sử dụng Flower kết hợp với AWS (sẽ nói trong mục tiếp theo) là một cách dễ dàng hơn để các bạn tiếp cận vấn đề mà ít mất công sức. Cài cắm thì khá đơn giản mà Flower cũng hỗ trợ hết các thư viện/frameworks nổi như HuggingFace6, Tensorflow3, PyTorch2, PyTorch-Lightning7, MXNet8, .v.v… Chọn những con đường khác cũng được nhưng mất công quá vào những việc ngoài mục tiêu nghiên cứu thì không nên. Đôi dòng về AWS SageMaker Nền tảng điện toán đám mây của Amazon Amazon Web Services (AWS) là tên một công ty con của Amazon chuyên về cung cấp các dịch vụ điện toán đám mây. Bắt đầu từ năm 2006, công ty hiện là nhà cung cấp hàng đầu trong mảng dịch vụ điện toán đám mây, bao gồm 3 nhóm dịch vụ điện toán đám mây chính: Infrastructure-as-a-Service (IaaS): tức là cung cấp người dùng hệ thống toàn quyền cấp phát khởi tạo và kiểm soát hệ thống điện toán đám mây. Người dùng nắm toàn quyền từ quản lý tài nguyên, ứng dụng, dữ liệu và kể cả các hệ điều hành. Một ví dụ đơn giản nhất là bạn viết một ứng dụng web và deploy lên EC2, sau đó dữ liệu được lưu vào Amazon RDS, file được lưu trữ trên S3. Một ví dụ đơn giản như vậy có thể thể hiện được tính năng IaaS của AWS. Platform-as-a-Service (PaaS): tức là người dùng không quan tâm tới các vấn đề bên dưới như phần cứng (vCPU/vGPU), phần mềm (hệ điều hành) của hệ thống điện toán đám mây, mà chỉ tập trung vào viết ứng dụng. Việc cấp phát và khởi tạo tài nguyên đủ để ứng dụng người dùng chạy được do nền tảng lo hết. Tất nhiên, người dùng có thể viết cấu hình đơn giản bằng YAML hoặc JSON. Ví dụ đơn giản nhất chính là SageMaker mà chúng ta đang nói đến. Thay vì bạn phải khởi tạo và lựa chọn cấu hình máy ảo, instance của EC2, rồi login vào để cài đặt hệ điều hành, các gói hệ thống, ứng dụng thì SageMaker sẽ đảm nhiệm hết cho bạn. Một ví dụ khác là Lambda, bạn chỉ cần tập trung viết Lambda function bằng Python, rồi việc khởi tạo tài nguyên cũng như đảm bảo cho hàm được chạy trơn chu (khi có lỗi log lại hoặc bắn vào dead queue) thì Lambda sẽ lo hết những việc bên dưới ấy. Software-as-a-Service (SaaS): tức là người dùng chỉ dùng ứng dụng, tương tác và quản lý dữ liệu ở tầng ứng dụng, chứ không can thiệp tận tầng infra hay platform, và đương nhiên cũng không cần code hàm. Một ví dụ đơn giản là GMail, hoặc các hệ thống quản lý quan hệ khách hàng (CRM). Đơn giản chỉ “dùng” thôi! Thì tại sao nên dùng PaaS như SageMaker? Lựa chọn loại hình điện toán đám mây còn phụ thuộc vào mục tiêu kinh doanh, cũng như yêu cầu khách hàng. Tuy nhiên, với một usecase đơn giản là bạn thực hiện một nghiên cứu máy học đơn thuần. Cũng chẳng có ai yêu cầu bạn phải làm product (ý tưởng nghiên cứu chưa có các thày review chẳng may nó có “độc” hoặc là vũ khí hạt nhân thì làm sao?), nên chắc chắn là đến khi được phép chuyển ý tưởng thành product là sẽ phải trải qua 1 thời gian dài, và rủi ro là không được phép làm ấy. Thế với rủi ro như vậy thì tư thế đúng nhất của người làm nghiên cứu là gì? Là phải lựa chọn con đường thoáng nhất mà đi, dễ thành công nhất mà đi. Thế bây giờ cùng nghĩ nhé, Nếu chọn SaaS thì nó có hết tính năng rồi, ông chỉ ngồi cấu hình thì không có ý tưởng mới thực sự -&gt; thế còn làm làm gì? Nếu chọn IaaS thì khối lượng công việc nó rất là lớn, không chỉ có viết code Flask đâu nhé. Ông còn phải ngồi ông cấu hình, rồi đủ kiểu, mà kể cả có làm được thì nhìn chung cũng … không xịn! Mà kể cả làm demo mà so sánh với PaaS hoặc SaaS mà thấy không sang xịn mịn thì … lượn còn gì nữa? Đấy thế thì tại sao lại phải bỏ công vào những thứ không đóng góp gì vào việc hình thành ý tưởng như IaaS? tại sao lại đâm đầu vào mấy cái cấu hình như SaaS, trong khi đó là việc của người dùng? Rốt cuộc là chỉ còn những giải pháp kiểu PaaS là hợp lý nhất: nhà nghiên cứu tập trung vào đúng phần có giá trị lõi, mà không phải lan man đi ra những chỗ vớ vẩn chả liên quan gì tới anh! Đấy nên là chọn PaaS là ông vẫn được ngồi viết vài dòng code (cần thiết nhất, chứ những code không cần thiết không phải viết dòng nào) gọi là code chơi, vừa nhâm nhi cà phê vừa viết. Còn phần cứng các cái hệ thống nó lo hết! Mà thế nó mới đúng, thế mới sang xịn mịn, đẳng cấp product, chất lượng ngang với thung lũng Silicon! Chứ giờ mà ngồi viết, kể cả thuê thợ code chất lượng nhất cái mảnh đất Đông Dương này, chắc cũng chỉ chất lượng tầm 30%. Mà đã không sang xịn mịn 100%, trong khi mục tiêu của mình là nghiên cứu thì mình cứ PaaS thôi! Một lý do nữa nên dùng PaaS, là ví dụ so sánh với IaaS là ông suốt ngày ngồi code kiếc, cấu hình, trong khi với PaaS, ông tiết kiệm thời gian ấy, dùng thời gian ấy để lên kế hoạch, tìm kiếm ý tưởng, khách hàng mới. Trong khi IaaS thì ông suốt ngày ngồi ỳ trước màn hình code, cái kiểu ấy là không ăn thua ở VN. Phải đi họp hành thảo luận, tìm kiếm ý tưởng, gặp mặt khách hàng, … Nên chắc chắn cũng không cần suy nghĩ nhiều, PaaS là chắc chắn, và trong đó AWS SageMaker là một trong những người dẫn đầu thị trường! Sơ lược về AWS SageMaker Amazon SageMaker helps data scientists and developers to prepare data and build, train, and deploy machine learning models quickly by bringing together purpose-built capabilities. These capabilities allow you to build highly accurate models that improve over time without all the undifferentiated heavy lifting of managing ML environments and infrastructure. Amazon SageMaker không chỉ đơn thuần là 1 nền tảng PaaS hỗ trợ training mô hình máy học, mà bên trong nền tảng này còn hàng chục những tính năng chờ người dùng khám phá: SageMaker Studio Notebooks SageMaker Processing SageMaker Training SageMaker Batch Transform RStudio on SageMaker SageMaker Data Wrangler SageMaker Real-Time Inference SageMaker Edge Manager SageMaker On-Demand Notebook Instances SageMaker Feature Store SageMaker Asynchronous Inference SageMaker Serverless Inference SageMaker Debugger SageMaker Clarify Dưới đây là 1 video giới thiệu ngắn về AWS SageMaker. Ví dụ triển khai FedML trên SageMaker Dưới đây là 1 ví dụ triển khai FedML trên AWS PaaS. Chúng ta sử dụng các dịch vụ sau: AWS Step Functions: đây chính là mô phỏng của người điều phối (co-ordinator) của chúng ta. Chúng ta sử dụng AWS::StepFunctions::StateMachine để mô phỏng vai trò của người điều phối. Đoạn mã YAML dưới đây mô tả cấu hình của người điều phối thực hiện phát tán thông số mô hình vào các mô phỏng thiết bị trên ECS/Fargate. Hãy chú ý đến trạng thái RunTask-FlowerCoordinator 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 StateMachine: Type: AWS::StepFunctions::StateMachine Properties: StateMachineName: !Join [&quot;&quot;, [!Ref ProjectTag, &quot;-StateMachine&quot;]] RoleArn: !GetAtt StateMachineTaskRole.Arn Tags: - Key: Project Value: !Ref ProjectTag Definition: Comment: Deploys flower-coordinator and flower-proxy ecs tasks StartAt: GetIotConfig States: GetIotConfig: Type: Parallel Next: IotConfigFound Branches: - StartAt: DescribeIotEndpoint States: DescribeIotEndpoint: Parameters: EndpointType: iot:Data-ATS Resource: arn:aws:states:::aws-sdk:iot:describeEndpoint ResultSelector: IotEndpointAddress.$: $.EndpointAddress Type: Task End: true - StartAt: GetDatasetNameParameter States: GetDatasetNameParameter: Parameters: Name: !Sub /${ProjectTag}/DatasetName Resource: arn:aws:states:::aws-sdk:ssm:getParameter ResultSelector: DatasetName.$: $.Parameter.Value Type: Task Next: GetDatasetContent GetDatasetContent: Parameters: DatasetName.$: $.DatasetName Resource: arn:aws:states:::aws-sdk:iotanalytics:getDatasetContent ResultSelector: DataURI.$: $.Entries[0].DataURI Type: Task Next: GetClientList GetClientList: Parameters: FunctionName: !Sub &quot;${GetDatasetContentLambda.Arn}:$LATEST&quot; Payload: DataURI.$: $.DataURI Resource: arn:aws:states:::lambda:invoke ResultSelector: ClientList.$: $.Payload.Payload Retry: - BackoffRate: 2 ErrorEquals: - Lambda.ServiceException - Lambda.AWSLambdaException - Lambda.SdkClientException IntervalSeconds: 2 MaxAttempts: 6 Type: Task End: true ResultSelector: ClientList.$: $[1].ClientList IotEndpointAddress.$: $[0].IotEndpointAddress CoordinatorTaskComplete: Choices: - And: - StringMatches: STOPPED Variable: $.Tasks[0].Containers[0].LastStatus - NumericEquals: 0 Variable: $.Tasks[0].Containers[0].ExitCode Next: Success - And: - StringMatches: STOPPED Variable: $.Tasks[0].Containers[0].LastStatus - Not: NumericEquals: 0 Variable: $.Tasks[0].Containers[0].ExitCode Next: Fail Default: WaitForCoordinatorTask Type: Choice IotConfigFound: Choices: - And: - Variable: $.ClientList IsPresent: true - Variable: $.ClientList[0] IsPresent: true - Variable: $.IotEndpointAddress IsPresent: true Next: RunTask-FlowerCoordinator Default: Fail Type: Choice DescribeCoordinatorTask: Type: Task Next: CoordinatorTaskComplete Parameters: Cluster: !GetAtt ECSCluster.Arn Tasks.$: States.Array($.CoordinatorTaskResult.taskArn) Resource: arn:aws:states:::aws-sdk:ecs:describeTasks MapGreenGrassClients: Type: Map Catch: - ErrorEquals: - States.TaskFailed Next: StopCoordinatorTask ResultPath: $.mapClientsResult Next: WaitForCoordinatorTask Iterator: StartAt: RunTask-FlowerProxy States: RunTask-FlowerProxy: Type: Task Resource: arn:aws:states:::ecs:runTask.sync Parameters: LaunchType: FARGATE Cluster: !GetAtt ECSCluster.Arn TaskDefinition: !Ref ProxyTaskDef NetworkConfiguration: AwsvpcConfiguration: SecurityGroups: - !GetAtt SGContainers.GroupId Subnets: - !Ref Subnet Overrides: ContainerOverrides: - Name: flower-proxy Environment: - Name: CLIENT Value.$: $.client - Name: ENDPOINT Value.$: $.endpoint - Name: COORDINATOR Value.$: $.coordinator - Name: TABLE Value: !Ref DDBTable - Name: BUCKET Value: !Ref ProxyBucket End: true ItemsPath: $.ClientList Parameters: coordinator.$: States.Format(&#39;{}:8080&#39;, $.CoordinatorTaskResult.ip) client.$: $$.Map.Item.Value endpoint.$: States.Format(&#39;https://{}&#39;, $.IotEndpointAddress) RunTask-FlowerCoordinator: Type: Task Resource: arn:aws:states:::ecs:runTask.waitForTaskToken HeartbeatSeconds: 600 Parameters: LaunchType: FARGATE Cluster: !GetAtt ECSCluster.Arn TaskDefinition: !Ref CoordinatorTaskDef Overrides: ContainerOverrides: - Name: flower-coordinator Environment: - Name: TASK_TOKEN Value.$: $$.Task.Token NetworkConfiguration: AwsvpcConfiguration: SecurityGroups: - !GetAtt SGContainers.GroupId Subnets: - !Ref Subnet Next: MapGreenGrassClients ResultPath: $.CoordinatorTaskResult StopCoordinatorTask: Type: Task Parameters: Task.$: $.CoordinatorTaskResult.taskArn Resource: arn:aws:states:::aws-sdk:ecs:stopTask Next: Fail WaitForCoordinatorTask: Next: DescribeCoordinatorTask Seconds: 60 Type: Wait Success: Type: Succeed Fail: Type: Fail AWS ECS/FarGate: được dùng để host container cho người điều phối và các thiết bị mô phỏng. Một đoạn mã server của người điều phối dùng Flower như sau: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 # Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved. # SPDX-License-Identifier: MIT-0 import flwr as fl import boto3 import os import requests import json import logging import sys # Setup logging to stdout logger = logging.getLogger(__name__) logging.basicConfig(stream=sys.stdout, level=logging.INFO) token = os.getenv(&#39;TASK_TOKEN&#39;) metadata_uri = os.getenv(&#39;ECS_CONTAINER_METADATA_URI_V4&#39;) token_response = &quot;&quot; if metadata_uri is not None: r = requests.get(f&quot;{metadata_uri}/task&quot;) task_meta = r.json() logger.info(f&quot;found task metadata: {task_meta}&quot;) token_response = json.dumps({ &quot;ip&quot;: task_meta[&#39;Containers&#39;][0][&#39;Networks&#39;][0][&#39;IPv4Addresses&#39;][0], &quot;taskArn&quot;: task_meta[&#39;TaskARN&#39;] }) if token is not None: stfn = boto3.client(&#39;stepfunctions&#39;) logger.info(f&quot;send_task_success - taskToken={token}, output={token_response}&quot;) stfn.send_task_success(taskToken=token, output=token_response) fl.server.start_server(config={&quot;num_rounds&quot;: 3}) Ngoài ra, chúng ta cũng sử dụng một proxy container có nhiệm vụ trung chuyển yêu cầu giữa người điều phối và các thiết bị. Proxy này cũng thực hiện lưu dữ liệu xuống S3: lý do cho việc này là do thông số mô hình có thể tới vài MB, nên lưu vào S3 để về sau thiết bị tự load lên thì hiệu quả hơn. AWS IoT GreenGrass: ở đây để quản lý giao tiếp giữa các thiết bị IoT với proxies. GG Streams được dùng để lưu dữ liệu vào S3 cũng như load mô hình từ S3 lên. AWS IoT Core kết nối thiết bị IoT với các dịch vụ điện toán đám mây như DynamoDB. AWS DynamoDB lưu trữ rules từ IoT core. AWS Lambda được triển khai lên thiết bị GreenGrass và thực hiện training trên thiết bị IoT. AWS S3 lưu trữ mô hình. Triển khai giải pháp FedML trên Amazon SageMaker Kết luận Nhìn chung, qua bài viết này, chúng ta đã nhìn thấy tiềm năng cũng như sự cần thiết của FedML trong ứng dụng máy học thực tế. So với ML cơ bản thì FedML giải quyết khá nhiều vấn đề thực tế như bảo mật và bảo vệ dữ liệu người dùng, cải thiện băng thông. Và FedML cũng có những vấn đề riêng đang trong giai đoạn nghiên cứu. Chúng ta cũng điểm qua ứng dụng PoC thực tế của FedML bằng AWS SageMaker. References Aledhari, M., Razzak, R., Parizi, R.M. and Saeed, F. 2020. Federated learning: A survey on enabling technologies, protocols, and applications. IEEE Access. 8, (2020), 140699–140725.Details Liu, Y., Yuan, X., Xiong, Z., Kang, J., Wang, X. and Niyato, D. 2020. Federated learning for 6G communications: Challenges, methods, and future directions. China Communications. 17, 9 (2020), 105–118.Details Khan, L.U., Saad, W., Han, Z., Hossain, E. and Hong, C.S. 2021. Federated learning for internet of things: Recent advances, taxonomy, and open challenges. IEEE Communications Surveys &amp; Tutorials. (2021).Details Kaissis, G.A., Makowski, M.R., Rückert, D. and Braren, R.F. 2020. Secure, privacy-preserving and federated machine learning in medical imaging. Nature Machine Intelligence. 2, 6 (2020), 305–311.Details Nguyen, D.C., Ding, M., Pathirana, P.N., Seneviratne, A., Li, J. and Poor, H.V. 2021. Federated learning for internet of things: A comprehensive survey. IEEE Communications Surveys &amp; Tutorials. (2021).Details Kaissis, G., Ziller, A., Passerat-Palmbach, J., Ryffel, T., Usynin, D., Trask, A., Lima, I., Mancuso, J., Jungmann, F., Steinborn, M.-M. and others 2021. End-to-end privacy preserving deep learning on multi-institutional medical imaging. Nature Machine Intelligence. 3, 6 (2021), 473–484.Details https://mqtt.org/ &#8617; https://pytorch.org/ &#8617; &#8617;2 https://www.tensorflow.org/ &#8617; &#8617;2 https://github.com/OpenMined/PySyft &#8617; https://flower.dev/ &#8617; https://huggingface.co/ &#8617; https://www.pytorchlightning.ai/ &#8617; https://mxnet.apache.org/versions/1.9.1/ &#8617;" />
<meta property="og:description" content="Federated learning (FL) is a machine learning (ML) scenario with two distinct characteristics. First, training occurs on multiple machines. Second, each machine involved in training keeps training data locally; the only information shared between machines is the ML model and its parameters. FL solves challenges related to data privacy and scalability in scenarios such as mobile devices and IoT. By Amazon Web Service (AWS) Theo định nghĩa của AWS, thì Federated Machine Learning (FedML) là một hình thức (scenario) máy học có 2 đặc trưng nổi bật là: 1. quá trình học diễn ra trên nhiều máy.; 2. mỗi máy thực hiện học (training) sẽ giữ kín dữ liệu training ở local; dữ liệu duy nhất mà các máy chia sẻ với nhau chỉ là mô hình (model) máy học và các thông số model (parameters). Các bạn có thể thấy nếu chỉ có 1. thì FedML chỉ đơn giản là distributed learning (học phân tán) ra nhiều máy thiết bị, cái đặc trưng không kém phần quan trọng của FedML là 2. giấu kín dữ liệu của từng máy, tức là không có chuyện chia sẻ dữ liệu người dùng, và vì vậy nên tính bảo mật và tuân thủ privacy cao hơn. Ngoài ra vì chỉ chia sẻ một “ít” dữ liệu là thông số mô hình nên độ ngốn băng thông là thấp, dẫn đến FedML là 1 hình thức học đang trở nên dần nhận được nhiều sự quan tâm. Tuy nhiên, học đi đôi với hành, nên chúng ta cũng sẽ lấy ví dụ về FedML trong thực tế qua một ví dụ triển khai trên AWS SageMaker. Giới thiệu về FedML Machine Learning truyền thống vs. FedML ML truyền thống (hay là Machine Learning cơ bản) thì chủ yếu dựa vào nguồn dữ liệu, kiến trúc mô hình và thuật toán máy học cơ bản (xem hình dưới). Định nghĩa lý thuyết của ML tôi xin phép không bàn tới, mà điểm focus của bài viết là từ góc nhìn kỹ thuật, kiến trúc vận hành thực tế của ML. Machine Learning cơ bản Các bạn có thể thấy ngay, với kiến trúc ML cơ bản như trên, dữ liệu học (training data) sẽ được gửi về 1 địa điểm tập trung để thực hiện quá trình học. Và đây chính là vấn đề: việc gửi dữ liệu qua đường truyền mạng sẽ có khá nhiều vấn đề về tuân thủ dữ liệu người dùng cũng như bảo mật. Ngoài ra, cái gọi là địa điểm tập trung ấy cũng có vấn đề: nếu địa điểm đó nằm ngoài phạm vi đất nước, tức là dữ liệu người dùng 1 quốc gia, ví dụ như Việt Nam, sẽ bị gửi sang 1 server ở Trung Quốc? Các bạn thấy đấy, ML cơ bản có khá nhiều giới hạn và vấn đề, đòi hỏi researcher lẫn kỹ sư máy học phải có sự cân nhắc kỹ càng khi thiết kế triển khai vận hành 1 hệ thống ML cơ bản. Ngoài ra, nhu cầu về bảo mật dữ liệu cấp công nghiệp ngày càng cao, dẫn đến các hệ thống ML cơ bản chỉ dừng ở mức độ lý thuyết chứ khó triển khai vào sản phẩm thực tế. Khi triển khai vận hành vào sản phẩm thực tế, chúng ta cần 1 mô hình kiến trúc học tối tân hơn, và đó chính là lúc chúng ta cần FedML. FedML [6, 6, 6, 6, 6, 6] giải quyết một phát cả 2 vấn đề trên, thậm chí còn cải thiện cả băng thông (vì không phải chia sẻ data nữa). Dưới đây là biểu đồ luồng thông tin của 1 hệ thống FedML (cũng cơ bản thôi). FedML Luồng FedML ở trên đây có 2 nhóm thiết bị chính: devices (thiết bị) và coordinators (người điều phối). Devices có thể là các thiết bị IoT, smartphones, sensors, PCs, .v.v… Người điều phối (co-ordinator) là nhóm những servers thực hiện aggregate thông số mô hình và phát tán cho các thiết bị. Chú ý: Người điều phối không cần truy cập hay tiếp xúc với dữ liệu, việc duy nhất của người điều phối là phát tán mô hình (bao gồm cả thông số), nhận mô hình được train ở các thiết bị local và aggregate. Người điều phối cũng không train gì cả, mà đó là việc của thiết bị (devices). Thiết bị cũng thu thập dữ liệu luôn, và người điều phối cũng không cần quan tâm tới dữ liệu ở local của thiết bị. Luồng xử lý của FedML cơ bản bao gồm: Người điều phối gửi dữ liệu mô hình đến các thiết bị để khởi tạo mô hình trên từng thiết bị. Về cơ bản, ở bước này, mô hình ở mọi thiết bị sẽ là đồng bộ. Khi các thiết bị đã “sẵn sàng”, người điều phối gửi tín hiệu bắt đầu train. Sau hiệu lệnh này, các thiết bị bắt đầu chuyển sang trạng thái training, tức là bắt đầu thu thập dữ liệu và cập nhật thông số mô hình. Việc train được các thiết bị thực hiện với dữ liệu được thu thập ở local và không chia sẻ đi đâu cả. Bộ dữ liệu local có thể có sẵn (và được cung cấp bởi bên thứ 3), hoặc có thể được thu thập online (ví dụ như camera giao thông). Khi việc học (train) kết thúc, các thiết bị tổng hợp dữ liệu mô hình (thông số và trọng số weights) để gửi về cho người điều phối. Ở đây có vấn đề là độ trễ giữa các thiết bị, nên người điều phối có thể xem xét để thực hiện bước tiếp theo khi chờ đủ khoảng bao nhiều % mô hình chứ không nhất thiết chờ tới 100%. Người điều phối thực hiện thuật toán aggregate các thông tin mô hình được gửi về từ các thiết bị local. Thuật toán đơn giản nhất là FedAvg tức là đơn thuần là lấy trung bình mọi thông số làm thông số mới. Quay lại 1. tức là lại phát tán lại thông số mô hình cho các thiết bị. Vai trò của người điều phối tưởng đơn giản nhưng lại khá quan trọng. Thường thì sẽ phải kết hợp với weight monitoring tức là giám sát trọng số, phát hiện trọng số bất thường, … Ưu nhược điểm của FedML Ưu điểm Nâng cao tính bảo mật, bảo vệ dữ liệu người dùng tốt hơn. Cải thiện băng thông dữ liệu. Nhược điểm Tính bất định trong tập thiết bị: số lượng thiết bị lên tới hàng triệu, chục triệu và bất cứ lúc nào cũng có thiết bị thêm vào hoặc bỏ ra. Nói nôm na là người ra người vào liên tục. Liên lạc bất đồng bộ: các thiết bị giao tiếp với người điều phối thông qua giao thức bất đồng bộ (dựa trên pub/sub messaging) như MQTT1. Ví dụ như khi người điều phối muốn yêu cầu các thiết bị nộp thông số mô hình, thì call đó có thể không đồng bộ và xuất hiện độ trễ. Như đã nói ở trên, nếu chờ hết 100% thiết bị nộp bài sẽ rất lâu, người điều phối có thể phải set timeout. Băng thông mô hình: mặc dù việc không phải truyền tải dữ liệu là đã tiết kiệm rất lớn băng thông, dữ liệu mô hình vẫn có thể từ vài MB tới vài trăm MB/lần. Frameworks: cái này cũng là vấn đề vì những framework máy học truyền thống như PyTorch2 hay Tensorflow3 vẫn chưa chịu hỗ trợ FedML tối đa. Phần lớn các framework này vẫn đang dừng ở mức hỗ trợ EdgeML hơn là FedML. Mọi kiến trúc máy học đều có ưu nhược điểm riêng, kể cả ML cơ bản lẫn FedML. FedML giải quyết các vấn đề của ML cơ bản, và chúng ta lại tiếp tục giải quyết các vấn đề của FedML. Vấn đề người ra người vào liên tục thì có chuyện gì ở đây là cấu hình của tập thiết bị sẽ thay đổi, chúng ta không thể kỳ vọng thiết bị mới vào sẽ lại có cấu hình và năng lực tương tự như các thiết bị đang có và đã bỏ ra. Và vấn đề là không chỉ năng lực không đồng bộ mà còn là những thiết bị mới tuyển vào có thể “lái” việc huấn luyện mô hình đi theo hướng mà chúng mong muốn. Tức là những thiết bị “xấu”: vào chỉ để ảnh hưởng xấu đến mô hình, hoặc vào một tí lại bỏ việc chả đóng góp gì cho việc học của mô hình, hoặc vào chỉ để nghe ngóng chứ không phải để đóng góp vào việc tính toán huấn luyện mô hình. Vấn đề liên lạc bất đồng bộ thì chủ yếu là giao tiếp giữa thiết bị và người điều phối: thiết bị do không đồng bộ nên có thể bắt người điều phối chờ. Thì nói chung 2 cái vấn đề này tôi nghĩ cũng là những vấn đề “muôn thuở” của FedML. Bây giờ cũng có nhiều hướng giải quyết. Vấn đề băng thông mô hình thì chủ yếu là tối ưu size của mô hình thì giờ cũng nhiều hướng giải quyết mở ra như Distillation, Prunning, Binary Neural Nets, Quantization, … Vấn đề frameworks thì cũng dần dần có những phát triển mới như PySyft4 hay Flower5. Flower là một frameworks hoàn thiện cho FedML với hỗ trợ dành cho cả PyTorch và Tensorflow. Khá nhiều thuật toán tối ưu hóa (optimization algorithms) dành cho FedML được implement. Các thuật toán tối ưu hóa được hỗ trợ trong Flower. Tôi nghĩ khi mới bắt đầu nghiên cứu theo hướng này, việc lên stack công nghệ cho giả lập là quan trọng. Trong đó việc sử dụng Flower kết hợp với AWS (sẽ nói trong mục tiếp theo) là một cách dễ dàng hơn để các bạn tiếp cận vấn đề mà ít mất công sức. Cài cắm thì khá đơn giản mà Flower cũng hỗ trợ hết các thư viện/frameworks nổi như HuggingFace6, Tensorflow3, PyTorch2, PyTorch-Lightning7, MXNet8, .v.v… Chọn những con đường khác cũng được nhưng mất công quá vào những việc ngoài mục tiêu nghiên cứu thì không nên. Đôi dòng về AWS SageMaker Nền tảng điện toán đám mây của Amazon Amazon Web Services (AWS) là tên một công ty con của Amazon chuyên về cung cấp các dịch vụ điện toán đám mây. Bắt đầu từ năm 2006, công ty hiện là nhà cung cấp hàng đầu trong mảng dịch vụ điện toán đám mây, bao gồm 3 nhóm dịch vụ điện toán đám mây chính: Infrastructure-as-a-Service (IaaS): tức là cung cấp người dùng hệ thống toàn quyền cấp phát khởi tạo và kiểm soát hệ thống điện toán đám mây. Người dùng nắm toàn quyền từ quản lý tài nguyên, ứng dụng, dữ liệu và kể cả các hệ điều hành. Một ví dụ đơn giản nhất là bạn viết một ứng dụng web và deploy lên EC2, sau đó dữ liệu được lưu vào Amazon RDS, file được lưu trữ trên S3. Một ví dụ đơn giản như vậy có thể thể hiện được tính năng IaaS của AWS. Platform-as-a-Service (PaaS): tức là người dùng không quan tâm tới các vấn đề bên dưới như phần cứng (vCPU/vGPU), phần mềm (hệ điều hành) của hệ thống điện toán đám mây, mà chỉ tập trung vào viết ứng dụng. Việc cấp phát và khởi tạo tài nguyên đủ để ứng dụng người dùng chạy được do nền tảng lo hết. Tất nhiên, người dùng có thể viết cấu hình đơn giản bằng YAML hoặc JSON. Ví dụ đơn giản nhất chính là SageMaker mà chúng ta đang nói đến. Thay vì bạn phải khởi tạo và lựa chọn cấu hình máy ảo, instance của EC2, rồi login vào để cài đặt hệ điều hành, các gói hệ thống, ứng dụng thì SageMaker sẽ đảm nhiệm hết cho bạn. Một ví dụ khác là Lambda, bạn chỉ cần tập trung viết Lambda function bằng Python, rồi việc khởi tạo tài nguyên cũng như đảm bảo cho hàm được chạy trơn chu (khi có lỗi log lại hoặc bắn vào dead queue) thì Lambda sẽ lo hết những việc bên dưới ấy. Software-as-a-Service (SaaS): tức là người dùng chỉ dùng ứng dụng, tương tác và quản lý dữ liệu ở tầng ứng dụng, chứ không can thiệp tận tầng infra hay platform, và đương nhiên cũng không cần code hàm. Một ví dụ đơn giản là GMail, hoặc các hệ thống quản lý quan hệ khách hàng (CRM). Đơn giản chỉ “dùng” thôi! Thì tại sao nên dùng PaaS như SageMaker? Lựa chọn loại hình điện toán đám mây còn phụ thuộc vào mục tiêu kinh doanh, cũng như yêu cầu khách hàng. Tuy nhiên, với một usecase đơn giản là bạn thực hiện một nghiên cứu máy học đơn thuần. Cũng chẳng có ai yêu cầu bạn phải làm product (ý tưởng nghiên cứu chưa có các thày review chẳng may nó có “độc” hoặc là vũ khí hạt nhân thì làm sao?), nên chắc chắn là đến khi được phép chuyển ý tưởng thành product là sẽ phải trải qua 1 thời gian dài, và rủi ro là không được phép làm ấy. Thế với rủi ro như vậy thì tư thế đúng nhất của người làm nghiên cứu là gì? Là phải lựa chọn con đường thoáng nhất mà đi, dễ thành công nhất mà đi. Thế bây giờ cùng nghĩ nhé, Nếu chọn SaaS thì nó có hết tính năng rồi, ông chỉ ngồi cấu hình thì không có ý tưởng mới thực sự -&gt; thế còn làm làm gì? Nếu chọn IaaS thì khối lượng công việc nó rất là lớn, không chỉ có viết code Flask đâu nhé. Ông còn phải ngồi ông cấu hình, rồi đủ kiểu, mà kể cả có làm được thì nhìn chung cũng … không xịn! Mà kể cả làm demo mà so sánh với PaaS hoặc SaaS mà thấy không sang xịn mịn thì … lượn còn gì nữa? Đấy thế thì tại sao lại phải bỏ công vào những thứ không đóng góp gì vào việc hình thành ý tưởng như IaaS? tại sao lại đâm đầu vào mấy cái cấu hình như SaaS, trong khi đó là việc của người dùng? Rốt cuộc là chỉ còn những giải pháp kiểu PaaS là hợp lý nhất: nhà nghiên cứu tập trung vào đúng phần có giá trị lõi, mà không phải lan man đi ra những chỗ vớ vẩn chả liên quan gì tới anh! Đấy nên là chọn PaaS là ông vẫn được ngồi viết vài dòng code (cần thiết nhất, chứ những code không cần thiết không phải viết dòng nào) gọi là code chơi, vừa nhâm nhi cà phê vừa viết. Còn phần cứng các cái hệ thống nó lo hết! Mà thế nó mới đúng, thế mới sang xịn mịn, đẳng cấp product, chất lượng ngang với thung lũng Silicon! Chứ giờ mà ngồi viết, kể cả thuê thợ code chất lượng nhất cái mảnh đất Đông Dương này, chắc cũng chỉ chất lượng tầm 30%. Mà đã không sang xịn mịn 100%, trong khi mục tiêu của mình là nghiên cứu thì mình cứ PaaS thôi! Một lý do nữa nên dùng PaaS, là ví dụ so sánh với IaaS là ông suốt ngày ngồi code kiếc, cấu hình, trong khi với PaaS, ông tiết kiệm thời gian ấy, dùng thời gian ấy để lên kế hoạch, tìm kiếm ý tưởng, khách hàng mới. Trong khi IaaS thì ông suốt ngày ngồi ỳ trước màn hình code, cái kiểu ấy là không ăn thua ở VN. Phải đi họp hành thảo luận, tìm kiếm ý tưởng, gặp mặt khách hàng, … Nên chắc chắn cũng không cần suy nghĩ nhiều, PaaS là chắc chắn, và trong đó AWS SageMaker là một trong những người dẫn đầu thị trường! Sơ lược về AWS SageMaker Amazon SageMaker helps data scientists and developers to prepare data and build, train, and deploy machine learning models quickly by bringing together purpose-built capabilities. These capabilities allow you to build highly accurate models that improve over time without all the undifferentiated heavy lifting of managing ML environments and infrastructure. Amazon SageMaker không chỉ đơn thuần là 1 nền tảng PaaS hỗ trợ training mô hình máy học, mà bên trong nền tảng này còn hàng chục những tính năng chờ người dùng khám phá: SageMaker Studio Notebooks SageMaker Processing SageMaker Training SageMaker Batch Transform RStudio on SageMaker SageMaker Data Wrangler SageMaker Real-Time Inference SageMaker Edge Manager SageMaker On-Demand Notebook Instances SageMaker Feature Store SageMaker Asynchronous Inference SageMaker Serverless Inference SageMaker Debugger SageMaker Clarify Dưới đây là 1 video giới thiệu ngắn về AWS SageMaker. Ví dụ triển khai FedML trên SageMaker Dưới đây là 1 ví dụ triển khai FedML trên AWS PaaS. Chúng ta sử dụng các dịch vụ sau: AWS Step Functions: đây chính là mô phỏng của người điều phối (co-ordinator) của chúng ta. Chúng ta sử dụng AWS::StepFunctions::StateMachine để mô phỏng vai trò của người điều phối. Đoạn mã YAML dưới đây mô tả cấu hình của người điều phối thực hiện phát tán thông số mô hình vào các mô phỏng thiết bị trên ECS/Fargate. Hãy chú ý đến trạng thái RunTask-FlowerCoordinator 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 StateMachine: Type: AWS::StepFunctions::StateMachine Properties: StateMachineName: !Join [&quot;&quot;, [!Ref ProjectTag, &quot;-StateMachine&quot;]] RoleArn: !GetAtt StateMachineTaskRole.Arn Tags: - Key: Project Value: !Ref ProjectTag Definition: Comment: Deploys flower-coordinator and flower-proxy ecs tasks StartAt: GetIotConfig States: GetIotConfig: Type: Parallel Next: IotConfigFound Branches: - StartAt: DescribeIotEndpoint States: DescribeIotEndpoint: Parameters: EndpointType: iot:Data-ATS Resource: arn:aws:states:::aws-sdk:iot:describeEndpoint ResultSelector: IotEndpointAddress.$: $.EndpointAddress Type: Task End: true - StartAt: GetDatasetNameParameter States: GetDatasetNameParameter: Parameters: Name: !Sub /${ProjectTag}/DatasetName Resource: arn:aws:states:::aws-sdk:ssm:getParameter ResultSelector: DatasetName.$: $.Parameter.Value Type: Task Next: GetDatasetContent GetDatasetContent: Parameters: DatasetName.$: $.DatasetName Resource: arn:aws:states:::aws-sdk:iotanalytics:getDatasetContent ResultSelector: DataURI.$: $.Entries[0].DataURI Type: Task Next: GetClientList GetClientList: Parameters: FunctionName: !Sub &quot;${GetDatasetContentLambda.Arn}:$LATEST&quot; Payload: DataURI.$: $.DataURI Resource: arn:aws:states:::lambda:invoke ResultSelector: ClientList.$: $.Payload.Payload Retry: - BackoffRate: 2 ErrorEquals: - Lambda.ServiceException - Lambda.AWSLambdaException - Lambda.SdkClientException IntervalSeconds: 2 MaxAttempts: 6 Type: Task End: true ResultSelector: ClientList.$: $[1].ClientList IotEndpointAddress.$: $[0].IotEndpointAddress CoordinatorTaskComplete: Choices: - And: - StringMatches: STOPPED Variable: $.Tasks[0].Containers[0].LastStatus - NumericEquals: 0 Variable: $.Tasks[0].Containers[0].ExitCode Next: Success - And: - StringMatches: STOPPED Variable: $.Tasks[0].Containers[0].LastStatus - Not: NumericEquals: 0 Variable: $.Tasks[0].Containers[0].ExitCode Next: Fail Default: WaitForCoordinatorTask Type: Choice IotConfigFound: Choices: - And: - Variable: $.ClientList IsPresent: true - Variable: $.ClientList[0] IsPresent: true - Variable: $.IotEndpointAddress IsPresent: true Next: RunTask-FlowerCoordinator Default: Fail Type: Choice DescribeCoordinatorTask: Type: Task Next: CoordinatorTaskComplete Parameters: Cluster: !GetAtt ECSCluster.Arn Tasks.$: States.Array($.CoordinatorTaskResult.taskArn) Resource: arn:aws:states:::aws-sdk:ecs:describeTasks MapGreenGrassClients: Type: Map Catch: - ErrorEquals: - States.TaskFailed Next: StopCoordinatorTask ResultPath: $.mapClientsResult Next: WaitForCoordinatorTask Iterator: StartAt: RunTask-FlowerProxy States: RunTask-FlowerProxy: Type: Task Resource: arn:aws:states:::ecs:runTask.sync Parameters: LaunchType: FARGATE Cluster: !GetAtt ECSCluster.Arn TaskDefinition: !Ref ProxyTaskDef NetworkConfiguration: AwsvpcConfiguration: SecurityGroups: - !GetAtt SGContainers.GroupId Subnets: - !Ref Subnet Overrides: ContainerOverrides: - Name: flower-proxy Environment: - Name: CLIENT Value.$: $.client - Name: ENDPOINT Value.$: $.endpoint - Name: COORDINATOR Value.$: $.coordinator - Name: TABLE Value: !Ref DDBTable - Name: BUCKET Value: !Ref ProxyBucket End: true ItemsPath: $.ClientList Parameters: coordinator.$: States.Format(&#39;{}:8080&#39;, $.CoordinatorTaskResult.ip) client.$: $$.Map.Item.Value endpoint.$: States.Format(&#39;https://{}&#39;, $.IotEndpointAddress) RunTask-FlowerCoordinator: Type: Task Resource: arn:aws:states:::ecs:runTask.waitForTaskToken HeartbeatSeconds: 600 Parameters: LaunchType: FARGATE Cluster: !GetAtt ECSCluster.Arn TaskDefinition: !Ref CoordinatorTaskDef Overrides: ContainerOverrides: - Name: flower-coordinator Environment: - Name: TASK_TOKEN Value.$: $$.Task.Token NetworkConfiguration: AwsvpcConfiguration: SecurityGroups: - !GetAtt SGContainers.GroupId Subnets: - !Ref Subnet Next: MapGreenGrassClients ResultPath: $.CoordinatorTaskResult StopCoordinatorTask: Type: Task Parameters: Task.$: $.CoordinatorTaskResult.taskArn Resource: arn:aws:states:::aws-sdk:ecs:stopTask Next: Fail WaitForCoordinatorTask: Next: DescribeCoordinatorTask Seconds: 60 Type: Wait Success: Type: Succeed Fail: Type: Fail AWS ECS/FarGate: được dùng để host container cho người điều phối và các thiết bị mô phỏng. Một đoạn mã server của người điều phối dùng Flower như sau: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 # Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved. # SPDX-License-Identifier: MIT-0 import flwr as fl import boto3 import os import requests import json import logging import sys # Setup logging to stdout logger = logging.getLogger(__name__) logging.basicConfig(stream=sys.stdout, level=logging.INFO) token = os.getenv(&#39;TASK_TOKEN&#39;) metadata_uri = os.getenv(&#39;ECS_CONTAINER_METADATA_URI_V4&#39;) token_response = &quot;&quot; if metadata_uri is not None: r = requests.get(f&quot;{metadata_uri}/task&quot;) task_meta = r.json() logger.info(f&quot;found task metadata: {task_meta}&quot;) token_response = json.dumps({ &quot;ip&quot;: task_meta[&#39;Containers&#39;][0][&#39;Networks&#39;][0][&#39;IPv4Addresses&#39;][0], &quot;taskArn&quot;: task_meta[&#39;TaskARN&#39;] }) if token is not None: stfn = boto3.client(&#39;stepfunctions&#39;) logger.info(f&quot;send_task_success - taskToken={token}, output={token_response}&quot;) stfn.send_task_success(taskToken=token, output=token_response) fl.server.start_server(config={&quot;num_rounds&quot;: 3}) Ngoài ra, chúng ta cũng sử dụng một proxy container có nhiệm vụ trung chuyển yêu cầu giữa người điều phối và các thiết bị. Proxy này cũng thực hiện lưu dữ liệu xuống S3: lý do cho việc này là do thông số mô hình có thể tới vài MB, nên lưu vào S3 để về sau thiết bị tự load lên thì hiệu quả hơn. AWS IoT GreenGrass: ở đây để quản lý giao tiếp giữa các thiết bị IoT với proxies. GG Streams được dùng để lưu dữ liệu vào S3 cũng như load mô hình từ S3 lên. AWS IoT Core kết nối thiết bị IoT với các dịch vụ điện toán đám mây như DynamoDB. AWS DynamoDB lưu trữ rules từ IoT core. AWS Lambda được triển khai lên thiết bị GreenGrass và thực hiện training trên thiết bị IoT. AWS S3 lưu trữ mô hình. Triển khai giải pháp FedML trên Amazon SageMaker Kết luận Nhìn chung, qua bài viết này, chúng ta đã nhìn thấy tiềm năng cũng như sự cần thiết của FedML trong ứng dụng máy học thực tế. So với ML cơ bản thì FedML giải quyết khá nhiều vấn đề thực tế như bảo mật và bảo vệ dữ liệu người dùng, cải thiện băng thông. Và FedML cũng có những vấn đề riêng đang trong giai đoạn nghiên cứu. Chúng ta cũng điểm qua ứng dụng PoC thực tế của FedML bằng AWS SageMaker. References Aledhari, M., Razzak, R., Parizi, R.M. and Saeed, F. 2020. Federated learning: A survey on enabling technologies, protocols, and applications. IEEE Access. 8, (2020), 140699–140725.Details Liu, Y., Yuan, X., Xiong, Z., Kang, J., Wang, X. and Niyato, D. 2020. Federated learning for 6G communications: Challenges, methods, and future directions. China Communications. 17, 9 (2020), 105–118.Details Khan, L.U., Saad, W., Han, Z., Hossain, E. and Hong, C.S. 2021. Federated learning for internet of things: Recent advances, taxonomy, and open challenges. IEEE Communications Surveys &amp; Tutorials. (2021).Details Kaissis, G.A., Makowski, M.R., Rückert, D. and Braren, R.F. 2020. Secure, privacy-preserving and federated machine learning in medical imaging. Nature Machine Intelligence. 2, 6 (2020), 305–311.Details Nguyen, D.C., Ding, M., Pathirana, P.N., Seneviratne, A., Li, J. and Poor, H.V. 2021. Federated learning for internet of things: A comprehensive survey. IEEE Communications Surveys &amp; Tutorials. (2021).Details Kaissis, G., Ziller, A., Passerat-Palmbach, J., Ryffel, T., Usynin, D., Trask, A., Lima, I., Mancuso, J., Jungmann, F., Steinborn, M.-M. and others 2021. End-to-end privacy preserving deep learning on multi-institutional medical imaging. Nature Machine Intelligence. 3, 6 (2021), 473–484.Details https://mqtt.org/ &#8617; https://pytorch.org/ &#8617; &#8617;2 https://www.tensorflow.org/ &#8617; &#8617;2 https://github.com/OpenMined/PySyft &#8617; https://flower.dev/ &#8617; https://huggingface.co/ &#8617; https://www.pytorchlightning.ai/ &#8617; https://mxnet.apache.org/versions/1.9.1/ &#8617;" />
<meta property="og:site_name" content="AiFi" />
<meta property="og:image" content="https://github.com/aws-samples/federated-learning-greengrass-ecs/raw/main/diagrams/overview.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-06-05T00:00:00+09:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="https://github.com/aws-samples/federated-learning-greengrass-ecs/raw/main/diagrams/overview.png" />
<meta property="twitter:title" content="Best practices for Federated Machine Learning (FedML) with Amazon Web Services (AWS)" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"tuan"},"dateModified":"2022-06-05T00:00:00+09:00","datePublished":"2022-06-05T00:00:00+09:00","description":"Federated learning (FL) is a machine learning (ML) scenario with two distinct characteristics. First, training occurs on multiple machines. Second, each machine involved in training keeps training data locally; the only information shared between machines is the ML model and its parameters. FL solves challenges related to data privacy and scalability in scenarios such as mobile devices and IoT. By Amazon Web Service (AWS) Theo định nghĩa của AWS, thì Federated Machine Learning (FedML) là một hình thức (scenario) máy học có 2 đặc trưng nổi bật là: 1. quá trình học diễn ra trên nhiều máy.; 2. mỗi máy thực hiện học (training) sẽ giữ kín dữ liệu training ở local; dữ liệu duy nhất mà các máy chia sẻ với nhau chỉ là mô hình (model) máy học và các thông số model (parameters). Các bạn có thể thấy nếu chỉ có 1. thì FedML chỉ đơn giản là distributed learning (học phân tán) ra nhiều máy thiết bị, cái đặc trưng không kém phần quan trọng của FedML là 2. giấu kín dữ liệu của từng máy, tức là không có chuyện chia sẻ dữ liệu người dùng, và vì vậy nên tính bảo mật và tuân thủ privacy cao hơn. Ngoài ra vì chỉ chia sẻ một “ít” dữ liệu là thông số mô hình nên độ ngốn băng thông là thấp, dẫn đến FedML là 1 hình thức học đang trở nên dần nhận được nhiều sự quan tâm. Tuy nhiên, học đi đôi với hành, nên chúng ta cũng sẽ lấy ví dụ về FedML trong thực tế qua một ví dụ triển khai trên AWS SageMaker. Giới thiệu về FedML Machine Learning truyền thống vs. FedML ML truyền thống (hay là Machine Learning cơ bản) thì chủ yếu dựa vào nguồn dữ liệu, kiến trúc mô hình và thuật toán máy học cơ bản (xem hình dưới). Định nghĩa lý thuyết của ML tôi xin phép không bàn tới, mà điểm focus của bài viết là từ góc nhìn kỹ thuật, kiến trúc vận hành thực tế của ML. Machine Learning cơ bản Các bạn có thể thấy ngay, với kiến trúc ML cơ bản như trên, dữ liệu học (training data) sẽ được gửi về 1 địa điểm tập trung để thực hiện quá trình học. Và đây chính là vấn đề: việc gửi dữ liệu qua đường truyền mạng sẽ có khá nhiều vấn đề về tuân thủ dữ liệu người dùng cũng như bảo mật. Ngoài ra, cái gọi là địa điểm tập trung ấy cũng có vấn đề: nếu địa điểm đó nằm ngoài phạm vi đất nước, tức là dữ liệu người dùng 1 quốc gia, ví dụ như Việt Nam, sẽ bị gửi sang 1 server ở Trung Quốc? Các bạn thấy đấy, ML cơ bản có khá nhiều giới hạn và vấn đề, đòi hỏi researcher lẫn kỹ sư máy học phải có sự cân nhắc kỹ càng khi thiết kế triển khai vận hành 1 hệ thống ML cơ bản. Ngoài ra, nhu cầu về bảo mật dữ liệu cấp công nghiệp ngày càng cao, dẫn đến các hệ thống ML cơ bản chỉ dừng ở mức độ lý thuyết chứ khó triển khai vào sản phẩm thực tế. Khi triển khai vận hành vào sản phẩm thực tế, chúng ta cần 1 mô hình kiến trúc học tối tân hơn, và đó chính là lúc chúng ta cần FedML. FedML [6, 6, 6, 6, 6, 6] giải quyết một phát cả 2 vấn đề trên, thậm chí còn cải thiện cả băng thông (vì không phải chia sẻ data nữa). Dưới đây là biểu đồ luồng thông tin của 1 hệ thống FedML (cũng cơ bản thôi). FedML Luồng FedML ở trên đây có 2 nhóm thiết bị chính: devices (thiết bị) và coordinators (người điều phối). Devices có thể là các thiết bị IoT, smartphones, sensors, PCs, .v.v… Người điều phối (co-ordinator) là nhóm những servers thực hiện aggregate thông số mô hình và phát tán cho các thiết bị. Chú ý: Người điều phối không cần truy cập hay tiếp xúc với dữ liệu, việc duy nhất của người điều phối là phát tán mô hình (bao gồm cả thông số), nhận mô hình được train ở các thiết bị local và aggregate. Người điều phối cũng không train gì cả, mà đó là việc của thiết bị (devices). Thiết bị cũng thu thập dữ liệu luôn, và người điều phối cũng không cần quan tâm tới dữ liệu ở local của thiết bị. Luồng xử lý của FedML cơ bản bao gồm: Người điều phối gửi dữ liệu mô hình đến các thiết bị để khởi tạo mô hình trên từng thiết bị. Về cơ bản, ở bước này, mô hình ở mọi thiết bị sẽ là đồng bộ. Khi các thiết bị đã “sẵn sàng”, người điều phối gửi tín hiệu bắt đầu train. Sau hiệu lệnh này, các thiết bị bắt đầu chuyển sang trạng thái training, tức là bắt đầu thu thập dữ liệu và cập nhật thông số mô hình. Việc train được các thiết bị thực hiện với dữ liệu được thu thập ở local và không chia sẻ đi đâu cả. Bộ dữ liệu local có thể có sẵn (và được cung cấp bởi bên thứ 3), hoặc có thể được thu thập online (ví dụ như camera giao thông). Khi việc học (train) kết thúc, các thiết bị tổng hợp dữ liệu mô hình (thông số và trọng số weights) để gửi về cho người điều phối. Ở đây có vấn đề là độ trễ giữa các thiết bị, nên người điều phối có thể xem xét để thực hiện bước tiếp theo khi chờ đủ khoảng bao nhiều % mô hình chứ không nhất thiết chờ tới 100%. Người điều phối thực hiện thuật toán aggregate các thông tin mô hình được gửi về từ các thiết bị local. Thuật toán đơn giản nhất là FedAvg tức là đơn thuần là lấy trung bình mọi thông số làm thông số mới. Quay lại 1. tức là lại phát tán lại thông số mô hình cho các thiết bị. Vai trò của người điều phối tưởng đơn giản nhưng lại khá quan trọng. Thường thì sẽ phải kết hợp với weight monitoring tức là giám sát trọng số, phát hiện trọng số bất thường, … Ưu nhược điểm của FedML Ưu điểm Nâng cao tính bảo mật, bảo vệ dữ liệu người dùng tốt hơn. Cải thiện băng thông dữ liệu. Nhược điểm Tính bất định trong tập thiết bị: số lượng thiết bị lên tới hàng triệu, chục triệu và bất cứ lúc nào cũng có thiết bị thêm vào hoặc bỏ ra. Nói nôm na là người ra người vào liên tục. Liên lạc bất đồng bộ: các thiết bị giao tiếp với người điều phối thông qua giao thức bất đồng bộ (dựa trên pub/sub messaging) như MQTT1. Ví dụ như khi người điều phối muốn yêu cầu các thiết bị nộp thông số mô hình, thì call đó có thể không đồng bộ và xuất hiện độ trễ. Như đã nói ở trên, nếu chờ hết 100% thiết bị nộp bài sẽ rất lâu, người điều phối có thể phải set timeout. Băng thông mô hình: mặc dù việc không phải truyền tải dữ liệu là đã tiết kiệm rất lớn băng thông, dữ liệu mô hình vẫn có thể từ vài MB tới vài trăm MB/lần. Frameworks: cái này cũng là vấn đề vì những framework máy học truyền thống như PyTorch2 hay Tensorflow3 vẫn chưa chịu hỗ trợ FedML tối đa. Phần lớn các framework này vẫn đang dừng ở mức hỗ trợ EdgeML hơn là FedML. Mọi kiến trúc máy học đều có ưu nhược điểm riêng, kể cả ML cơ bản lẫn FedML. FedML giải quyết các vấn đề của ML cơ bản, và chúng ta lại tiếp tục giải quyết các vấn đề của FedML. Vấn đề người ra người vào liên tục thì có chuyện gì ở đây là cấu hình của tập thiết bị sẽ thay đổi, chúng ta không thể kỳ vọng thiết bị mới vào sẽ lại có cấu hình và năng lực tương tự như các thiết bị đang có và đã bỏ ra. Và vấn đề là không chỉ năng lực không đồng bộ mà còn là những thiết bị mới tuyển vào có thể “lái” việc huấn luyện mô hình đi theo hướng mà chúng mong muốn. Tức là những thiết bị “xấu”: vào chỉ để ảnh hưởng xấu đến mô hình, hoặc vào một tí lại bỏ việc chả đóng góp gì cho việc học của mô hình, hoặc vào chỉ để nghe ngóng chứ không phải để đóng góp vào việc tính toán huấn luyện mô hình. Vấn đề liên lạc bất đồng bộ thì chủ yếu là giao tiếp giữa thiết bị và người điều phối: thiết bị do không đồng bộ nên có thể bắt người điều phối chờ. Thì nói chung 2 cái vấn đề này tôi nghĩ cũng là những vấn đề “muôn thuở” của FedML. Bây giờ cũng có nhiều hướng giải quyết. Vấn đề băng thông mô hình thì chủ yếu là tối ưu size của mô hình thì giờ cũng nhiều hướng giải quyết mở ra như Distillation, Prunning, Binary Neural Nets, Quantization, … Vấn đề frameworks thì cũng dần dần có những phát triển mới như PySyft4 hay Flower5. Flower là một frameworks hoàn thiện cho FedML với hỗ trợ dành cho cả PyTorch và Tensorflow. Khá nhiều thuật toán tối ưu hóa (optimization algorithms) dành cho FedML được implement. Các thuật toán tối ưu hóa được hỗ trợ trong Flower. Tôi nghĩ khi mới bắt đầu nghiên cứu theo hướng này, việc lên stack công nghệ cho giả lập là quan trọng. Trong đó việc sử dụng Flower kết hợp với AWS (sẽ nói trong mục tiếp theo) là một cách dễ dàng hơn để các bạn tiếp cận vấn đề mà ít mất công sức. Cài cắm thì khá đơn giản mà Flower cũng hỗ trợ hết các thư viện/frameworks nổi như HuggingFace6, Tensorflow3, PyTorch2, PyTorch-Lightning7, MXNet8, .v.v… Chọn những con đường khác cũng được nhưng mất công quá vào những việc ngoài mục tiêu nghiên cứu thì không nên. Đôi dòng về AWS SageMaker Nền tảng điện toán đám mây của Amazon Amazon Web Services (AWS) là tên một công ty con của Amazon chuyên về cung cấp các dịch vụ điện toán đám mây. Bắt đầu từ năm 2006, công ty hiện là nhà cung cấp hàng đầu trong mảng dịch vụ điện toán đám mây, bao gồm 3 nhóm dịch vụ điện toán đám mây chính: Infrastructure-as-a-Service (IaaS): tức là cung cấp người dùng hệ thống toàn quyền cấp phát khởi tạo và kiểm soát hệ thống điện toán đám mây. Người dùng nắm toàn quyền từ quản lý tài nguyên, ứng dụng, dữ liệu và kể cả các hệ điều hành. Một ví dụ đơn giản nhất là bạn viết một ứng dụng web và deploy lên EC2, sau đó dữ liệu được lưu vào Amazon RDS, file được lưu trữ trên S3. Một ví dụ đơn giản như vậy có thể thể hiện được tính năng IaaS của AWS. Platform-as-a-Service (PaaS): tức là người dùng không quan tâm tới các vấn đề bên dưới như phần cứng (vCPU/vGPU), phần mềm (hệ điều hành) của hệ thống điện toán đám mây, mà chỉ tập trung vào viết ứng dụng. Việc cấp phát và khởi tạo tài nguyên đủ để ứng dụng người dùng chạy được do nền tảng lo hết. Tất nhiên, người dùng có thể viết cấu hình đơn giản bằng YAML hoặc JSON. Ví dụ đơn giản nhất chính là SageMaker mà chúng ta đang nói đến. Thay vì bạn phải khởi tạo và lựa chọn cấu hình máy ảo, instance của EC2, rồi login vào để cài đặt hệ điều hành, các gói hệ thống, ứng dụng thì SageMaker sẽ đảm nhiệm hết cho bạn. Một ví dụ khác là Lambda, bạn chỉ cần tập trung viết Lambda function bằng Python, rồi việc khởi tạo tài nguyên cũng như đảm bảo cho hàm được chạy trơn chu (khi có lỗi log lại hoặc bắn vào dead queue) thì Lambda sẽ lo hết những việc bên dưới ấy. Software-as-a-Service (SaaS): tức là người dùng chỉ dùng ứng dụng, tương tác và quản lý dữ liệu ở tầng ứng dụng, chứ không can thiệp tận tầng infra hay platform, và đương nhiên cũng không cần code hàm. Một ví dụ đơn giản là GMail, hoặc các hệ thống quản lý quan hệ khách hàng (CRM). Đơn giản chỉ “dùng” thôi! Thì tại sao nên dùng PaaS như SageMaker? Lựa chọn loại hình điện toán đám mây còn phụ thuộc vào mục tiêu kinh doanh, cũng như yêu cầu khách hàng. Tuy nhiên, với một usecase đơn giản là bạn thực hiện một nghiên cứu máy học đơn thuần. Cũng chẳng có ai yêu cầu bạn phải làm product (ý tưởng nghiên cứu chưa có các thày review chẳng may nó có “độc” hoặc là vũ khí hạt nhân thì làm sao?), nên chắc chắn là đến khi được phép chuyển ý tưởng thành product là sẽ phải trải qua 1 thời gian dài, và rủi ro là không được phép làm ấy. Thế với rủi ro như vậy thì tư thế đúng nhất của người làm nghiên cứu là gì? Là phải lựa chọn con đường thoáng nhất mà đi, dễ thành công nhất mà đi. Thế bây giờ cùng nghĩ nhé, Nếu chọn SaaS thì nó có hết tính năng rồi, ông chỉ ngồi cấu hình thì không có ý tưởng mới thực sự -&gt; thế còn làm làm gì? Nếu chọn IaaS thì khối lượng công việc nó rất là lớn, không chỉ có viết code Flask đâu nhé. Ông còn phải ngồi ông cấu hình, rồi đủ kiểu, mà kể cả có làm được thì nhìn chung cũng … không xịn! Mà kể cả làm demo mà so sánh với PaaS hoặc SaaS mà thấy không sang xịn mịn thì … lượn còn gì nữa? Đấy thế thì tại sao lại phải bỏ công vào những thứ không đóng góp gì vào việc hình thành ý tưởng như IaaS? tại sao lại đâm đầu vào mấy cái cấu hình như SaaS, trong khi đó là việc của người dùng? Rốt cuộc là chỉ còn những giải pháp kiểu PaaS là hợp lý nhất: nhà nghiên cứu tập trung vào đúng phần có giá trị lõi, mà không phải lan man đi ra những chỗ vớ vẩn chả liên quan gì tới anh! Đấy nên là chọn PaaS là ông vẫn được ngồi viết vài dòng code (cần thiết nhất, chứ những code không cần thiết không phải viết dòng nào) gọi là code chơi, vừa nhâm nhi cà phê vừa viết. Còn phần cứng các cái hệ thống nó lo hết! Mà thế nó mới đúng, thế mới sang xịn mịn, đẳng cấp product, chất lượng ngang với thung lũng Silicon! Chứ giờ mà ngồi viết, kể cả thuê thợ code chất lượng nhất cái mảnh đất Đông Dương này, chắc cũng chỉ chất lượng tầm 30%. Mà đã không sang xịn mịn 100%, trong khi mục tiêu của mình là nghiên cứu thì mình cứ PaaS thôi! Một lý do nữa nên dùng PaaS, là ví dụ so sánh với IaaS là ông suốt ngày ngồi code kiếc, cấu hình, trong khi với PaaS, ông tiết kiệm thời gian ấy, dùng thời gian ấy để lên kế hoạch, tìm kiếm ý tưởng, khách hàng mới. Trong khi IaaS thì ông suốt ngày ngồi ỳ trước màn hình code, cái kiểu ấy là không ăn thua ở VN. Phải đi họp hành thảo luận, tìm kiếm ý tưởng, gặp mặt khách hàng, … Nên chắc chắn cũng không cần suy nghĩ nhiều, PaaS là chắc chắn, và trong đó AWS SageMaker là một trong những người dẫn đầu thị trường! Sơ lược về AWS SageMaker Amazon SageMaker helps data scientists and developers to prepare data and build, train, and deploy machine learning models quickly by bringing together purpose-built capabilities. These capabilities allow you to build highly accurate models that improve over time without all the undifferentiated heavy lifting of managing ML environments and infrastructure. Amazon SageMaker không chỉ đơn thuần là 1 nền tảng PaaS hỗ trợ training mô hình máy học, mà bên trong nền tảng này còn hàng chục những tính năng chờ người dùng khám phá: SageMaker Studio Notebooks SageMaker Processing SageMaker Training SageMaker Batch Transform RStudio on SageMaker SageMaker Data Wrangler SageMaker Real-Time Inference SageMaker Edge Manager SageMaker On-Demand Notebook Instances SageMaker Feature Store SageMaker Asynchronous Inference SageMaker Serverless Inference SageMaker Debugger SageMaker Clarify Dưới đây là 1 video giới thiệu ngắn về AWS SageMaker. Ví dụ triển khai FedML trên SageMaker Dưới đây là 1 ví dụ triển khai FedML trên AWS PaaS. Chúng ta sử dụng các dịch vụ sau: AWS Step Functions: đây chính là mô phỏng của người điều phối (co-ordinator) của chúng ta. Chúng ta sử dụng AWS::StepFunctions::StateMachine để mô phỏng vai trò của người điều phối. Đoạn mã YAML dưới đây mô tả cấu hình của người điều phối thực hiện phát tán thông số mô hình vào các mô phỏng thiết bị trên ECS/Fargate. Hãy chú ý đến trạng thái RunTask-FlowerCoordinator 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 StateMachine: Type: AWS::StepFunctions::StateMachine Properties: StateMachineName: !Join [&quot;&quot;, [!Ref ProjectTag, &quot;-StateMachine&quot;]] RoleArn: !GetAtt StateMachineTaskRole.Arn Tags: - Key: Project Value: !Ref ProjectTag Definition: Comment: Deploys flower-coordinator and flower-proxy ecs tasks StartAt: GetIotConfig States: GetIotConfig: Type: Parallel Next: IotConfigFound Branches: - StartAt: DescribeIotEndpoint States: DescribeIotEndpoint: Parameters: EndpointType: iot:Data-ATS Resource: arn:aws:states:::aws-sdk:iot:describeEndpoint ResultSelector: IotEndpointAddress.$: $.EndpointAddress Type: Task End: true - StartAt: GetDatasetNameParameter States: GetDatasetNameParameter: Parameters: Name: !Sub /${ProjectTag}/DatasetName Resource: arn:aws:states:::aws-sdk:ssm:getParameter ResultSelector: DatasetName.$: $.Parameter.Value Type: Task Next: GetDatasetContent GetDatasetContent: Parameters: DatasetName.$: $.DatasetName Resource: arn:aws:states:::aws-sdk:iotanalytics:getDatasetContent ResultSelector: DataURI.$: $.Entries[0].DataURI Type: Task Next: GetClientList GetClientList: Parameters: FunctionName: !Sub &quot;${GetDatasetContentLambda.Arn}:$LATEST&quot; Payload: DataURI.$: $.DataURI Resource: arn:aws:states:::lambda:invoke ResultSelector: ClientList.$: $.Payload.Payload Retry: - BackoffRate: 2 ErrorEquals: - Lambda.ServiceException - Lambda.AWSLambdaException - Lambda.SdkClientException IntervalSeconds: 2 MaxAttempts: 6 Type: Task End: true ResultSelector: ClientList.$: $[1].ClientList IotEndpointAddress.$: $[0].IotEndpointAddress CoordinatorTaskComplete: Choices: - And: - StringMatches: STOPPED Variable: $.Tasks[0].Containers[0].LastStatus - NumericEquals: 0 Variable: $.Tasks[0].Containers[0].ExitCode Next: Success - And: - StringMatches: STOPPED Variable: $.Tasks[0].Containers[0].LastStatus - Not: NumericEquals: 0 Variable: $.Tasks[0].Containers[0].ExitCode Next: Fail Default: WaitForCoordinatorTask Type: Choice IotConfigFound: Choices: - And: - Variable: $.ClientList IsPresent: true - Variable: $.ClientList[0] IsPresent: true - Variable: $.IotEndpointAddress IsPresent: true Next: RunTask-FlowerCoordinator Default: Fail Type: Choice DescribeCoordinatorTask: Type: Task Next: CoordinatorTaskComplete Parameters: Cluster: !GetAtt ECSCluster.Arn Tasks.$: States.Array($.CoordinatorTaskResult.taskArn) Resource: arn:aws:states:::aws-sdk:ecs:describeTasks MapGreenGrassClients: Type: Map Catch: - ErrorEquals: - States.TaskFailed Next: StopCoordinatorTask ResultPath: $.mapClientsResult Next: WaitForCoordinatorTask Iterator: StartAt: RunTask-FlowerProxy States: RunTask-FlowerProxy: Type: Task Resource: arn:aws:states:::ecs:runTask.sync Parameters: LaunchType: FARGATE Cluster: !GetAtt ECSCluster.Arn TaskDefinition: !Ref ProxyTaskDef NetworkConfiguration: AwsvpcConfiguration: SecurityGroups: - !GetAtt SGContainers.GroupId Subnets: - !Ref Subnet Overrides: ContainerOverrides: - Name: flower-proxy Environment: - Name: CLIENT Value.$: $.client - Name: ENDPOINT Value.$: $.endpoint - Name: COORDINATOR Value.$: $.coordinator - Name: TABLE Value: !Ref DDBTable - Name: BUCKET Value: !Ref ProxyBucket End: true ItemsPath: $.ClientList Parameters: coordinator.$: States.Format(&#39;{}:8080&#39;, $.CoordinatorTaskResult.ip) client.$: $$.Map.Item.Value endpoint.$: States.Format(&#39;https://{}&#39;, $.IotEndpointAddress) RunTask-FlowerCoordinator: Type: Task Resource: arn:aws:states:::ecs:runTask.waitForTaskToken HeartbeatSeconds: 600 Parameters: LaunchType: FARGATE Cluster: !GetAtt ECSCluster.Arn TaskDefinition: !Ref CoordinatorTaskDef Overrides: ContainerOverrides: - Name: flower-coordinator Environment: - Name: TASK_TOKEN Value.$: $$.Task.Token NetworkConfiguration: AwsvpcConfiguration: SecurityGroups: - !GetAtt SGContainers.GroupId Subnets: - !Ref Subnet Next: MapGreenGrassClients ResultPath: $.CoordinatorTaskResult StopCoordinatorTask: Type: Task Parameters: Task.$: $.CoordinatorTaskResult.taskArn Resource: arn:aws:states:::aws-sdk:ecs:stopTask Next: Fail WaitForCoordinatorTask: Next: DescribeCoordinatorTask Seconds: 60 Type: Wait Success: Type: Succeed Fail: Type: Fail AWS ECS/FarGate: được dùng để host container cho người điều phối và các thiết bị mô phỏng. Một đoạn mã server của người điều phối dùng Flower như sau: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 # Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved. # SPDX-License-Identifier: MIT-0 import flwr as fl import boto3 import os import requests import json import logging import sys # Setup logging to stdout logger = logging.getLogger(__name__) logging.basicConfig(stream=sys.stdout, level=logging.INFO) token = os.getenv(&#39;TASK_TOKEN&#39;) metadata_uri = os.getenv(&#39;ECS_CONTAINER_METADATA_URI_V4&#39;) token_response = &quot;&quot; if metadata_uri is not None: r = requests.get(f&quot;{metadata_uri}/task&quot;) task_meta = r.json() logger.info(f&quot;found task metadata: {task_meta}&quot;) token_response = json.dumps({ &quot;ip&quot;: task_meta[&#39;Containers&#39;][0][&#39;Networks&#39;][0][&#39;IPv4Addresses&#39;][0], &quot;taskArn&quot;: task_meta[&#39;TaskARN&#39;] }) if token is not None: stfn = boto3.client(&#39;stepfunctions&#39;) logger.info(f&quot;send_task_success - taskToken={token}, output={token_response}&quot;) stfn.send_task_success(taskToken=token, output=token_response) fl.server.start_server(config={&quot;num_rounds&quot;: 3}) Ngoài ra, chúng ta cũng sử dụng một proxy container có nhiệm vụ trung chuyển yêu cầu giữa người điều phối và các thiết bị. Proxy này cũng thực hiện lưu dữ liệu xuống S3: lý do cho việc này là do thông số mô hình có thể tới vài MB, nên lưu vào S3 để về sau thiết bị tự load lên thì hiệu quả hơn. AWS IoT GreenGrass: ở đây để quản lý giao tiếp giữa các thiết bị IoT với proxies. GG Streams được dùng để lưu dữ liệu vào S3 cũng như load mô hình từ S3 lên. AWS IoT Core kết nối thiết bị IoT với các dịch vụ điện toán đám mây như DynamoDB. AWS DynamoDB lưu trữ rules từ IoT core. AWS Lambda được triển khai lên thiết bị GreenGrass và thực hiện training trên thiết bị IoT. AWS S3 lưu trữ mô hình. Triển khai giải pháp FedML trên Amazon SageMaker Kết luận Nhìn chung, qua bài viết này, chúng ta đã nhìn thấy tiềm năng cũng như sự cần thiết của FedML trong ứng dụng máy học thực tế. So với ML cơ bản thì FedML giải quyết khá nhiều vấn đề thực tế như bảo mật và bảo vệ dữ liệu người dùng, cải thiện băng thông. Và FedML cũng có những vấn đề riêng đang trong giai đoạn nghiên cứu. Chúng ta cũng điểm qua ứng dụng PoC thực tế của FedML bằng AWS SageMaker. References Aledhari, M., Razzak, R., Parizi, R.M. and Saeed, F. 2020. Federated learning: A survey on enabling technologies, protocols, and applications. IEEE Access. 8, (2020), 140699–140725.Details Liu, Y., Yuan, X., Xiong, Z., Kang, J., Wang, X. and Niyato, D. 2020. Federated learning for 6G communications: Challenges, methods, and future directions. China Communications. 17, 9 (2020), 105–118.Details Khan, L.U., Saad, W., Han, Z., Hossain, E. and Hong, C.S. 2021. Federated learning for internet of things: Recent advances, taxonomy, and open challenges. IEEE Communications Surveys &amp; Tutorials. (2021).Details Kaissis, G.A., Makowski, M.R., Rückert, D. and Braren, R.F. 2020. Secure, privacy-preserving and federated machine learning in medical imaging. Nature Machine Intelligence. 2, 6 (2020), 305–311.Details Nguyen, D.C., Ding, M., Pathirana, P.N., Seneviratne, A., Li, J. and Poor, H.V. 2021. Federated learning for internet of things: A comprehensive survey. IEEE Communications Surveys &amp; Tutorials. (2021).Details Kaissis, G., Ziller, A., Passerat-Palmbach, J., Ryffel, T., Usynin, D., Trask, A., Lima, I., Mancuso, J., Jungmann, F., Steinborn, M.-M. and others 2021. End-to-end privacy preserving deep learning on multi-institutional medical imaging. Nature Machine Intelligence. 3, 6 (2021), 473–484.Details https://mqtt.org/ &#8617; https://pytorch.org/ &#8617; &#8617;2 https://www.tensorflow.org/ &#8617; &#8617;2 https://github.com/OpenMined/PySyft &#8617; https://flower.dev/ &#8617; https://huggingface.co/ &#8617; https://www.pytorchlightning.ai/ &#8617; https://mxnet.apache.org/versions/1.9.1/ &#8617;","headline":"Best practices for Federated Machine Learning (FedML) with Amazon Web Services (AWS)","image":"https://github.com/aws-samples/federated-learning-greengrass-ecs/raw/main/diagrams/overview.png","mainEntityOfPage":{"@type":"WebPage","@id":"/https://wanted2.github.io/federated-learning/"},"publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"/https://wanted2.github.io/assets/images/favicon.ico"},"name":"tuan"},"url":"/https://wanted2.github.io/federated-learning/"}</script>
<!-- End Jekyll SEO tag -->


<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous">
    
<link href="https://wanted2.github.io/assets/css/screen.css" rel="stylesheet">

<link href="https://wanted2.github.io/assets/css/main.css" rel="stylesheet">

<script src="https://wanted2.github.io/assets/js/jquery.min.js"></script>
<script src="https://kit.fontawesome.com/d0b91d895e.js" crossorigin="anonymous"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        processEscapes: true
    }
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript" crossorigin="anonymous"></script>
<script src="https://d3js.org/d3.v4.js" crossorigin="anonymous"></script>
<!-- <script src="https://bl.ocks.org/mbostock/raw/4061502/0a200ddf998aa75dfdb1ff32e16b680a15e5cb01/box.js" crossorigin="anonymous"></script> -->
</head>


<body class="layout-post">
	<!-- defer loading of font and font awesome -->
	<noscript id="deferred-styles">
		<link href="https://fonts.googleapis.com/css?family=Righteous%7CMerriweather:300,300i,400,400i,700,700i" rel="stylesheet">
		<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.13/css/all.css" integrity="sha384-DNOHZ68U8hZfKXOrtjWvjxusGo9WQnrNx2sqG0tfsghAvtVlRW3tvkXWZh58N9jp" crossorigin="anonymous">
	</noscript>


<!-- Begin Menu Navigation
================================================== -->
<nav class="navbar navbar-expand-lg navbar-light bg-white fixed-top mediumnavigation nav-down">

    <div class="container pr-0">

    <!-- Begin Logo -->
    <a class="navbar-brand" href="https://wanted2.github.io/">
    <img src="https://wanted2.github.io/assets/images/favicon.ico" alt="AiFi">
    </a>
    <!-- End Logo -->

    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarMediumish" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
    </button>

    <div class="collapse navbar-collapse" id="navbarMediumish">

        <!-- Begin Menu -->

            <ul class="navbar-nav ml-auto">

                
                <li class="nav-item">
                
                <a class="nav-link" href="https://wanted2.github.io/">Blog</a>
                </li>

                <li class="nav-item">
                <a class="nav-link" href="https://wanted2.github.io/about">About</a>
                </li>

                <li class="nav-item">
                <a class="nav-link" href="https://wanted2.github.io/projects">Projects</a>
                </li>

                <li class="nav-item">
                    <a class="nav-link" href="https://wanted2.github.io/service">Services</a>
                </li>

                <!-- <li class="nav-item">
                <a target="_blank" class="nav-link" href="https://bootstrapstarter.com/bootstrap-templates/template-mediumish-bootstrap-jekyll/"> Docs</a>
                </li>

                <li class="nav-item">
                <a target="_blank" class="nav-link" href="https://www.wowthemes.net/themes/mediumish-wordpress/"><i class="fab fa-wordpress-simple"></i> WP Version</a>
                </li>

                <li class="nav-item">
                <a target="_blank" class="nav-link" href="https://www.wowthemes.net/themes/mediumish-ghost/"><i class="fab fa-snapchat-ghost"></i> Ghost Version</a>
                </li>

                <li class="nav-item">
                <a target="_blank" class="nav-link" href="https://github.com/wowthemesnet/mediumish-theme-jekyll"><i class="fab fa-github"></i> Fork on Github</a>
                </li> -->

                <!-- <script src="https://wanted2.github.io/assets/js/lunr.js"></script>


<style>
    .lunrsearchresult .title {color: #d9230f;}
    .lunrsearchresult .url {color: silver;}
    .lunrsearchresult a {display: block; color: #777;}
    .lunrsearchresult a:hover, .lunrsearchresult a:focus {text-decoration: none;}
    .lunrsearchresult a:hover .title {text-decoration: underline;}
</style>


<form class="bd-search" onSubmit="return lunr_search(document.getElementById('lunrsearch').value);">
    <input type="text" class="form-control text-small launch-modal-search" id="lunrsearch" name="q" maxlength="255" value="" placeholder="Type and enter..."/>
</form>

<div id="lunrsearchresults">
    <ul></ul>
</div>

<script src="https://wanted2.github.io/assets/js/lunrsearchengine.js"></script> -->

            </ul>

        <!-- End Menu -->

    </div>

    </div>
</nav>
<!-- End Navigation
================================================== -->

<div class="site-content">

<div class="container">

<!-- Site Title
================================================== -->
<div class="mainheading">
    <h1 class="sitetitle">AiFi</h1>
    <p class="lead">
        An AI Researcher's blog (This is a staging site, so the content may be imprecise, refer to official AiFi)
    </p>
</div>

<!-- Content
================================================== -->
<div class="main-content">
    <!-- Begin Article
================================================== -->
<div class="container">
    <div class="row">

        <!-- Post Share -->
        <div class="col-md-2 pl-0">
            <div class="share sticky-top sticky-top-offset">
    <p>
        Share
    </p>
    <ul>
        <li class="ml-1 mr-1">
            <a target="_blank" href="https://twitter.com/intent/tweet?text=Best practices for Federated Machine Learning (FedML) with Amazon Web Services (AWS)&url=https://wanted2.github.io/federated-learning/" onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
                <i class="fab fa-twitter"></i>
            </a>
        </li>

        <li class="ml-1 mr-1">
            <a target="_blank" href="https://facebook.com/sharer.php?u=https://wanted2.github.io/federated-learning/" onclick="window.open(this.href, 'facebook-share', 'width=550,height=435');return false;">
                <i class="fab fa-facebook-f"></i>
            </a>
        </li>

        <li class="ml-1 mr-1">
            <a target="_blank" href="https://www.linkedin.com/shareArticle?mini=true&url=https://wanted2.github.io/federated-learning/" onclick="window.open(this.href, 'width=550,height=435');return false;">
                <i class="fab fa-linkedin-in"></i>
            </a>
        </li>

        <li class="ml-1 mr-1">
            <a target="_blank" href="mailto:?subject=Best practices for Federated Machine Learning (FedML) with Amazon Web Services (AWS)&body=https://wanted2.github.io/federated-learning/" onclick="window.open(this.href, 'width=550,height=435');return false;">
                <i class="fas fa-envelope"></i>
            </a>
        </li>

    </ul>
    
    <div class="sep">
    </div>
    <ul>
        <li>
        <a class="small smoothscroll" href="#disqus_thread"></a>
        </li>
    </ul>
    
    
    <div class="sep">

    </div>
    <ul>
        <li class="small">
        4986
     words</li>
        <li class="small">27 minutes</li>
    </ul>
</div>

        </div>

        <!-- Post -->
        

        <div class="col-md-9 flex-first flex-md-unordered">
            <div class="mainheading">

                <!-- Author Box -->
                
                <div class="row post-top-meta">
                    <div class="col-xs-12 col-md-2 col-lg-2 text-left mb-4 mb-md-0">
                        
                        <img class="author-thumb" src="https://wanted2.github.io/assets/images/favicon.png" alt="AiFi">
                        
                    </div>
                    <div class="col-xs-12 col-md-10 col-lg-10 text-right">
                        <a target="_blank" class="link-dark" href="">AiFi</a>
                        <!-- <a target="_blank" href="" class="btn follow">Follow</a> -->
                        <!-- LikeBtn.com BEGIN -->
                        <span class="likebtn-wrapper" 
                            data-site_id=""
                            data-theme="custom" 
                            data-icon_l_url="/assets/images/OK_EM.png" 
                            data-icon_l_url_v="/assets/images/OK_EM_clicked.png" 
                            data-identifier="/federated-learning/" 
                            data-show_like_label="false" 
                            data-like_enabled="false" 
                            data-dislike_enabled="false" 
                            data-icon_dislike_show="false" 
                            data-voting_cancelable="false" 
                            data-counter_show="true"
                            data-counter_frmt="comma"></span>
                        <script>(function(d,e,s){if(d.getElementById("likebtn_wjs"))return;a=d.createElement(e);m=d.getElementsByTagName(e)[0];a.async=1;a.id="likebtn_wjs";a.src=s;m.parentNode.insertBefore(a, m)})(document,"script","//w.likebtn.com/js/w/widget.js");</script>
                        <!-- LikeBtn.com END -->
                        <span class="author-description"></span>
                    </div>
                </div>
                

                <!-- Post Title -->
                <h1 class="posttitle">Best practices for Federated Machine Learning (FedML) with Amazon Web Services (AWS)</h1>

            </div>

            <!-- Adsense if enabled from _config.yml (change your pub id and slot) -->
            
            <!-- End Adsense -->

            <!-- Post Featured Image -->
            

            
            <img class="featured-image img-fluid lazyimg" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAMAAAACCAQAAAA3fa6RAAAADklEQVR42mNkAANGCAUAACMAA2w/AMgAAAAASUVORK5CYII=" data-src="https://github.com/aws-samples/federated-learning-greengrass-ecs/raw/main/diagrams/overview.png" alt="Best practices for Federated Machine Learning (FedML) with Amazon Web Services (AWS)">
            

            
            <!-- End Featured Image -->

            <!-- Post Content -->
            <div class="article-post">
                <!-- Toc if any -->
                
                    
                    <div class="toc mt-4 mb-4 lead">
                        <h3 class="font-weight-bold">Summary</h3>
                        <ul>
  <li><a href="#giới-thiệu-về-fedml">Giới thiệu về FedML</a>
    <ul>
      <li><a href="#machine-learning-truyền-thống-vs-fedml">Machine Learning truyền thống vs. FedML</a></li>
      <li><a href="#ưu-nhược-điểm-của-fedml">Ưu nhược điểm của FedML</a></li>
    </ul>
  </li>
  <li><a href="#đôi-dòng-về-aws-sagemaker">Đôi dòng về AWS SageMaker</a>
    <ul>
      <li><a href="#nền-tảng-điện-toán-đám-mây-của-amazon">Nền tảng điện toán đám mây của Amazon</a></li>
      <li><a href="#sơ-lược-về-aws-sagemaker">Sơ lược về AWS SageMaker</a></li>
    </ul>
  </li>
  <li><a href="#ví-dụ-triển-khai-fedml-trên-sagemaker">Ví dụ triển khai FedML trên SageMaker</a></li>
  <li><a href="#kết-luận">Kết luận</a></li>
  <li><a href="#references">References</a></li>
</ul>
                    </div>
                
                <!-- End Toc -->
                <blockquote>
  <p>Federated learning (FL) is a machine learning (ML) scenario with two distinct characteristics. First, training occurs on multiple machines. Second, each machine involved in training keeps training data locally; the only information shared between machines is the ML model and its parameters. FL solves challenges related to data privacy and scalability in scenarios such as mobile devices and IoT.</p>
</blockquote>

<blockquote>
  <p>By Amazon Web Service (AWS)</p>
</blockquote>

<p>Theo định nghĩa của AWS, thì Federated Machine Learning (FedML) là một hình thức (scenario) máy học có 2 đặc trưng nổi bật là: 1. quá trình học diễn ra trên <strong>nhiều máy</strong>.; 2. mỗi máy thực hiện học (training) sẽ <strong>giữ kín</strong> dữ liệu training ở local; dữ liệu duy nhất mà các máy chia sẻ với nhau chỉ là mô hình (model) máy học và các thông số model (parameters).
Các bạn có thể thấy nếu chỉ có 1. thì FedML chỉ đơn giản là distributed learning (học phân tán) ra nhiều máy thiết bị, cái đặc trưng không kém phần quan trọng của FedML là 2. giấu kín dữ liệu của từng máy, tức là <strong>không có chuyện chia sẻ dữ liệu người dùng, và vì vậy nên tính bảo mật và tuân thủ privacy cao hơn</strong>.
Ngoài ra vì chỉ chia sẻ một “ít” dữ liệu là thông số mô hình nên độ ngốn băng thông là thấp, dẫn đến FedML là 1 hình thức học đang trở nên dần nhận được nhiều sự quan tâm.
Tuy nhiên, học đi đôi với hành, nên chúng ta cũng sẽ lấy ví dụ về FedML trong thực tế qua một ví dụ triển khai trên AWS SageMaker.</p>

<h1 id="giới-thiệu-về-fedml">Giới thiệu về FedML</h1>

<h2 id="machine-learning-truyền-thống-vs-fedml">Machine Learning truyền thống vs. FedML</h2>

<p>ML truyền thống (hay là Machine Learning cơ bản) thì chủ yếu dựa vào nguồn dữ liệu, kiến trúc mô hình và thuật toán máy học cơ bản (xem hình dưới).
Định nghĩa lý thuyết của ML tôi xin phép không bàn tới, mà điểm focus của bài viết là từ góc nhìn kỹ thuật, kiến trúc vận hành thực tế của ML.</p>

<p><img src="https://d2908q01vomqb2.cloudfront.net/fc074d501302eb2b93e2554793fcaf50b3bf7291/2021/12/08/Fig1-1.png" alt="" />
<em>Machine Learning cơ bản</em></p>

<p>Các bạn có thể thấy ngay, với kiến trúc ML cơ bản như trên, dữ liệu học (training data) sẽ được gửi về <strong>1 địa điểm tập trung</strong> để thực hiện quá trình học.
Và đây chính là vấn đề: <strong>việc gửi dữ liệu qua đường truyền mạng sẽ có khá nhiều vấn đề về tuân thủ dữ liệu người dùng cũng như bảo mật</strong>.
Ngoài ra, cái gọi là <strong><em>địa điểm tập trung</em></strong> ấy cũng có vấn đề: nếu địa điểm đó nằm ngoài phạm vi đất nước, tức là dữ liệu người dùng 1 quốc gia, ví dụ như Việt Nam, sẽ bị gửi sang 1 server ở Trung Quốc?
Các bạn thấy đấy, ML cơ bản có khá nhiều giới hạn và vấn đề, đòi hỏi researcher lẫn kỹ sư máy học phải có sự cân nhắc kỹ càng khi thiết kế triển khai vận hành 1 hệ thống ML cơ bản.
Ngoài ra, nhu cầu về bảo mật dữ liệu cấp công nghiệp ngày càng cao, dẫn đến các hệ thống ML cơ bản chỉ dừng ở mức độ lý thuyết chứ khó triển khai vào sản phẩm thực tế.
Khi triển khai vận hành vào sản phẩm thực tế, chúng ta cần 1 mô hình kiến trúc học tối tân hơn, và đó chính là lúc chúng ta cần FedML.</p>

<p><strong>FedML</strong> <a class="citation" href="#aledhari2020federated">[1, 2, 3, 4, 5, 6]</a> giải quyết một phát cả 2 vấn đề trên, thậm chí còn cải thiện cả băng thông (vì không phải chia sẻ data nữa).
Dưới đây là biểu đồ luồng thông tin của 1 hệ thống FedML (cũng cơ bản thôi).</p>

<p><img src="https://d2908q01vomqb2.cloudfront.net/fc074d501302eb2b93e2554793fcaf50b3bf7291/2021/12/08/Fig2-2.png" alt="" />
<em>FedML</em></p>

<p>Luồng FedML ở trên đây có 2 nhóm thiết bị chính: <strong>devices (thiết bị) và coordinators (người điều phối)</strong>.
Devices có thể là các thiết bị IoT, smartphones, sensors, PCs, .v.v…
<strong>Người điều phối (co-ordinator)</strong> là nhóm những servers thực hiện aggregate thông số mô hình và phát tán cho các thiết bị.</p>

<p><em>Chú ý: <strong>Người điều phối không cần truy cập hay tiếp xúc với dữ liệu</strong>, việc duy nhất của người điều phối là phát tán mô hình (bao gồm cả thông số), nhận mô hình được train ở các thiết bị local và aggregate.</em></p>

<p>Người điều phối cũng không train gì cả, mà đó là việc của thiết bị (devices).
Thiết bị cũng thu thập dữ liệu luôn, và người điều phối cũng không cần quan tâm tới dữ liệu ở local của thiết bị.
Luồng xử lý của FedML cơ bản bao gồm:</p>

<ol>
  <li><strong>Người điều phối gửi dữ liệu mô hình đến các thiết bị để khởi tạo mô hình trên từng thiết bị</strong>. Về cơ bản, ở bước này, mô hình ở mọi thiết bị sẽ là đồng bộ.</li>
  <li>Khi các thiết bị đã “sẵn sàng”, <strong>người điều phối gửi tín hiệu bắt đầu train</strong>. Sau hiệu lệnh này, các thiết bị bắt đầu chuyển sang trạng thái training, tức là bắt đầu thu thập dữ liệu và cập nhật thông số mô hình.</li>
  <li>Việc train được các thiết bị thực hiện với dữ liệu được thu thập ở local <strong>và không chia sẻ đi đâu cả.</strong> Bộ dữ liệu local có thể có sẵn (và được cung cấp bởi bên thứ 3), hoặc có thể được thu thập online (ví dụ như camera giao thông).</li>
  <li>Khi việc học (train) kết thúc, các <strong>thiết bị tổng hợp dữ liệu mô hình</strong> (thông số và trọng số weights) để <strong>gửi về cho người điều phối</strong>. Ở đây có vấn đề là độ trễ giữa các thiết bị, nên người điều phối có thể xem xét để thực hiện bước tiếp theo khi chờ đủ khoảng bao nhiều % mô hình chứ không nhất thiết chờ tới 100%.</li>
  <li><strong>Người điều phối thực hiện thuật toán aggregate các thông tin mô hình được gửi về từ các thiết bị local</strong>. Thuật toán đơn giản nhất là <em>FedAvg</em> tức là đơn thuần là lấy trung bình mọi thông số làm thông số mới.</li>
  <li>Quay lại 1. tức là lại phát tán lại thông số mô hình cho các thiết bị.</li>
</ol>

<p>Vai trò của người điều phối tưởng đơn giản nhưng lại khá quan trọng.
Thường thì sẽ phải kết hợp với <em>weight monitoring</em> tức là giám sát trọng số, phát hiện trọng số bất thường, …</p>

<h2 id="ưu-nhược-điểm-của-fedml">Ưu nhược điểm của FedML</h2>

<ul>
  <li><strong>Ưu điểm</strong>
    <ul>
      <li>Nâng cao tính bảo mật, bảo vệ dữ liệu người dùng tốt hơn.</li>
      <li>Cải thiện băng thông dữ liệu.</li>
    </ul>
  </li>
  <li><strong>Nhược điểm</strong>
    <ul>
      <li><strong>Tính bất định trong tập thiết bị</strong>: số lượng thiết bị lên tới hàng triệu, chục triệu và bất cứ lúc nào cũng có thiết bị thêm vào hoặc bỏ ra. Nói nôm na là <em>người ra người vào liên tục</em>.</li>
      <li><strong>Liên lạc bất đồng bộ</strong>: các thiết bị giao tiếp với người điều phối thông qua giao thức bất đồng bộ (dựa trên pub/sub messaging) như MQTT<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote" rel="footnote">1</a></sup>. Ví dụ như khi người điều phối muốn yêu cầu các thiết bị nộp thông số mô hình, thì call đó có thể không đồng bộ và xuất hiện độ trễ. Như đã nói ở trên, nếu chờ hết 100% thiết bị nộp bài sẽ rất lâu, người điều phối có thể phải set timeout.</li>
      <li><strong>Băng thông mô hình</strong>: mặc dù việc không phải truyền tải dữ liệu là đã tiết kiệm rất lớn băng thông, dữ liệu mô hình vẫn có thể từ vài MB tới vài trăm MB/lần.</li>
      <li><strong>Frameworks</strong>: cái này cũng là vấn đề vì những framework máy học truyền thống như PyTorch<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">2</a></sup> hay Tensorflow<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">3</a></sup> vẫn chưa chịu hỗ trợ FedML tối đa. Phần lớn các framework này vẫn đang dừng ở mức hỗ trợ EdgeML hơn là FedML.</li>
    </ul>
  </li>
</ul>

<p>Mọi kiến trúc máy học đều có ưu nhược điểm riêng, kể cả ML cơ bản lẫn FedML.
FedML giải quyết các vấn đề của ML cơ bản, và chúng ta lại tiếp tục giải quyết các vấn đề của FedML.</p>

<p>Vấn đề <strong><em>người ra người vào liên tục</em></strong> thì có chuyện gì ở đây là cấu hình của tập thiết bị sẽ thay đổi, chúng ta không thể kỳ vọng thiết bị mới vào sẽ lại có cấu hình và năng lực tương tự như các thiết bị đang có và đã bỏ ra.
Và vấn đề là không chỉ năng lực không đồng bộ mà còn là những thiết bị mới tuyển vào có thể “lái” việc huấn luyện mô hình đi theo hướng mà chúng mong muốn.
Tức là những thiết bị “xấu”: vào chỉ để ảnh hưởng xấu đến mô hình, hoặc vào một tí lại bỏ việc chả đóng góp gì cho việc học của mô hình, hoặc vào chỉ để nghe ngóng chứ không phải để đóng góp vào việc tính toán huấn luyện mô hình.
Vấn đề <strong><em>liên lạc bất đồng bộ</em></strong> thì chủ yếu là giao tiếp giữa thiết bị và người điều phối: thiết bị do không đồng bộ nên có thể bắt người điều phối chờ.
Thì nói chung 2 cái vấn đề này tôi nghĩ cũng là những vấn đề “muôn thuở” của FedML.
Bây giờ cũng có nhiều hướng giải quyết.</p>

<p>Vấn đề <strong><em>băng thông mô hình</em></strong> thì chủ yếu là tối ưu size của mô hình thì giờ cũng nhiều hướng giải quyết mở ra như Distillation, Prunning, Binary Neural Nets, Quantization, …</p>

<p>Vấn đề <strong><em>frameworks</em></strong> thì cũng dần dần có những phát triển mới như PySyft<sup id="fnref:4" role="doc-noteref"><a href="#fn:4" class="footnote" rel="footnote">4</a></sup> hay Flower<sup id="fnref:5" role="doc-noteref"><a href="#fn:5" class="footnote" rel="footnote">5</a></sup>.
Flower là một frameworks hoàn thiện cho FedML với hỗ trợ dành cho cả PyTorch và Tensorflow.
Khá nhiều thuật toán tối ưu hóa (optimization algorithms) dành cho FedML được implement.</p>

<p><img src="/assets/images/flower-update-algo.png" alt="" />
<em>Các thuật toán tối ưu hóa được hỗ trợ trong Flower.</em></p>

<p>Tôi nghĩ khi mới bắt đầu nghiên cứu theo hướng này, việc lên stack công nghệ cho giả lập là quan trọng.
Trong đó việc sử dụng Flower kết hợp với AWS (sẽ nói trong mục tiếp theo) là một cách dễ dàng hơn để các bạn tiếp cận vấn đề mà ít mất công sức.
Cài cắm thì khá đơn giản mà Flower cũng hỗ trợ hết các thư viện/frameworks nổi như HuggingFace<sup id="fnref:8" role="doc-noteref"><a href="#fn:8" class="footnote" rel="footnote">6</a></sup>, Tensorflow<sup id="fnref:2:1" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">3</a></sup>, PyTorch<sup id="fnref:1:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">2</a></sup>, PyTorch-Lightning<sup id="fnref:6" role="doc-noteref"><a href="#fn:6" class="footnote" rel="footnote">7</a></sup>, MXNet<sup id="fnref:7" role="doc-noteref"><a href="#fn:7" class="footnote" rel="footnote">8</a></sup>, .v.v…
Chọn những con đường khác cũng được nhưng mất công quá vào những việc ngoài mục tiêu nghiên cứu thì không nên.</p>

<h1 id="đôi-dòng-về-aws-sagemaker">Đôi dòng về AWS SageMaker</h1>

<h2 id="nền-tảng-điện-toán-đám-mây-của-amazon">Nền tảng điện toán đám mây của Amazon</h2>
<p>Amazon Web Services (AWS) là tên một công ty con của Amazon chuyên về cung cấp các dịch vụ điện toán đám mây.
Bắt đầu từ năm 2006, công ty hiện là nhà cung cấp hàng đầu trong mảng dịch vụ điện toán đám mây, bao gồm 3 nhóm dịch vụ điện toán đám mây chính:</p>

<ul>
  <li><strong>Infrastructure-as-a-Service (IaaS)</strong>: tức là cung cấp người dùng hệ thống toàn quyền cấp phát khởi tạo và kiểm soát hệ thống điện toán đám mây. Người dùng nắm toàn quyền từ quản lý tài nguyên, ứng dụng, dữ liệu và kể cả các hệ điều hành. Một ví dụ đơn giản nhất là bạn viết một ứng dụng web và deploy lên EC2, sau đó dữ liệu được lưu vào Amazon RDS, file được lưu trữ trên S3. Một ví dụ đơn giản như vậy có thể thể hiện được tính năng IaaS của AWS.</li>
  <li><strong>Platform-as-a-Service (PaaS)</strong>: tức là người dùng không quan tâm tới các vấn đề bên dưới như phần cứng (vCPU/vGPU), phần mềm (hệ điều hành) của hệ thống điện toán đám mây, mà chỉ tập trung vào viết ứng dụng. Việc cấp phát và khởi tạo tài nguyên đủ để ứng dụng người dùng chạy được do nền tảng lo hết. Tất nhiên, người dùng có thể viết cấu hình đơn giản bằng YAML hoặc JSON. Ví dụ đơn giản nhất chính là SageMaker mà chúng ta đang nói đến. Thay vì bạn phải khởi tạo và lựa chọn cấu hình máy ảo, instance của EC2, rồi login vào để cài đặt hệ điều hành, các gói hệ thống, ứng dụng thì SageMaker sẽ đảm nhiệm hết cho bạn. Một ví dụ khác là Lambda, bạn chỉ cần tập trung viết Lambda function bằng Python, rồi việc khởi tạo tài nguyên cũng như đảm bảo cho hàm được chạy trơn chu (khi có lỗi log lại hoặc bắn vào dead queue) thì Lambda sẽ lo hết những việc bên dưới ấy.</li>
  <li><strong>Software-as-a-Service (SaaS)</strong>: tức là người dùng chỉ dùng ứng dụng, tương tác và quản lý dữ liệu ở tầng ứng dụng, chứ không can thiệp tận tầng infra hay platform, và đương nhiên cũng không cần code hàm. Một ví dụ đơn giản là GMail, hoặc các hệ thống quản lý quan hệ khách hàng (CRM). Đơn giản chỉ “dùng” thôi!</li>
</ul>

<p><strong><em>Thì tại sao nên dùng PaaS như SageMaker?</em></strong> Lựa chọn loại hình điện toán đám mây còn phụ thuộc vào mục tiêu kinh doanh, cũng như yêu cầu khách hàng. Tuy nhiên, với một usecase đơn giản là bạn thực hiện một nghiên cứu máy học đơn thuần. Cũng chẳng có ai yêu cầu bạn phải làm product (ý tưởng nghiên cứu chưa có các thày review chẳng may nó có “độc” hoặc là vũ khí hạt nhân thì làm sao?), nên chắc chắn là đến khi <strong>được phép chuyển ý tưởng thành product</strong> là sẽ phải trải qua 1 thời gian dài, và <strong>rủi ro</strong> là không được phép làm ấy. Thế với rủi ro như vậy thì <strong>tư thế đúng nhất của người làm nghiên cứu là gì?</strong> Là phải lựa chọn con đường <strong>thoáng nhất mà đi, dễ thành công nhất mà đi</strong>.
Thế bây giờ cùng nghĩ nhé,</p>

<ul>
  <li>Nếu chọn <strong>SaaS</strong> thì nó có hết tính năng rồi, ông chỉ ngồi cấu hình thì không có ý tưởng mới thực sự -&gt; thế còn làm làm gì?</li>
  <li>Nếu chọn <strong>IaaS</strong> thì khối lượng công việc nó rất là lớn, <strong>không chỉ có viết code Flask đâu nhé</strong>. Ông còn phải ngồi ông cấu hình, rồi đủ kiểu, mà kể cả có làm được thì nhìn chung cũng … không xịn! Mà kể cả làm demo mà so sánh với PaaS hoặc SaaS mà thấy không <strong>sang xịn mịn</strong> thì … lượn còn gì nữa?</li>
</ul>

<p>Đấy thế thì tại sao lại phải bỏ công vào những thứ không đóng góp gì vào việc hình thành ý tưởng như IaaS? tại sao lại đâm đầu vào mấy cái cấu hình như SaaS, trong khi đó là việc của người dùng?
Rốt cuộc là chỉ còn những giải pháp kiểu <strong>PaaS</strong> là hợp lý nhất: nhà nghiên cứu tập trung vào đúng phần có giá trị <strong>lõi</strong>, mà không phải lan man đi ra những chỗ vớ vẩn chả liên quan gì tới anh!</p>

<p>Đấy nên là chọn PaaS là ông vẫn được ngồi viết vài dòng code (cần thiết nhất, chứ những code không cần thiết không phải viết dòng nào) gọi là code chơi, vừa nhâm nhi cà phê vừa viết. Còn phần cứng các cái hệ thống nó lo hết! <strong>Mà thế nó mới đúng, thế mới sang xịn mịn, đẳng cấp product, chất lượng ngang với thung lũng Silicon</strong>! Chứ giờ mà ngồi viết, kể cả thuê thợ code chất lượng nhất cái mảnh đất Đông Dương này, chắc cũng chỉ chất lượng tầm 30%. Mà đã không sang xịn mịn 100%, trong khi mục tiêu của mình là nghiên cứu thì mình cứ PaaS thôi!</p>

<p>Một lý do nữa nên dùng PaaS, là ví dụ so sánh với IaaS là ông suốt ngày ngồi code kiếc, cấu hình, trong khi với PaaS, ông tiết kiệm thời gian ấy, <strong>dùng thời gian ấy để lên kế hoạch, tìm kiếm ý tưởng, khách hàng mới.</strong> Trong khi IaaS thì ông suốt ngày ngồi ỳ trước màn hình code, cái kiểu ấy là không ăn thua ở VN. Phải đi họp hành thảo luận, tìm kiếm ý tưởng, gặp mặt khách hàng, …</p>

<p>Nên chắc chắn cũng không cần suy nghĩ nhiều, PaaS là chắc chắn, và trong đó AWS SageMaker là một trong những người dẫn đầu thị trường!</p>

<h2 id="sơ-lược-về-aws-sagemaker">Sơ lược về AWS SageMaker</h2>

<blockquote>
  <p>Amazon SageMaker helps data scientists and developers to prepare data and build, train, and deploy
machine learning models quickly by bringing together purpose-built capabilities.
These capabilities allow you to build highly accurate models that improve over time
without all the undifferentiated heavy lifting of managing ML environments and infrastructure.</p>
</blockquote>

<p>Amazon SageMaker không chỉ đơn thuần là 1 nền tảng PaaS hỗ trợ training mô hình máy học, mà bên trong nền tảng này còn hàng chục những tính năng chờ người dùng khám phá:</p>

<ul>
  <li><strong>SageMaker Studio Notebooks</strong></li>
  <li><strong>SageMaker Processing</strong></li>
  <li><strong>SageMaker Training</strong></li>
  <li><strong>SageMaker Batch Transform</strong></li>
  <li><strong>RStudio on SageMaker</strong></li>
  <li><strong>SageMaker Data Wrangler</strong></li>
  <li><strong>SageMaker Real-Time Inference</strong></li>
  <li><strong>SageMaker Edge Manager</strong></li>
  <li><strong>SageMaker On-Demand Notebook Instances</strong></li>
  <li><strong>SageMaker Feature Store</strong></li>
  <li><strong>SageMaker Asynchronous Inference</strong></li>
  <li><strong>SageMaker Serverless Inference</strong></li>
  <li><strong>SageMaker Debugger</strong></li>
  <li><strong>SageMaker Clarify</strong></li>
</ul>

<p>Dưới đây là 1 video giới thiệu ngắn về AWS SageMaker.</p>

<iframe width="100%" height="315" src="https://www.youtube.com/embed/Qv_Tr_BCFCQ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<h1 id="ví-dụ-triển-khai-fedml-trên-sagemaker">Ví dụ triển khai FedML trên SageMaker</h1>

<p>Dưới đây là 1 ví dụ triển khai FedML trên AWS PaaS.
Chúng ta sử dụng các dịch vụ sau:</p>
<ul>
  <li><strong>AWS Step Functions</strong>: đây chính là mô phỏng của <strong>người điều phối (co-ordinator)</strong> của chúng ta.
Chúng ta sử dụng <code class="language-plaintext highlighter-rouge">AWS::StepFunctions::StateMachine</code> để mô phỏng vai trò của người điều phối.
Đoạn mã YAML dưới đây mô tả cấu hình của người điều phối thực hiện phát tán thông số mô hình vào các mô phỏng thiết bị trên ECS/Fargate.
Hãy chú ý đến trạng thái <code class="language-plaintext highlighter-rouge">RunTask-FlowerCoordinator</code></li>
</ul>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
</pre></td><td class="rouge-code"><pre><span class="na">StateMachine</span><span class="pi">:</span>
    <span class="na">Type</span><span class="pi">:</span> <span class="s">AWS::StepFunctions::StateMachine</span>
    <span class="na">Properties</span><span class="pi">:</span>
      <span class="na">StateMachineName</span><span class="pi">:</span> <span class="kt">!Join</span> <span class="pi">[</span><span class="s2">"</span><span class="s">"</span><span class="pi">,</span> <span class="pi">[</span><span class="kt">!Ref</span> <span class="nv">ProjectTag</span><span class="pi">,</span> <span class="s2">"</span><span class="s">-StateMachine"</span><span class="pi">]]</span>
      <span class="na">RoleArn</span><span class="pi">:</span> <span class="kt">!GetAtt</span> <span class="s">StateMachineTaskRole.Arn</span>
      <span class="na">Tags</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">Key</span><span class="pi">:</span> <span class="s">Project</span>
          <span class="na">Value</span><span class="pi">:</span> <span class="kt">!Ref</span> <span class="s">ProjectTag</span>
      <span class="na">Definition</span><span class="pi">:</span>
        <span class="na">Comment</span><span class="pi">:</span> <span class="s">Deploys flower-coordinator and flower-proxy ecs tasks</span>
        <span class="na">StartAt</span><span class="pi">:</span> <span class="s">GetIotConfig</span>
        <span class="na">States</span><span class="pi">:</span>
          <span class="na">GetIotConfig</span><span class="pi">:</span>
            <span class="na">Type</span><span class="pi">:</span> <span class="s">Parallel</span>
            <span class="na">Next</span><span class="pi">:</span> <span class="s">IotConfigFound</span>
            <span class="na">Branches</span><span class="pi">:</span>
              <span class="pi">-</span> <span class="na">StartAt</span><span class="pi">:</span> <span class="s">DescribeIotEndpoint</span>
                <span class="na">States</span><span class="pi">:</span>
                  <span class="na">DescribeIotEndpoint</span><span class="pi">:</span>
                    <span class="na">Parameters</span><span class="pi">:</span>
                      <span class="na">EndpointType</span><span class="pi">:</span> <span class="s">iot:Data-ATS</span>
                    <span class="na">Resource</span><span class="pi">:</span> <span class="s">arn:aws:states:::aws-sdk:iot:describeEndpoint</span>
                    <span class="na">ResultSelector</span><span class="pi">:</span>
                      <span class="na">IotEndpointAddress.$</span><span class="pi">:</span> <span class="s">$.EndpointAddress</span>
                    <span class="na">Type</span><span class="pi">:</span> <span class="s">Task</span>
                    <span class="na">End</span><span class="pi">:</span> <span class="no">true</span>
              <span class="pi">-</span> <span class="na">StartAt</span><span class="pi">:</span> <span class="s">GetDatasetNameParameter</span>
                <span class="na">States</span><span class="pi">:</span>
                  <span class="na">GetDatasetNameParameter</span><span class="pi">:</span>
                    <span class="na">Parameters</span><span class="pi">:</span>
                      <span class="na">Name</span><span class="pi">:</span> <span class="kt">!Sub</span> <span class="s">/${ProjectTag}/DatasetName</span>
                    <span class="na">Resource</span><span class="pi">:</span> <span class="s">arn:aws:states:::aws-sdk:ssm:getParameter</span>
                    <span class="na">ResultSelector</span><span class="pi">:</span>
                      <span class="na">DatasetName.$</span><span class="pi">:</span> <span class="s">$.Parameter.Value</span>
                    <span class="na">Type</span><span class="pi">:</span> <span class="s">Task</span>
                    <span class="na">Next</span><span class="pi">:</span> <span class="s">GetDatasetContent</span>
                  <span class="na">GetDatasetContent</span><span class="pi">:</span>
                    <span class="na">Parameters</span><span class="pi">:</span>
                      <span class="na">DatasetName.$</span><span class="pi">:</span> <span class="s">$.DatasetName</span>
                    <span class="na">Resource</span><span class="pi">:</span> <span class="s">arn:aws:states:::aws-sdk:iotanalytics:getDatasetContent</span>
                    <span class="na">ResultSelector</span><span class="pi">:</span>
                      <span class="na">DataURI.$</span><span class="pi">:</span> <span class="s">$.Entries[0].DataURI</span>
                    <span class="na">Type</span><span class="pi">:</span> <span class="s">Task</span>
                    <span class="na">Next</span><span class="pi">:</span> <span class="s">GetClientList</span>
                  <span class="na">GetClientList</span><span class="pi">:</span>
                    <span class="na">Parameters</span><span class="pi">:</span>
                      <span class="na">FunctionName</span><span class="pi">:</span> <span class="kt">!Sub</span> <span class="s2">"</span><span class="s">${GetDatasetContentLambda.Arn}:$LATEST"</span>
                      <span class="na">Payload</span><span class="pi">:</span>
                        <span class="na">DataURI.$</span><span class="pi">:</span> <span class="s">$.DataURI</span>
                    <span class="na">Resource</span><span class="pi">:</span> <span class="s">arn:aws:states:::lambda:invoke</span>
                    <span class="na">ResultSelector</span><span class="pi">:</span>
                      <span class="na">ClientList.$</span><span class="pi">:</span> <span class="s">$.Payload.Payload</span>
                    <span class="na">Retry</span><span class="pi">:</span>
                      <span class="pi">-</span> <span class="na">BackoffRate</span><span class="pi">:</span> <span class="m">2</span>
                        <span class="na">ErrorEquals</span><span class="pi">:</span>
                          <span class="pi">-</span> <span class="s">Lambda.ServiceException</span>
                          <span class="pi">-</span> <span class="s">Lambda.AWSLambdaException</span>
                          <span class="pi">-</span> <span class="s">Lambda.SdkClientException</span>
                        <span class="na">IntervalSeconds</span><span class="pi">:</span> <span class="m">2</span>
                        <span class="na">MaxAttempts</span><span class="pi">:</span> <span class="m">6</span>
                    <span class="na">Type</span><span class="pi">:</span> <span class="s">Task</span>
                    <span class="na">End</span><span class="pi">:</span> <span class="no">true</span>
            <span class="na">ResultSelector</span><span class="pi">:</span>
              <span class="na">ClientList.$</span><span class="pi">:</span> <span class="s">$[1].ClientList</span>
              <span class="na">IotEndpointAddress.$</span><span class="pi">:</span> <span class="s">$[0].IotEndpointAddress</span>
          <span class="na">CoordinatorTaskComplete</span><span class="pi">:</span>
            <span class="na">Choices</span><span class="pi">:</span>
              <span class="pi">-</span> <span class="na">And</span><span class="pi">:</span>
                  <span class="pi">-</span> <span class="na">StringMatches</span><span class="pi">:</span> <span class="s">STOPPED</span>
                    <span class="na">Variable</span><span class="pi">:</span> <span class="s">$.Tasks[0].Containers[0].LastStatus</span>
                  <span class="pi">-</span> <span class="na">NumericEquals</span><span class="pi">:</span> <span class="m">0</span>
                    <span class="na">Variable</span><span class="pi">:</span> <span class="s">$.Tasks[0].Containers[0].ExitCode</span>
                <span class="na">Next</span><span class="pi">:</span> <span class="s">Success</span>
              <span class="pi">-</span> <span class="na">And</span><span class="pi">:</span>
                  <span class="pi">-</span> <span class="na">StringMatches</span><span class="pi">:</span> <span class="s">STOPPED</span>
                    <span class="na">Variable</span><span class="pi">:</span> <span class="s">$.Tasks[0].Containers[0].LastStatus</span>
                  <span class="pi">-</span> <span class="na">Not</span><span class="pi">:</span>
                      <span class="na">NumericEquals</span><span class="pi">:</span> <span class="m">0</span>
                      <span class="na">Variable</span><span class="pi">:</span> <span class="s">$.Tasks[0].Containers[0].ExitCode</span>
                <span class="na">Next</span><span class="pi">:</span> <span class="s">Fail</span>
            <span class="na">Default</span><span class="pi">:</span> <span class="s">WaitForCoordinatorTask</span>
            <span class="na">Type</span><span class="pi">:</span> <span class="s">Choice</span>
          <span class="na">IotConfigFound</span><span class="pi">:</span>
            <span class="na">Choices</span><span class="pi">:</span>
              <span class="pi">-</span> <span class="na">And</span><span class="pi">:</span>
                  <span class="pi">-</span> <span class="na">Variable</span><span class="pi">:</span> <span class="s">$.ClientList</span>
                    <span class="na">IsPresent</span><span class="pi">:</span> <span class="no">true</span>
                  <span class="pi">-</span> <span class="na">Variable</span><span class="pi">:</span> <span class="s">$.ClientList[0]</span>
                    <span class="na">IsPresent</span><span class="pi">:</span> <span class="no">true</span>
                  <span class="pi">-</span> <span class="na">Variable</span><span class="pi">:</span> <span class="s">$.IotEndpointAddress</span>
                    <span class="na">IsPresent</span><span class="pi">:</span> <span class="no">true</span>
                <span class="na">Next</span><span class="pi">:</span> <span class="s">RunTask-FlowerCoordinator</span>
            <span class="na">Default</span><span class="pi">:</span> <span class="s">Fail</span>
            <span class="na">Type</span><span class="pi">:</span> <span class="s">Choice</span>
          <span class="na">DescribeCoordinatorTask</span><span class="pi">:</span>
            <span class="na">Type</span><span class="pi">:</span> <span class="s">Task</span>
            <span class="na">Next</span><span class="pi">:</span> <span class="s">CoordinatorTaskComplete</span>
            <span class="na">Parameters</span><span class="pi">:</span>
              <span class="na">Cluster</span><span class="pi">:</span> <span class="kt">!GetAtt</span> <span class="s">ECSCluster.Arn</span>
              <span class="na">Tasks.$</span><span class="pi">:</span> <span class="s">States.Array($.CoordinatorTaskResult.taskArn)</span>
            <span class="na">Resource</span><span class="pi">:</span> <span class="s">arn:aws:states:::aws-sdk:ecs:describeTasks</span>
          <span class="na">MapGreenGrassClients</span><span class="pi">:</span>
            <span class="na">Type</span><span class="pi">:</span> <span class="s">Map</span>
            <span class="na">Catch</span><span class="pi">:</span>
              <span class="pi">-</span> <span class="na">ErrorEquals</span><span class="pi">:</span>
                  <span class="pi">-</span> <span class="s">States.TaskFailed</span>
                <span class="na">Next</span><span class="pi">:</span> <span class="s">StopCoordinatorTask</span>
            <span class="na">ResultPath</span><span class="pi">:</span> <span class="s">$.mapClientsResult</span>
            <span class="na">Next</span><span class="pi">:</span> <span class="s">WaitForCoordinatorTask</span>
            <span class="na">Iterator</span><span class="pi">:</span>
              <span class="na">StartAt</span><span class="pi">:</span> <span class="s">RunTask-FlowerProxy</span>
              <span class="na">States</span><span class="pi">:</span>
                <span class="na">RunTask-FlowerProxy</span><span class="pi">:</span>
                  <span class="na">Type</span><span class="pi">:</span> <span class="s">Task</span>
                  <span class="na">Resource</span><span class="pi">:</span> <span class="s">arn:aws:states:::ecs:runTask.sync</span>
                  <span class="na">Parameters</span><span class="pi">:</span>
                    <span class="na">LaunchType</span><span class="pi">:</span> <span class="s">FARGATE</span>
                    <span class="na">Cluster</span><span class="pi">:</span> <span class="kt">!GetAtt</span> <span class="s">ECSCluster.Arn</span>
                    <span class="na">TaskDefinition</span><span class="pi">:</span> <span class="kt">!Ref</span> <span class="s">ProxyTaskDef</span>
                    <span class="na">NetworkConfiguration</span><span class="pi">:</span>
                      <span class="na">AwsvpcConfiguration</span><span class="pi">:</span>
                        <span class="na">SecurityGroups</span><span class="pi">:</span>
                          <span class="pi">-</span> <span class="kt">!GetAtt</span> <span class="s">SGContainers.GroupId</span>
                        <span class="na">Subnets</span><span class="pi">:</span>
                          <span class="pi">-</span> <span class="kt">!Ref</span> <span class="s">Subnet</span>
                    <span class="na">Overrides</span><span class="pi">:</span>
                      <span class="na">ContainerOverrides</span><span class="pi">:</span>
                        <span class="pi">-</span> <span class="na">Name</span><span class="pi">:</span> <span class="s">flower-proxy</span>
                          <span class="na">Environment</span><span class="pi">:</span>
                            <span class="pi">-</span> <span class="na">Name</span><span class="pi">:</span> <span class="s">CLIENT</span>
                              <span class="na">Value.$</span><span class="pi">:</span> <span class="s">$.client</span>
                            <span class="pi">-</span> <span class="na">Name</span><span class="pi">:</span> <span class="s">ENDPOINT</span>
                              <span class="na">Value.$</span><span class="pi">:</span> <span class="s">$.endpoint</span>
                            <span class="pi">-</span> <span class="na">Name</span><span class="pi">:</span> <span class="s">COORDINATOR</span>
                              <span class="na">Value.$</span><span class="pi">:</span> <span class="s">$.coordinator</span>
                            <span class="pi">-</span> <span class="na">Name</span><span class="pi">:</span> <span class="s">TABLE</span>
                              <span class="na">Value</span><span class="pi">:</span> <span class="kt">!Ref</span> <span class="s">DDBTable</span>
                            <span class="pi">-</span> <span class="na">Name</span><span class="pi">:</span> <span class="s">BUCKET</span>
                              <span class="na">Value</span><span class="pi">:</span> <span class="kt">!Ref</span> <span class="s">ProxyBucket</span>
                  <span class="na">End</span><span class="pi">:</span> <span class="no">true</span>
            <span class="na">ItemsPath</span><span class="pi">:</span> <span class="s">$.ClientList</span>
            <span class="na">Parameters</span><span class="pi">:</span>
              <span class="na">coordinator.$</span><span class="pi">:</span> <span class="s">States.Format('{}:8080', $.CoordinatorTaskResult.ip)</span>
              <span class="na">client.$</span><span class="pi">:</span> <span class="s">$$.Map.Item.Value</span>
              <span class="na">endpoint.$</span><span class="pi">:</span> <span class="s">States.Format('https://{}', $.IotEndpointAddress)</span>
          <span class="na">RunTask-FlowerCoordinator</span><span class="pi">:</span>
            <span class="na">Type</span><span class="pi">:</span> <span class="s">Task</span>
            <span class="na">Resource</span><span class="pi">:</span> <span class="s">arn:aws:states:::ecs:runTask.waitForTaskToken</span>
            <span class="na">HeartbeatSeconds</span><span class="pi">:</span> <span class="m">600</span>
            <span class="na">Parameters</span><span class="pi">:</span>
              <span class="na">LaunchType</span><span class="pi">:</span> <span class="s">FARGATE</span>
              <span class="na">Cluster</span><span class="pi">:</span> <span class="kt">!GetAtt</span> <span class="s">ECSCluster.Arn</span>
              <span class="na">TaskDefinition</span><span class="pi">:</span> <span class="kt">!Ref</span> <span class="s">CoordinatorTaskDef</span>
              <span class="na">Overrides</span><span class="pi">:</span>
                <span class="na">ContainerOverrides</span><span class="pi">:</span>
                  <span class="pi">-</span> <span class="na">Name</span><span class="pi">:</span> <span class="s">flower-coordinator</span>
                    <span class="na">Environment</span><span class="pi">:</span>
                      <span class="pi">-</span> <span class="na">Name</span><span class="pi">:</span> <span class="s">TASK_TOKEN</span>
                        <span class="na">Value.$</span><span class="pi">:</span> <span class="s">$$.Task.Token</span>
              <span class="na">NetworkConfiguration</span><span class="pi">:</span>
                <span class="na">AwsvpcConfiguration</span><span class="pi">:</span>
                  <span class="na">SecurityGroups</span><span class="pi">:</span>
                    <span class="pi">-</span> <span class="kt">!GetAtt</span> <span class="s">SGContainers.GroupId</span>
                  <span class="na">Subnets</span><span class="pi">:</span>
                    <span class="pi">-</span> <span class="kt">!Ref</span> <span class="s">Subnet</span>
            <span class="na">Next</span><span class="pi">:</span> <span class="s">MapGreenGrassClients</span>
            <span class="na">ResultPath</span><span class="pi">:</span> <span class="s">$.CoordinatorTaskResult</span>
          <span class="na">StopCoordinatorTask</span><span class="pi">:</span>
            <span class="na">Type</span><span class="pi">:</span> <span class="s">Task</span>
            <span class="na">Parameters</span><span class="pi">:</span>
              <span class="na">Task.$</span><span class="pi">:</span> <span class="s">$.CoordinatorTaskResult.taskArn</span>
            <span class="na">Resource</span><span class="pi">:</span> <span class="s">arn:aws:states:::aws-sdk:ecs:stopTask</span>
            <span class="na">Next</span><span class="pi">:</span> <span class="s">Fail</span>
          <span class="na">WaitForCoordinatorTask</span><span class="pi">:</span>
            <span class="na">Next</span><span class="pi">:</span> <span class="s">DescribeCoordinatorTask</span>
            <span class="na">Seconds</span><span class="pi">:</span> <span class="m">60</span>
            <span class="na">Type</span><span class="pi">:</span> <span class="s">Wait</span>
          <span class="na">Success</span><span class="pi">:</span>
            <span class="na">Type</span><span class="pi">:</span> <span class="s">Succeed</span>
          <span class="na">Fail</span><span class="pi">:</span>
            <span class="na">Type</span><span class="pi">:</span> <span class="s">Fail</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<ul>
  <li><strong>AWS ECS/FarGate</strong>: được dùng để host container cho người điều phối và các thiết bị mô phỏng. Một đoạn mã server của người điều phối dùng Flower như sau:</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
</pre></td><td class="rouge-code"><pre><span class="c1"># Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.
# SPDX-License-Identifier: MIT-0
</span>
<span class="kn">import</span> <span class="nn">flwr</span> <span class="k">as</span> <span class="n">fl</span>
<span class="kn">import</span> <span class="nn">boto3</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">sys</span>

<span class="c1"># Setup logging to stdout
</span><span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="p">.</span><span class="n">getLogger</span><span class="p">(</span><span class="n">__name__</span><span class="p">)</span>
<span class="n">logging</span><span class="p">.</span><span class="n">basicConfig</span><span class="p">(</span><span class="n">stream</span><span class="o">=</span><span class="n">sys</span><span class="p">.</span><span class="n">stdout</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="p">.</span><span class="n">INFO</span><span class="p">)</span>

<span class="n">token</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">getenv</span><span class="p">(</span><span class="s">'TASK_TOKEN'</span><span class="p">)</span>
<span class="n">metadata_uri</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">getenv</span><span class="p">(</span><span class="s">'ECS_CONTAINER_METADATA_URI_V4'</span><span class="p">)</span>
<span class="n">token_response</span> <span class="o">=</span> <span class="s">""</span>
<span class="k">if</span> <span class="n">metadata_uri</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">metadata_uri</span><span class="si">}</span><span class="s">/task"</span><span class="p">)</span>
    <span class="n">task_meta</span> <span class="o">=</span> <span class="n">r</span><span class="p">.</span><span class="n">json</span><span class="p">()</span>
    <span class="n">logger</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s">"found task metadata: </span><span class="si">{</span><span class="n">task_meta</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    <span class="n">token_response</span> <span class="o">=</span> <span class="n">json</span><span class="p">.</span><span class="n">dumps</span><span class="p">({</span>
        <span class="s">"ip"</span><span class="p">:</span> <span class="n">task_meta</span><span class="p">[</span><span class="s">'Containers'</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s">'Networks'</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s">'IPv4Addresses'</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span>
        <span class="s">"taskArn"</span><span class="p">:</span> <span class="n">task_meta</span><span class="p">[</span><span class="s">'TaskARN'</span><span class="p">]</span>
    <span class="p">})</span>

<span class="k">if</span> <span class="n">token</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
    <span class="n">stfn</span> <span class="o">=</span> <span class="n">boto3</span><span class="p">.</span><span class="n">client</span><span class="p">(</span><span class="s">'stepfunctions'</span><span class="p">)</span>
    <span class="n">logger</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s">"send_task_success - taskToken=</span><span class="si">{</span><span class="n">token</span><span class="si">}</span><span class="s">, output=</span><span class="si">{</span><span class="n">token_response</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    <span class="n">stfn</span><span class="p">.</span><span class="n">send_task_success</span><span class="p">(</span><span class="n">taskToken</span><span class="o">=</span><span class="n">token</span><span class="p">,</span> <span class="n">output</span><span class="o">=</span><span class="n">token_response</span><span class="p">)</span>

<span class="n">fl</span><span class="p">.</span><span class="n">server</span><span class="p">.</span><span class="n">start_server</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="p">{</span><span class="s">"num_rounds"</span><span class="p">:</span> <span class="mi">3</span><span class="p">})</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Ngoài ra, chúng ta cũng sử dụng một proxy container có nhiệm vụ trung chuyển yêu cầu giữa người điều phối và các thiết bị. 
Proxy này cũng thực hiện lưu dữ liệu xuống S3: lý do cho việc này là do thông số mô hình có thể tới vài MB, nên lưu vào S3 để về sau thiết bị tự load lên thì hiệu quả hơn.</p>

<ul>
  <li><strong>AWS IoT GreenGrass</strong>: ở đây để quản lý giao tiếp giữa các thiết bị IoT với proxies. GG Streams được dùng để lưu dữ liệu vào S3 cũng như load mô hình từ S3 lên.</li>
  <li><strong>AWS IoT Core</strong> kết nối thiết bị IoT với các dịch vụ điện toán đám mây như DynamoDB.</li>
  <li><strong>AWS DynamoDB</strong> lưu trữ rules từ IoT core.</li>
  <li><strong>AWS Lambda</strong> được triển khai lên thiết bị GreenGrass và thực hiện training trên thiết bị IoT.</li>
  <li><strong>AWS S3</strong> lưu trữ mô hình.</li>
</ul>

<p><img src="https://d2908q01vomqb2.cloudfront.net/fc074d501302eb2b93e2554793fcaf50b3bf7291/2021/12/08/Fig3-fed-ml.png" alt="" />
<em>Triển khai giải pháp FedML trên Amazon SageMaker</em></p>

<h1 id="kết-luận">Kết luận</h1>

<p>Nhìn chung, qua bài viết này, chúng ta đã nhìn thấy tiềm năng cũng như sự cần thiết của FedML trong ứng dụng máy học thực tế.
So với ML cơ bản thì FedML giải quyết khá nhiều vấn đề thực tế như bảo mật và bảo vệ dữ liệu người dùng, cải thiện băng thông.
Và FedML cũng có những vấn đề riêng đang trong giai đoạn nghiên cứu.
Chúng ta cũng điểm qua ứng dụng PoC thực tế của FedML bằng AWS SageMaker.</p>

<h1 id="references">References</h1>

<ol class="bibliography"><li><span id="aledhari2020federated">Aledhari, M., Razzak, R., Parizi, R.M. and Saeed, F. 2020. Federated learning: A survey on enabling technologies, protocols, and applications. <i>IEEE Access</i>. 8, (2020), 140699–140725.</span><a class="details" href="https://wanted2.github.io/bibliography/aledhari2020federated/">Details</a></li>
<li><span id="liu2020federated">Liu, Y., Yuan, X., Xiong, Z., Kang, J., Wang, X. and Niyato, D. 2020. Federated learning for 6G communications: Challenges, methods, and future directions. <i>China Communications</i>. 17, 9 (2020), 105–118.</span><a class="details" href="https://wanted2.github.io/bibliography/liu2020federated/">Details</a></li>
<li><span id="khan2021federated">Khan, L.U., Saad, W., Han, Z., Hossain, E. and Hong, C.S. 2021. Federated learning for internet of things: Recent advances, taxonomy, and open challenges. <i>IEEE Communications Surveys &amp; Tutorials</i>. (2021).</span><a class="details" href="https://wanted2.github.io/bibliography/khan2021federated/">Details</a></li>
<li><span id="kaissis2020secure">Kaissis, G.A., Makowski, M.R., Rückert, D. and Braren, R.F. 2020. Secure, privacy-preserving and federated machine learning in medical imaging. <i>Nature Machine Intelligence</i>. 2, 6 (2020), 305–311.</span><a class="details" href="https://wanted2.github.io/bibliography/kaissis2020secure/">Details</a></li>
<li><span id="nguyen2021federated">Nguyen, D.C., Ding, M., Pathirana, P.N., Seneviratne, A., Li, J. and Poor, H.V. 2021. Federated learning for internet of things: A comprehensive survey. <i>IEEE Communications Surveys &amp; Tutorials</i>. (2021).</span><a class="details" href="https://wanted2.github.io/bibliography/nguyen2021federated/">Details</a></li>
<li><span id="kaissis2021end">Kaissis, G., Ziller, A., Passerat-Palmbach, J., Ryffel, T., Usynin, D., Trask, A., Lima, I., Mancuso, J., Jungmann, F., Steinborn, M.-M. and others 2021. End-to-end privacy preserving deep learning on multi-institutional medical imaging. <i>Nature Machine Intelligence</i>. 3, 6 (2021), 473–484.</span><a class="details" href="https://wanted2.github.io/bibliography/kaissis2021end/">Details</a></li></ol>
<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:3" role="doc-endnote">
      <p><a href="https://mqtt.org/">https://mqtt.org/</a> <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:1" role="doc-endnote">
      <p><a href="https://pytorch.org/">https://pytorch.org/</a> <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a> <a href="#fnref:1:1" class="reversefootnote" role="doc-backlink">&#8617;<sup>2</sup></a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p><a href="https://www.tensorflow.org/">https://www.tensorflow.org/</a> <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a> <a href="#fnref:2:1" class="reversefootnote" role="doc-backlink">&#8617;<sup>2</sup></a></p>
    </li>
    <li id="fn:4" role="doc-endnote">
      <p><a href="https://github.com/OpenMined/PySyft">https://github.com/OpenMined/PySyft</a> <a href="#fnref:4" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:5" role="doc-endnote">
      <p><a href="https://flower.dev/">https://flower.dev/</a> <a href="#fnref:5" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:8" role="doc-endnote">
      <p><a href="https://huggingface.co/">https://huggingface.co/</a> <a href="#fnref:8" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:6" role="doc-endnote">
      <p><a href="https://www.pytorchlightning.ai/">https://www.pytorchlightning.ai/</a> <a href="#fnref:6" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:7" role="doc-endnote">
      <p><a href="https://mxnet.apache.org/versions/1.9.1/">https://mxnet.apache.org/versions/1.9.1/</a> <a href="#fnref:7" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>

            </div>

            <!-- Rating -->
            

            <!-- Post Date -->
            <p>
            <small>
                <span class="post-date"><time class="post-date" datetime="2022-06-05">05 Jun 2022</time></span>           
                
                </small>
            </p>

            <!-- Post Categories -->
            <div class="after-post-cats">
                <ul class="tags mb-4">
                    
                    
                    <li>
                        <a class="smoothscroll" href="https://wanted2.github.io/categories#Artificial-Intelligence">Artificial Intelligence</a>
                    </li>
                    
                </ul>
            </div>
            <!-- End Categories -->

            <!-- Post Tags -->
            <div class="after-post-tags">
                <ul class="tags">
                    
                    
                    <li>
                        <a class="smoothscroll" href="https://wanted2.github.io/tags#6g">#6g</a>
                    </li>
                    
                    <li>
                        <a class="smoothscroll" href="https://wanted2.github.io/tags#Machine-learning">#Machine learning</a>
                    </li>
                    
                    <li>
                        <a class="smoothscroll" href="https://wanted2.github.io/tags#TPU">#TPU</a>
                    </li>
                    
                    <li>
                        <a class="smoothscroll" href="https://wanted2.github.io/tags#amazon-web-services">#amazon web services</a>
                    </li>
                    
                    <li>
                        <a class="smoothscroll" href="https://wanted2.github.io/tags#aws">#aws</a>
                    </li>
                    
                    <li>
                        <a class="smoothscroll" href="https://wanted2.github.io/tags#cloud-computing">#cloud computing</a>
                    </li>
                    
                    <li>
                        <a class="smoothscroll" href="https://wanted2.github.io/tags#distributed-computing">#distributed computing</a>
                    </li>
                    
                    <li>
                        <a class="smoothscroll" href="https://wanted2.github.io/tags#edge-computing">#edge computing</a>
                    </li>
                    
                    <li>
                        <a class="smoothscroll" href="https://wanted2.github.io/tags#edge-devices">#edge devices</a>
                    </li>
                    
                    <li>
                        <a class="smoothscroll" href="https://wanted2.github.io/tags#edge-server">#edge server</a>
                    </li>
                    
                    <li>
                        <a class="smoothscroll" href="https://wanted2.github.io/tags#edge-cloud-architectures">#edge-cloud architectures</a>
                    </li>
                    
                    <li>
                        <a class="smoothscroll" href="https://wanted2.github.io/tags#federated-learning">#federated learning</a>
                    </li>
                    
                    <li>
                        <a class="smoothscroll" href="https://wanted2.github.io/tags#fedml">#fedml</a>
                    </li>
                    
                    <li>
                        <a class="smoothscroll" href="https://wanted2.github.io/tags#internet-of-things">#internet of things</a>
                    </li>
                    
                    <li>
                        <a class="smoothscroll" href="https://wanted2.github.io/tags#iot">#iot</a>
                    </li>
                    
                </ul>
            </div>
            <!-- End Tags -->

            <!-- Prev/Next -->
            <div class="row PageNavigation d-flex justify-content-between font-weight-bold">
            
            <a class="prev d-block col-md-6" href="https://wanted2.github.io//hanoi-eating-habits/"> &laquo; Ăn gì ở Hà Nội: Luận về thói quen ăn uống của người Hà Nội</a>
            
            
            <div class="clearfix"></div>
            </div>
            <!-- End Categories -->

        </div>
        <!-- End Post -->

    </div>
</div>
<!-- End Article
================================================== -->

<!-- Begin Comments
================================================== -->

    <div class="container">
        <div id="comments" class="row justify-content-center mb-5">
            <div class="col-md-8">
                <section class="disqus">
    <div id="disqus_thread"></div>
    <script type="text/javascript">
        var disqus_shortname = 'caineng'; 
        var disqus_developer = 0;
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = window.location.protocol + '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</section>

            </div>
        </div>
    </div>

<!--End Comments
================================================== -->

<!-- Review with LD-JSON, adapt it for your needs if you like, but make sure you test the generated HTML source code first: 
https://search.google.com/structured-data/testing-tool/u/0/
================================================== -->

</div>


<!-- Bottom Alert Bar
================================================== -->
<div class="alertbar">
	<div class="container text-center">
		<span><img src="https://wanted2.github.io/assets/images/favicon.ico" alt="AiFi" style="max-height: 48px;" /> &nbsp; Never miss a <b>story</b> from us, subscribe to our newsletter</span>
        <form action="https://caineng.us20.list-manage.com/subscribe/post?u=76342d3d74a6807aac5aec0d7&id=b5645e19be" method="post" name="mc-embedded-subscribe-form" class="wj-contact-form validate" target="_blank" novalidate>
            <div class="mc-field-group">
            <input type="email" placeholder="Email" name="EMAIL" class="required email" id="mce-EMAIL" autocomplete="on" required>
            <input type="submit" value="Subscribe" name="subscribe" class="heart">
            </div>
        </form>
	</div>
</div>

    
</div>

<!-- Categories Jumbotron
================================================== -->
<div class="jumbotron fortags">
	<div class="d-md-flex h-100">
		<div class="col-md-4 transpdark align-self-center text-center h-100">
            <div class="d-md-flex align-items-center justify-content-center h-100">
                <h2 class="d-md-block align-self-center py-1 font-weight-light">Explore <span class="d-none d-md-inline">→</span></h2>
            </div>
		</div>
		<div class="col-md-8 p-5 align-self-center text-center">
            
            
                
                    <a class="mt-1 mb-1" href="https://wanted2.github.io/categories#Site-Reliable-Engineering">Site Reliable Engineering (13)</a>
                
                    <a class="mt-1 mb-1" href="https://wanted2.github.io/categories#Software-Engineering">Software Engineering (37)</a>
                
                    <a class="mt-1 mb-1" href="https://wanted2.github.io/categories#Computer-Vision">Computer Vision (6)</a>
                
                    <a class="mt-1 mb-1" href="https://wanted2.github.io/categories#Artificial-Intelligence">Artificial Intelligence (18)</a>
                
                    <a class="mt-1 mb-1" href="https://wanted2.github.io/categories#Tiếng-Việt,-日本語">Tiếng Việt, 日本語 (35)</a>
                
                    <a class="mt-1 mb-1" href="https://wanted2.github.io/categories#Project-Management">Project Management (34)</a>
                
            
            
		</div>
	</div>
</div>

<!-- Begin Footer
================================================== -->
<footer class="footer">
    <div class="container">
        <div class="row">
            <div class="col-md-6 col-sm-6 text-center text-lg-left">
                Copyright © 2022 AiFi 
            </div>
            <div class="col-md-6 col-sm-6 text-center text-lg-right">    
                <a target="_blank" href="https://www.wowthemes.net/mediumish-free-jekyll-template/">Mediumish Jekyll Theme</a> by WowThemes.net
            </div>
        </div>
    </div>
</footer>
<!-- End Footer
================================================== -->

</div> <!-- /.site-content -->

<!-- Scripts
================================================== -->

<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js" integrity="sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut" crossorigin="anonymous"></script>

<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js" integrity="sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k" crossorigin="anonymous"></script>

<script src="https://wanted2.github.io/assets/js/mediumish.js"></script>


<script src="https://wanted2.github.io/assets/js/lazyload.js"></script>


<script src="https://wanted2.github.io/assets/js/ie10-viewport-bug-workaround.js"></script> 


<script id="dsq-count-scr" src="//caineng.disqus.com/count.js"></script>


</body>
</html>
