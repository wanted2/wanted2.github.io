<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<link rel="icon" href="https://wanted2.github.io/assets/images/favicon.ico">

<title>Seq2Seq for Computer Vision: Some state-of-the-arts and a thought on how to have a good GPU server | AiFi</title>

 
    
        <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=G-2CDTCF0EP6" crossorigin="anonymous"></script>
        <script>
            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());

            gtag('config', 'G-2CDTCF0EP6');
        </script>
    


<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Seq2Seq for Computer Vision: Some state-of-the-arts and a thought on how to have a good GPU server | AiFi</title>
<meta name="generator" content="Jekyll v4.2.1" />
<meta property="og:title" content="Seq2Seq for Computer Vision: Some state-of-the-arts and a thought on how to have a good GPU server" />
<meta name="author" content="tuan" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Vision Transformers ViT [6] Source: Google DETR [6, 6] YOLOX [6] Xây dựng tài nguyên GPU Đầu tiên chúng ta sẽ xem SOTA ở mảng này xài máy móc thế nào? Rồi mình lại xem giá thành bộ đó qua đủ các phương án: tự xây và thuê xem có “vừa túi tiền” không nhá. Giá thành khi train model State-of-the-art (SOTA) Nhìn chung là nếu chỉ hình ảnh với bộ dữ liệu nhỏ nhỏ như COCO [6] tầm trăm ngàn ảnh thì có bảng giá dưới đây: chúng ta lấy ví dụ từ báo cáo của 1 state-of-the-art thì họ dùng 8 cái V100, train tầm 6 ngày liên tục (\(6\times 24\) giờ) thì tổng tiền cho một lượt trên tầm ngàn Mỹ kim cho 6 ngày, 1 tháng cứ tầm 5 ngàn Mỹ kim. Mà các bạn cũng nhớ giá này là giá Spot tức là có thể bị interrupt giữa chừng nên mới rẻ thế. Chứ nếu bạn mà chọn on-demand thì có mà gấp 10 lần. Nhưng ở trên mới chỉ là giá bộ COCO có hơn 100k ảnh nhé. Bộ Open Images [6] với 1.7 triệu ảnh thì còn máu nữa. Search trên Kaggle mà có đồng chí chịu khó bỏ tiền ra ngồi train và báo cáo kết quả cho anh biết (xin cám ơn đồng chí): Kaggle Open Images 2019 challenge 6th place solution. Thì kết quả là đồng chí ấy báo cáo: train 8 models trên V100 (chắc lại EC2 P3 thôi thì mình cứ dùng p3.xlarge để làm phân tích giá nhé) rồi ensemble. mỗi model train mất 18-36 ngày (tùy model). Thì đồng chí này train 8 GPUs khác nhau. sau khi train xong các model thì mất thêm 1 ngày nữa để inference và 1 ngày nữa để ensemble (dùng NMS). Vậy tổng thể đã tiêu tốn \(36\times 8+1\times 8+1=297\) ngày train, tức là \(297\times 24=7128\) giờ train. p3.xlarge thì giá mềm nhất là Spot cũng tầm $0.918/h. Tức là để train được accuracy tầm 60% đã mất \(7128\times 0.918\) tức là tầm 6543 Mỹ kim và hơn tháng ngồi monitor màn hình train. Xây dựng hệ thống 8~16 GPU Nhìn chung thì theo dòng lịch sử có 3 loại NVIDIA GPU dành cho cloud khá thông dụng như sau (tôi không nói tới hai dòng GTX và RTX nhé): NVIDIA V100 hay Volta: nói đến dòng này chúng ta có những sự lựa chọn chủ yếu liên quan tới V100 Tensor Core mà đại diện cho thuê là p3.16xlarge và p3dn.24xlarge. Với băng thông mạng của phiên bản P3.16xlarge cao hơn tới 4 lần, phiên bản P3dn.24xlarge của Amazon EC2 là sự bổ sung mới nhất cho dòng phiên bản P3, được tối ưu hóa cho machine learning phân tán và các ứng dụng HPC. Các phiên bản này cung cấp thông lượng kết nối mạng lên tới 100 Gbps, 96 vCPU Intel® Xeon® Có thể mở rộng (Skylake) tùy chỉnh, 8 GPU NVIDIA® V100 Tensor Core với 32 GB bộ nhớ mỗi GPU và 1,8 TB ổ lưu trữ SSD cục bộ chuẩn NVMe. Các phiên bản P3dn.24xlarge cũng hỗ trợ Elastic Fabric Adapter (EFA). Giao diện này tăng tốc các ứng dụng machine learning phân tán sử dụng Thư viện giao tiếp chung NVIDIA (NCCL). EFA có thể mở rộng quy mô lên đến hàng nghìn GPU, cải thiện đáng kể thông lượng và khả năng mở rộng của các mô hình huấn luyện deep learning, từ đó cho kết quả nhanh hơn. Source: Amazon Web Service NVIDIA T4 hay Turing: với AWS EC2 thì bạn có thể thuê g4dn.metal. NVIDIA A100 hay Ampere: Với AWS EC2 thì có thể thuê p4d.24xlarge, với Azure HPC thì có thể thuê Standard_ND96amsr_A100_v4. GCP thì có a2-highgpu-8g hoặc bản 16 GPU là a2-highgpu-16g. Thì về mặt spec Ampere là khỏe nhất nếu nói về TFLOPS. Dưới đây là bảng giá thành của NVIDIA 8x A100 Tensor Core. Trong bảng này có 2 cột mà các bạn nên để ý là giá thành thuê theo giờ (Hourly cost) và tỷ lệ GFLOPS/USD (đáng giá thế nào). Giả định chung là hệ thống được xây dựng tối thiểu 4x GPU và được dùng ít nhất 24 tháng, mỗi tháng dùng 22 ngày (T7/CN nghỉ ngơi). Nói chung tự build thì các bạn có thể tham khảo cấu hình của DGX-11, DGX-22, và DGX-A1003 để mua các bộ phận về tự ráp thì sẽ tiết kiệm công lắp ráp, nhưng nhìn chung tôi nghĩ cũng phải 50 ngàn Mỹ Kim. Các cloud solutions Trong trường hợp bạn có bài toán train dữ liệu mà mất hàng tháng trời train với GTX/RTX thì bạn sẽ nghĩ phải thuê GPUs trên data center (8x-16x GPU). Thì ngoài AWS/Azure/GCP là khá cùng rank nên bảng giá không chênh lệch nhau mấy, bạn có thể tham khảo thêm các trang cho thuê GPU bên ngoài để tìm được chỗ thuê hợp lý hơn. Như kết quả tìm kiếm của AIFI thì hiện tại có trang vast.ai cung cấp khá nhiều sự lựa chọn cho thuê ở mức giá thấp hơn 5 USD/hour. Còn lời giải nào khác? Nhìn chung tự build thì có hai khả năng: Mua đồ sẵn như DGX123 thì các bạn cứ chuẩn bị 100k Mỹ kim trở lên. Mua bộ phận về tự ráp thì các bác tham khảo cấu hình của DGX rồi độ lại tùy theo nhu cầu. Tuy nhiên, chắc chỉ giảm được tiền công, và tối ưu một chút kiểu DGX dùng nhiều RAM thì mình giảm RAM xuống. Nói chung chắc cũng phải 50K Mỹ Kim. Về cá nhân, tôi thiên về thuê! Nếu tự build thì mua mấy cái RTX/GTX dòng Ti là ổn rồi. Tuy nhiên nếu bài toán lớn thì bạn bắt buộc phải dùng data center GPU thì lúc ấy phải có TIỀN! Kết luận Tài liệu tham khảo Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S., Uskoreit, J. and Houlsby, N. 2020. An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929. (2020).Details Carion, N., Massa, F., Synnaeve, G., Usunier, N., Kirillov, A. and Zagoruyko, S. 2020. End-to-end object detection with transformers. European conference on computer vision (2020), 213–229.Details Gao, P., Zheng, M., Wang, X., Dai, J. and Li, H. 2021. Fast convergence of detr with spatially modulated co-attention. Proceedings of the IEEE/CVF International Conference on Computer Vision (2021), 3621–3630.Details Ge, Z., Liu, S., Wang, F., Li, Z. and Sun, J. 2021. Yolox: Exceeding yolo series in 2021. arXiv preprint arXiv:2107.08430. (2021).Details Lin, T.-Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., Dollár, P. and Zitnick, C.L. 2014. Microsoft coco: Common objects in context. European conference on computer vision (2014), 740–755.Details Kuznetsova, A., Rom, H., Alldrin, N., Uijlings, J., Krasin, I., Pont-Tuset, J., Kamali, S., Popov, S., Malloci, M., Kolesnikov, A., Duerig, T. and Ferrari, V. 2020. The open images dataset v4. International Journal of Computer Vision. 128, 7 (2020), 1956–1981.Details https://www.nvidia.com/en-us/data-center/dgx-1/ &#8617; &#8617;2 https://www.nvidia.com/en-us/data-center/dgx-2/ &#8617; &#8617;2 https://www.nvidia.com/en-us/data-center/dgx-a100/ &#8617; &#8617;2" />
<meta property="og:description" content="Vision Transformers ViT [6] Source: Google DETR [6, 6] YOLOX [6] Xây dựng tài nguyên GPU Đầu tiên chúng ta sẽ xem SOTA ở mảng này xài máy móc thế nào? Rồi mình lại xem giá thành bộ đó qua đủ các phương án: tự xây và thuê xem có “vừa túi tiền” không nhá. Giá thành khi train model State-of-the-art (SOTA) Nhìn chung là nếu chỉ hình ảnh với bộ dữ liệu nhỏ nhỏ như COCO [6] tầm trăm ngàn ảnh thì có bảng giá dưới đây: chúng ta lấy ví dụ từ báo cáo của 1 state-of-the-art thì họ dùng 8 cái V100, train tầm 6 ngày liên tục (\(6\times 24\) giờ) thì tổng tiền cho một lượt trên tầm ngàn Mỹ kim cho 6 ngày, 1 tháng cứ tầm 5 ngàn Mỹ kim. Mà các bạn cũng nhớ giá này là giá Spot tức là có thể bị interrupt giữa chừng nên mới rẻ thế. Chứ nếu bạn mà chọn on-demand thì có mà gấp 10 lần. Nhưng ở trên mới chỉ là giá bộ COCO có hơn 100k ảnh nhé. Bộ Open Images [6] với 1.7 triệu ảnh thì còn máu nữa. Search trên Kaggle mà có đồng chí chịu khó bỏ tiền ra ngồi train và báo cáo kết quả cho anh biết (xin cám ơn đồng chí): Kaggle Open Images 2019 challenge 6th place solution. Thì kết quả là đồng chí ấy báo cáo: train 8 models trên V100 (chắc lại EC2 P3 thôi thì mình cứ dùng p3.xlarge để làm phân tích giá nhé) rồi ensemble. mỗi model train mất 18-36 ngày (tùy model). Thì đồng chí này train 8 GPUs khác nhau. sau khi train xong các model thì mất thêm 1 ngày nữa để inference và 1 ngày nữa để ensemble (dùng NMS). Vậy tổng thể đã tiêu tốn \(36\times 8+1\times 8+1=297\) ngày train, tức là \(297\times 24=7128\) giờ train. p3.xlarge thì giá mềm nhất là Spot cũng tầm $0.918/h. Tức là để train được accuracy tầm 60% đã mất \(7128\times 0.918\) tức là tầm 6543 Mỹ kim và hơn tháng ngồi monitor màn hình train. Xây dựng hệ thống 8~16 GPU Nhìn chung thì theo dòng lịch sử có 3 loại NVIDIA GPU dành cho cloud khá thông dụng như sau (tôi không nói tới hai dòng GTX và RTX nhé): NVIDIA V100 hay Volta: nói đến dòng này chúng ta có những sự lựa chọn chủ yếu liên quan tới V100 Tensor Core mà đại diện cho thuê là p3.16xlarge và p3dn.24xlarge. Với băng thông mạng của phiên bản P3.16xlarge cao hơn tới 4 lần, phiên bản P3dn.24xlarge của Amazon EC2 là sự bổ sung mới nhất cho dòng phiên bản P3, được tối ưu hóa cho machine learning phân tán và các ứng dụng HPC. Các phiên bản này cung cấp thông lượng kết nối mạng lên tới 100 Gbps, 96 vCPU Intel® Xeon® Có thể mở rộng (Skylake) tùy chỉnh, 8 GPU NVIDIA® V100 Tensor Core với 32 GB bộ nhớ mỗi GPU và 1,8 TB ổ lưu trữ SSD cục bộ chuẩn NVMe. Các phiên bản P3dn.24xlarge cũng hỗ trợ Elastic Fabric Adapter (EFA). Giao diện này tăng tốc các ứng dụng machine learning phân tán sử dụng Thư viện giao tiếp chung NVIDIA (NCCL). EFA có thể mở rộng quy mô lên đến hàng nghìn GPU, cải thiện đáng kể thông lượng và khả năng mở rộng của các mô hình huấn luyện deep learning, từ đó cho kết quả nhanh hơn. Source: Amazon Web Service NVIDIA T4 hay Turing: với AWS EC2 thì bạn có thể thuê g4dn.metal. NVIDIA A100 hay Ampere: Với AWS EC2 thì có thể thuê p4d.24xlarge, với Azure HPC thì có thể thuê Standard_ND96amsr_A100_v4. GCP thì có a2-highgpu-8g hoặc bản 16 GPU là a2-highgpu-16g. Thì về mặt spec Ampere là khỏe nhất nếu nói về TFLOPS. Dưới đây là bảng giá thành của NVIDIA 8x A100 Tensor Core. Trong bảng này có 2 cột mà các bạn nên để ý là giá thành thuê theo giờ (Hourly cost) và tỷ lệ GFLOPS/USD (đáng giá thế nào). Giả định chung là hệ thống được xây dựng tối thiểu 4x GPU và được dùng ít nhất 24 tháng, mỗi tháng dùng 22 ngày (T7/CN nghỉ ngơi). Nói chung tự build thì các bạn có thể tham khảo cấu hình của DGX-11, DGX-22, và DGX-A1003 để mua các bộ phận về tự ráp thì sẽ tiết kiệm công lắp ráp, nhưng nhìn chung tôi nghĩ cũng phải 50 ngàn Mỹ Kim. Các cloud solutions Trong trường hợp bạn có bài toán train dữ liệu mà mất hàng tháng trời train với GTX/RTX thì bạn sẽ nghĩ phải thuê GPUs trên data center (8x-16x GPU). Thì ngoài AWS/Azure/GCP là khá cùng rank nên bảng giá không chênh lệch nhau mấy, bạn có thể tham khảo thêm các trang cho thuê GPU bên ngoài để tìm được chỗ thuê hợp lý hơn. Như kết quả tìm kiếm của AIFI thì hiện tại có trang vast.ai cung cấp khá nhiều sự lựa chọn cho thuê ở mức giá thấp hơn 5 USD/hour. Còn lời giải nào khác? Nhìn chung tự build thì có hai khả năng: Mua đồ sẵn như DGX123 thì các bạn cứ chuẩn bị 100k Mỹ kim trở lên. Mua bộ phận về tự ráp thì các bác tham khảo cấu hình của DGX rồi độ lại tùy theo nhu cầu. Tuy nhiên, chắc chỉ giảm được tiền công, và tối ưu một chút kiểu DGX dùng nhiều RAM thì mình giảm RAM xuống. Nói chung chắc cũng phải 50K Mỹ Kim. Về cá nhân, tôi thiên về thuê! Nếu tự build thì mua mấy cái RTX/GTX dòng Ti là ổn rồi. Tuy nhiên nếu bài toán lớn thì bạn bắt buộc phải dùng data center GPU thì lúc ấy phải có TIỀN! Kết luận Tài liệu tham khảo Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S., Uskoreit, J. and Houlsby, N. 2020. An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929. (2020).Details Carion, N., Massa, F., Synnaeve, G., Usunier, N., Kirillov, A. and Zagoruyko, S. 2020. End-to-end object detection with transformers. European conference on computer vision (2020), 213–229.Details Gao, P., Zheng, M., Wang, X., Dai, J. and Li, H. 2021. Fast convergence of detr with spatially modulated co-attention. Proceedings of the IEEE/CVF International Conference on Computer Vision (2021), 3621–3630.Details Ge, Z., Liu, S., Wang, F., Li, Z. and Sun, J. 2021. Yolox: Exceeding yolo series in 2021. arXiv preprint arXiv:2107.08430. (2021).Details Lin, T.-Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., Dollár, P. and Zitnick, C.L. 2014. Microsoft coco: Common objects in context. European conference on computer vision (2014), 740–755.Details Kuznetsova, A., Rom, H., Alldrin, N., Uijlings, J., Krasin, I., Pont-Tuset, J., Kamali, S., Popov, S., Malloci, M., Kolesnikov, A., Duerig, T. and Ferrari, V. 2020. The open images dataset v4. International Journal of Computer Vision. 128, 7 (2020), 1956–1981.Details https://www.nvidia.com/en-us/data-center/dgx-1/ &#8617; &#8617;2 https://www.nvidia.com/en-us/data-center/dgx-2/ &#8617; &#8617;2 https://www.nvidia.com/en-us/data-center/dgx-a100/ &#8617; &#8617;2" />
<meta property="og:site_name" content="AiFi" />
<meta property="og:image" content="/https://wanted2.github.io/assets/images/yolox.gif" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-02-12T00:00:00+09:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="/https://wanted2.github.io/assets/images/yolox.gif" />
<meta property="twitter:title" content="Seq2Seq for Computer Vision: Some state-of-the-arts and a thought on how to have a good GPU server" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"tuan"},"dateModified":"2022-02-12T00:00:00+09:00","datePublished":"2022-02-12T00:00:00+09:00","description":"Vision Transformers ViT [6] Source: Google DETR [6, 6] YOLOX [6] Xây dựng tài nguyên GPU Đầu tiên chúng ta sẽ xem SOTA ở mảng này xài máy móc thế nào? Rồi mình lại xem giá thành bộ đó qua đủ các phương án: tự xây và thuê xem có “vừa túi tiền” không nhá. Giá thành khi train model State-of-the-art (SOTA) Nhìn chung là nếu chỉ hình ảnh với bộ dữ liệu nhỏ nhỏ như COCO [6] tầm trăm ngàn ảnh thì có bảng giá dưới đây: chúng ta lấy ví dụ từ báo cáo của 1 state-of-the-art thì họ dùng 8 cái V100, train tầm 6 ngày liên tục (\\(6\\times 24\\) giờ) thì tổng tiền cho một lượt trên tầm ngàn Mỹ kim cho 6 ngày, 1 tháng cứ tầm 5 ngàn Mỹ kim. Mà các bạn cũng nhớ giá này là giá Spot tức là có thể bị interrupt giữa chừng nên mới rẻ thế. Chứ nếu bạn mà chọn on-demand thì có mà gấp 10 lần. Nhưng ở trên mới chỉ là giá bộ COCO có hơn 100k ảnh nhé. Bộ Open Images [6] với 1.7 triệu ảnh thì còn máu nữa. Search trên Kaggle mà có đồng chí chịu khó bỏ tiền ra ngồi train và báo cáo kết quả cho anh biết (xin cám ơn đồng chí): Kaggle Open Images 2019 challenge 6th place solution. Thì kết quả là đồng chí ấy báo cáo: train 8 models trên V100 (chắc lại EC2 P3 thôi thì mình cứ dùng p3.xlarge để làm phân tích giá nhé) rồi ensemble. mỗi model train mất 18-36 ngày (tùy model). Thì đồng chí này train 8 GPUs khác nhau. sau khi train xong các model thì mất thêm 1 ngày nữa để inference và 1 ngày nữa để ensemble (dùng NMS). Vậy tổng thể đã tiêu tốn \\(36\\times 8+1\\times 8+1=297\\) ngày train, tức là \\(297\\times 24=7128\\) giờ train. p3.xlarge thì giá mềm nhất là Spot cũng tầm $0.918/h. Tức là để train được accuracy tầm 60% đã mất \\(7128\\times 0.918\\) tức là tầm 6543 Mỹ kim và hơn tháng ngồi monitor màn hình train. Xây dựng hệ thống 8~16 GPU Nhìn chung thì theo dòng lịch sử có 3 loại NVIDIA GPU dành cho cloud khá thông dụng như sau (tôi không nói tới hai dòng GTX và RTX nhé): NVIDIA V100 hay Volta: nói đến dòng này chúng ta có những sự lựa chọn chủ yếu liên quan tới V100 Tensor Core mà đại diện cho thuê là p3.16xlarge và p3dn.24xlarge. Với băng thông mạng của phiên bản P3.16xlarge cao hơn tới 4 lần, phiên bản P3dn.24xlarge của Amazon EC2 là sự bổ sung mới nhất cho dòng phiên bản P3, được tối ưu hóa cho machine learning phân tán và các ứng dụng HPC. Các phiên bản này cung cấp thông lượng kết nối mạng lên tới 100 Gbps, 96 vCPU Intel® Xeon® Có thể mở rộng (Skylake) tùy chỉnh, 8 GPU NVIDIA® V100 Tensor Core với 32 GB bộ nhớ mỗi GPU và 1,8 TB ổ lưu trữ SSD cục bộ chuẩn NVMe. Các phiên bản P3dn.24xlarge cũng hỗ trợ Elastic Fabric Adapter (EFA). Giao diện này tăng tốc các ứng dụng machine learning phân tán sử dụng Thư viện giao tiếp chung NVIDIA (NCCL). EFA có thể mở rộng quy mô lên đến hàng nghìn GPU, cải thiện đáng kể thông lượng và khả năng mở rộng của các mô hình huấn luyện deep learning, từ đó cho kết quả nhanh hơn. Source: Amazon Web Service NVIDIA T4 hay Turing: với AWS EC2 thì bạn có thể thuê g4dn.metal. NVIDIA A100 hay Ampere: Với AWS EC2 thì có thể thuê p4d.24xlarge, với Azure HPC thì có thể thuê Standard_ND96amsr_A100_v4. GCP thì có a2-highgpu-8g hoặc bản 16 GPU là a2-highgpu-16g. Thì về mặt spec Ampere là khỏe nhất nếu nói về TFLOPS. Dưới đây là bảng giá thành của NVIDIA 8x A100 Tensor Core. Trong bảng này có 2 cột mà các bạn nên để ý là giá thành thuê theo giờ (Hourly cost) và tỷ lệ GFLOPS/USD (đáng giá thế nào). Giả định chung là hệ thống được xây dựng tối thiểu 4x GPU và được dùng ít nhất 24 tháng, mỗi tháng dùng 22 ngày (T7/CN nghỉ ngơi). Nói chung tự build thì các bạn có thể tham khảo cấu hình của DGX-11, DGX-22, và DGX-A1003 để mua các bộ phận về tự ráp thì sẽ tiết kiệm công lắp ráp, nhưng nhìn chung tôi nghĩ cũng phải 50 ngàn Mỹ Kim. Các cloud solutions Trong trường hợp bạn có bài toán train dữ liệu mà mất hàng tháng trời train với GTX/RTX thì bạn sẽ nghĩ phải thuê GPUs trên data center (8x-16x GPU). Thì ngoài AWS/Azure/GCP là khá cùng rank nên bảng giá không chênh lệch nhau mấy, bạn có thể tham khảo thêm các trang cho thuê GPU bên ngoài để tìm được chỗ thuê hợp lý hơn. Như kết quả tìm kiếm của AIFI thì hiện tại có trang vast.ai cung cấp khá nhiều sự lựa chọn cho thuê ở mức giá thấp hơn 5 USD/hour. Còn lời giải nào khác? Nhìn chung tự build thì có hai khả năng: Mua đồ sẵn như DGX123 thì các bạn cứ chuẩn bị 100k Mỹ kim trở lên. Mua bộ phận về tự ráp thì các bác tham khảo cấu hình của DGX rồi độ lại tùy theo nhu cầu. Tuy nhiên, chắc chỉ giảm được tiền công, và tối ưu một chút kiểu DGX dùng nhiều RAM thì mình giảm RAM xuống. Nói chung chắc cũng phải 50K Mỹ Kim. Về cá nhân, tôi thiên về thuê! Nếu tự build thì mua mấy cái RTX/GTX dòng Ti là ổn rồi. Tuy nhiên nếu bài toán lớn thì bạn bắt buộc phải dùng data center GPU thì lúc ấy phải có TIỀN! Kết luận Tài liệu tham khảo Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S., Uskoreit, J. and Houlsby, N. 2020. An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929. (2020).Details Carion, N., Massa, F., Synnaeve, G., Usunier, N., Kirillov, A. and Zagoruyko, S. 2020. End-to-end object detection with transformers. European conference on computer vision (2020), 213–229.Details Gao, P., Zheng, M., Wang, X., Dai, J. and Li, H. 2021. Fast convergence of detr with spatially modulated co-attention. Proceedings of the IEEE/CVF International Conference on Computer Vision (2021), 3621–3630.Details Ge, Z., Liu, S., Wang, F., Li, Z. and Sun, J. 2021. Yolox: Exceeding yolo series in 2021. arXiv preprint arXiv:2107.08430. (2021).Details Lin, T.-Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., Dollár, P. and Zitnick, C.L. 2014. Microsoft coco: Common objects in context. European conference on computer vision (2014), 740–755.Details Kuznetsova, A., Rom, H., Alldrin, N., Uijlings, J., Krasin, I., Pont-Tuset, J., Kamali, S., Popov, S., Malloci, M., Kolesnikov, A., Duerig, T. and Ferrari, V. 2020. The open images dataset v4. International Journal of Computer Vision. 128, 7 (2020), 1956–1981.Details https://www.nvidia.com/en-us/data-center/dgx-1/ &#8617; &#8617;2 https://www.nvidia.com/en-us/data-center/dgx-2/ &#8617; &#8617;2 https://www.nvidia.com/en-us/data-center/dgx-a100/ &#8617; &#8617;2","headline":"Seq2Seq for Computer Vision: Some state-of-the-arts and a thought on how to have a good GPU server","image":"/https://wanted2.github.io/assets/images/yolox.gif","mainEntityOfPage":{"@type":"WebPage","@id":"/https://wanted2.github.io/seq2seq-cv/"},"publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"/https://wanted2.github.io/assets/images/favicon.ico"},"name":"tuan"},"url":"/https://wanted2.github.io/seq2seq-cv/"}</script>
<!-- End Jekyll SEO tag -->


<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous">
    
<link href="https://wanted2.github.io/assets/css/screen.css" rel="stylesheet">

<link href="https://wanted2.github.io/assets/css/main.css" rel="stylesheet">

<script src="https://wanted2.github.io/assets/js/jquery.min.js"></script>
<script src="https://kit.fontawesome.com/d0b91d895e.js" crossorigin="anonymous"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        processEscapes: true
    }
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript" crossorigin="anonymous"></script>
<script src="https://d3js.org/d3.v4.js" crossorigin="anonymous"></script>
<!-- <script src="https://bl.ocks.org/mbostock/raw/4061502/0a200ddf998aa75dfdb1ff32e16b680a15e5cb01/box.js" crossorigin="anonymous"></script> -->
</head>


<body class="layout-post">
	<!-- defer loading of font and font awesome -->
	<noscript id="deferred-styles">
		<link href="https://fonts.googleapis.com/css?family=Righteous%7CMerriweather:300,300i,400,400i,700,700i" rel="stylesheet">
		<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.13/css/all.css" integrity="sha384-DNOHZ68U8hZfKXOrtjWvjxusGo9WQnrNx2sqG0tfsghAvtVlRW3tvkXWZh58N9jp" crossorigin="anonymous">
	</noscript>


<!-- Begin Menu Navigation
================================================== -->
<nav class="navbar navbar-expand-lg navbar-light bg-white fixed-top mediumnavigation nav-down">

    <div class="container pr-0">

    <!-- Begin Logo -->
    <a class="navbar-brand" href="https://wanted2.github.io/">
    <img src="https://wanted2.github.io/assets/images/favicon.ico" alt="AiFi">
    </a>
    <!-- End Logo -->

    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarMediumish" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
    </button>

    <div class="collapse navbar-collapse" id="navbarMediumish">

        <!-- Begin Menu -->

            <ul class="navbar-nav ml-auto">

                
                <li class="nav-item">
                
                <a class="nav-link" href="https://wanted2.github.io/">Blog</a>
                </li>

                <li class="nav-item">
                <a class="nav-link" href="https://wanted2.github.io/about">About</a>
                </li>

                <li class="nav-item">
                <a class="nav-link" href="https://wanted2.github.io/projects">Projects</a>
                </li>

                <!-- <li class="nav-item">
                <a target="_blank" class="nav-link" href="https://bootstrapstarter.com/bootstrap-templates/template-mediumish-bootstrap-jekyll/"> Docs</a>
                </li>

                <li class="nav-item">
                <a target="_blank" class="nav-link" href="https://www.wowthemes.net/themes/mediumish-wordpress/"><i class="fab fa-wordpress-simple"></i> WP Version</a>
                </li>

                <li class="nav-item">
                <a target="_blank" class="nav-link" href="https://www.wowthemes.net/themes/mediumish-ghost/"><i class="fab fa-snapchat-ghost"></i> Ghost Version</a>
                </li>

                <li class="nav-item">
                <a target="_blank" class="nav-link" href="https://github.com/wowthemesnet/mediumish-theme-jekyll"><i class="fab fa-github"></i> Fork on Github</a>
                </li> -->

                <!-- <script src="https://wanted2.github.io/assets/js/lunr.js"></script>


<style>
    .lunrsearchresult .title {color: #d9230f;}
    .lunrsearchresult .url {color: silver;}
    .lunrsearchresult a {display: block; color: #777;}
    .lunrsearchresult a:hover, .lunrsearchresult a:focus {text-decoration: none;}
    .lunrsearchresult a:hover .title {text-decoration: underline;}
</style>


<form class="bd-search" onSubmit="return lunr_search(document.getElementById('lunrsearch').value);">
    <input type="text" class="form-control text-small launch-modal-search" id="lunrsearch" name="q" maxlength="255" value="" placeholder="Type and enter..."/>
</form>

<div id="lunrsearchresults">
    <ul></ul>
</div>

<script src="https://wanted2.github.io/assets/js/lunrsearchengine.js"></script> -->

            </ul>

        <!-- End Menu -->

    </div>

    </div>
</nav>
<!-- End Navigation
================================================== -->

<div class="site-content">

<div class="container">

<!-- Site Title
================================================== -->
<div class="mainheading">
    <h1 class="sitetitle">AiFi</h1>
    <p class="lead">
        An AI Engineer's blog
    </p>
</div>

<!-- Content
================================================== -->
<div class="main-content">
    <!-- Begin Article
================================================== -->
<div class="container">
    <div class="row">

        <!-- Post Share -->
        <div class="col-md-2 pl-0">
            <div class="share sticky-top sticky-top-offset">
    <p>
        Share
    </p>
    <ul>
        <li class="ml-1 mr-1">
            <a target="_blank" href="https://twitter.com/intent/tweet?text=Seq2Seq for Computer Vision: Some state-of-the-arts and a thought on how to have a good GPU server&url=https://wanted2.github.io/seq2seq-cv/" onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
                <i class="fab fa-twitter"></i>
            </a>
        </li>

        <li class="ml-1 mr-1">
            <a target="_blank" href="https://facebook.com/sharer.php?u=https://wanted2.github.io/seq2seq-cv/" onclick="window.open(this.href, 'facebook-share', 'width=550,height=435');return false;">
                <i class="fab fa-facebook-f"></i>
            </a>
        </li>

        <li class="ml-1 mr-1">
            <a target="_blank" href="https://www.linkedin.com/shareArticle?mini=true&url=https://wanted2.github.io/seq2seq-cv/" onclick="window.open(this.href, 'width=550,height=435');return false;">
                <i class="fab fa-linkedin-in"></i>
            </a>
        </li>

        <li class="ml-1 mr-1">
            <a target="_blank" href="mailto:?subject=Seq2Seq for Computer Vision: Some state-of-the-arts and a thought on how to have a good GPU server&body=https://wanted2.github.io/seq2seq-cv/" onclick="window.open(this.href, 'width=550,height=435');return false;">
                <i class="fas fa-envelope"></i>
            </a>
        </li>

    </ul>
    
    <div class="sep">
    </div>
    <ul>
        <li>
        <a class="small smoothscroll" href="#disqus_thread"></a>
        </li>
    </ul>
    
    
    <div class="sep">

    </div>
    <ul>
        <li class="small">
        1354
     words</li>
        <li class="small">7 minutes</li>
    </ul>
</div>

        </div>

        <!-- Post -->
        

        <div class="col-md-9 flex-first flex-md-unordered">
            <div class="mainheading">

                <!-- Author Box -->
                
                <div class="row post-top-meta">
                    <div class="col-xs-12 col-md-2 col-lg-2 text-left mb-4 mb-md-0">
                        
                        <img class="author-thumb" src="https://wanted2.github.io/assets/images/favicon.png" alt="AiFi">
                        
                    </div>
                    <div class="col-xs-12 col-md-10 col-lg-10 text-right">
                        <a target="_blank" class="link-dark" href="">AiFi</a>
                        <!-- <a target="_blank" href="" class="btn follow">Follow</a> -->
                        <!-- LikeBtn.com BEGIN -->
                        <span class="likebtn-wrapper" 
                            data-site_id="61cfccd36fd08b2d68c1929e"
                            data-theme="custom" 
                            data-icon_l_url="/assets/images/OK_EM.png" 
                            data-icon_l_url_v="/assets/images/OK_EM_clicked.png" 
                            data-identifier="/seq2seq-cv/" 
                            data-show_like_label="false" 
                            data-like_enabled="false" 
                            data-dislike_enabled="false" 
                            data-icon_dislike_show="false" 
                            data-voting_cancelable="false" 
                            data-counter_show="true"
                            data-counter_frmt="comma"></span>
                        <script>(function(d,e,s){if(d.getElementById("likebtn_wjs"))return;a=d.createElement(e);m=d.getElementsByTagName(e)[0];a.async=1;a.id="likebtn_wjs";a.src=s;m.parentNode.insertBefore(a, m)})(document,"script","//w.likebtn.com/js/w/widget.js");</script>
                        <!-- LikeBtn.com END -->
                        <span class="author-description"></span>
                    </div>
                </div>
                

                <!-- Post Title -->
                <h1 class="posttitle">Seq2Seq for Computer Vision: Some state-of-the-arts and a thought on how to have a good GPU server</h1>

            </div>

            <!-- Adsense if enabled from _config.yml (change your pub id and slot) -->
            
            <!-- End Adsense -->

            <!-- Post Featured Image -->
            

            
            <img class="featured-image img-fluid lazyimg" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAMAAAACCAQAAAA3fa6RAAAADklEQVR42mNkAANGCAUAACMAA2w/AMgAAAAASUVORK5CYII=" data-src="https://wanted2.github.io/assets/images/yolox.gif" alt="Seq2Seq for Computer Vision: Some state-of-the-arts and a thought on how to have a good GPU server">
            

            
            <!-- End Featured Image -->

            <!-- Post Content -->
            <div class="article-post">
                <!-- Toc if any -->
                
                    
                    <div class="toc mt-4 mb-4 lead">
                        <h3 class="font-weight-bold">Summary</h3>
                        <ul>
  <li><a href="#vision-transformers">Vision Transformers</a>
    <ul>
      <li><a href="#vit-1">ViT <a class="citation" href="#dosovitskiy2020image">[1]</a></a></li>
      <li><a href="#detr-2-3">DETR <a class="citation" href="#carion2020end">[2, 3]</a></a></li>
      <li><a href="#yolox-4">YOLOX <a class="citation" href="#ge2021yolox">[4]</a></a></li>
    </ul>
  </li>
  <li><a href="#xây-dựng-tài-nguyên-gpu">Xây dựng tài nguyên GPU</a>
    <ul>
      <li><a href="#giá-thành-khi-train-model-state-of-the-art-sota">Giá thành khi train model State-of-the-art (SOTA)</a></li>
      <li><a href="#xây-dựng-hệ-thống-816-gpu">Xây dựng hệ thống 8~16 GPU</a></li>
      <li><a href="#các-cloud-solutions">Các cloud solutions</a></li>
      <li><a href="#còn-lời-giải-nào-khác">Còn lời giải nào khác?</a></li>
    </ul>
  </li>
  <li><a href="#kết-luận">Kết luận</a></li>
  <li><a href="#tài-liệu-tham-khảo">Tài liệu tham khảo</a></li>
</ul>
                    </div>
                
                <!-- End Toc -->
                <h1 id="vision-transformers">Vision Transformers</h1>

<h2 id="vit-1">ViT <a class="citation" href="#dosovitskiy2020image">[1]</a></h2>

<p><img src="https://media.giphy.com/media/ATsWtUsuuFRfq8OhZ7/source.gif" alt="" />
<em>Source: Google</em></p>

<h2 id="detr-2-3">DETR <a class="citation" href="#carion2020end">[2, 3]</a></h2>

<h2 id="yolox-4">YOLOX <a class="citation" href="#ge2021yolox">[4]</a></h2>

<iframe width="100%" height="480" src="https://www.youtube.com/embed/_5inpa6ruUY" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<h1 id="xây-dựng-tài-nguyên-gpu">Xây dựng tài nguyên GPU</h1>

<p>Đầu tiên chúng ta sẽ xem SOTA ở mảng này xài máy móc thế nào?
Rồi mình lại xem giá thành bộ đó qua đủ các phương án: tự xây và thuê xem có “vừa túi tiền” không nhá.</p>

<h2 id="giá-thành-khi-train-model-state-of-the-art-sota">Giá thành khi train model State-of-the-art (SOTA)</h2>

<p>Nhìn chung là nếu chỉ hình ảnh với bộ dữ liệu nhỏ nhỏ như COCO <a class="citation" href="#lin2014microsoft">[5]</a> tầm trăm ngàn ảnh thì có bảng giá dưới đây: chúng ta lấy ví dụ từ báo cáo của 1 state-of-the-art thì họ dùng 8 cái V100, train tầm 6 ngày liên tục (\(6\times 24\) giờ) thì tổng tiền cho một lượt trên tầm ngàn Mỹ kim cho 6 ngày, 1 tháng cứ tầm 5 ngàn Mỹ kim.
Mà các bạn cũng nhớ giá này là giá <a href="https://aws.amazon.com/ec2/spot/pricing/"><strong>Spot</strong></a> tức là có thể bị interrupt giữa chừng nên mới rẻ thế.
Chứ nếu bạn mà chọn <a href="https://aws.amazon.com/ec2/pricing/on-demand/"><strong>on-demand</strong></a> thì có mà gấp 10 lần.</p>

<p><img src="/assets/images/detr-cost-analysis.jpg" alt="pricing" /></p>

<p>Nhưng ở trên mới chỉ là giá bộ COCO có hơn 100k ảnh nhé.
Bộ Open Images <a class="citation" href="#kuznetsova2020open">[6]</a> với 1.7 triệu ảnh thì còn máu nữa.
Search trên Kaggle mà có đồng chí chịu khó bỏ tiền ra ngồi train và báo cáo kết quả cho anh biết (xin cám ơn đồng chí): <a href="https://www.kaggle.com/c/open-images-2019-object-detection/discussion/110953">Kaggle Open Images 2019 challenge 6th place solution</a>.
Thì kết quả là đồng chí ấy báo cáo:</p>
<ul>
  <li>train 8 models trên V100 (chắc lại EC2 P3 thôi thì mình cứ dùng <code class="language-plaintext highlighter-rouge">p3.xlarge</code> để làm phân tích giá nhé) rồi ensemble.</li>
  <li>mỗi model train mất 18-36 ngày (tùy model). Thì đồng chí này train 8 GPUs khác nhau.</li>
  <li>sau khi train xong các model thì mất thêm 1 ngày nữa để inference và 1 ngày nữa để ensemble (dùng NMS).</li>
  <li>Vậy tổng thể đã tiêu tốn \(36\times 8+1\times 8+1=297\) ngày train, tức là \(297\times 24=7128\) giờ train.</li>
</ul>

<p><img src="/assets/images/open-images-price.jpg" alt="pricing" /></p>

<p><code class="language-plaintext highlighter-rouge">p3.xlarge</code> thì giá mềm nhất là <a href="https://aws.amazon.com/ec2/spot/pricing/"><strong>Spot</strong></a> cũng tầm $0.918/h.</p>

<p>Tức là để train được accuracy tầm 60% đã mất \(7128\times 0.918\) tức là tầm 6543 Mỹ kim và hơn tháng ngồi monitor màn hình train.</p>

<h2 id="xây-dựng-hệ-thống-816-gpu">Xây dựng hệ thống 8~16 GPU</h2>

<p>Nhìn chung thì theo dòng lịch sử có 3 loại NVIDIA GPU dành cho cloud khá thông dụng như sau (tôi không nói tới hai dòng GTX và RTX nhé):</p>

<ul>
  <li>NVIDIA V100 hay <strong>Volta</strong>: nói đến dòng này chúng ta có những sự lựa chọn chủ yếu liên quan tới V100 Tensor Core mà đại diện cho thuê là <code class="language-plaintext highlighter-rouge">p3.16xlarge</code> và <code class="language-plaintext highlighter-rouge">p3dn.24xlarge</code>.</li>
</ul>

<blockquote>
  <p>Với băng thông mạng của phiên bản P3.16xlarge cao hơn tới 4 lần, phiên bản P3dn.24xlarge của Amazon EC2 là sự bổ sung mới nhất cho dòng phiên bản P3, được tối ưu hóa cho machine learning phân tán và các ứng dụng HPC. Các phiên bản này cung cấp thông lượng kết nối mạng lên tới 100 Gbps, 96 vCPU Intel® Xeon® Có thể mở rộng (Skylake) tùy chỉnh, 8 GPU NVIDIA® V100 Tensor Core với 32 GB bộ nhớ mỗi GPU và 1,8 TB ổ lưu trữ SSD cục bộ chuẩn NVMe. Các phiên bản P3dn.24xlarge cũng hỗ trợ Elastic Fabric Adapter (EFA). Giao diện này tăng tốc các ứng dụng machine learning phân tán sử dụng Thư viện giao tiếp chung NVIDIA (NCCL). EFA có thể mở rộng quy mô lên đến hàng nghìn GPU, cải thiện đáng kể thông lượng và khả năng mở rộng của các mô hình huấn luyện deep learning, từ đó cho kết quả nhanh hơn.
Source: Amazon Web Service</p>
</blockquote>

<ul>
  <li>NVIDIA T4 hay <strong>Turing</strong>: với AWS EC2 thì bạn có thể thuê <code class="language-plaintext highlighter-rouge">g4dn.metal</code>.</li>
  <li>NVIDIA A100 hay <strong>Ampere</strong>: Với AWS EC2 thì có thể thuê <code class="language-plaintext highlighter-rouge">p4d.24xlarge</code>, với Azure HPC thì có thể thuê <code class="language-plaintext highlighter-rouge">Standard_ND96amsr_A100_v4</code>. GCP thì có <code class="language-plaintext highlighter-rouge">a2-highgpu-8g</code> hoặc bản 16 GPU là <code class="language-plaintext highlighter-rouge">a2-highgpu-16g</code>.</li>
</ul>

<p>Thì về mặt spec Ampere là khỏe nhất nếu nói về TFLOPS.
Dưới đây là bảng giá thành của NVIDIA 8x A100 Tensor Core.
Trong bảng này có 2 cột mà các bạn nên để ý là giá thành thuê theo giờ (<strong>Hourly cost</strong>) và tỷ lệ GFLOPS/USD (đáng giá thế nào).
Giả định chung là hệ thống được xây dựng tối thiểu 4x GPU và được dùng ít nhất 24 tháng, mỗi tháng dùng 22 ngày (T7/CN nghỉ ngơi).</p>

<p><img src="/assets/images/ampere.png" alt="ampere" /></p>

<p>Nói chung tự build thì các bạn có thể tham khảo cấu hình của DGX-1<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup>, DGX-2<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup>, và DGX-A100<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote" rel="footnote">3</a></sup> để mua các bộ phận về tự ráp thì sẽ tiết kiệm công lắp ráp, nhưng nhìn chung tôi nghĩ cũng phải 50 ngàn Mỹ Kim.</p>

<h2 id="các-cloud-solutions">Các cloud solutions</h2>
<p>Trong trường hợp bạn có bài toán train dữ liệu mà mất hàng tháng trời train với GTX/RTX thì bạn sẽ nghĩ phải thuê GPUs trên data center (8x-16x GPU).
Thì ngoài AWS/Azure/GCP là khá cùng rank nên bảng giá không chênh lệch nhau mấy, bạn có thể tham khảo thêm các trang cho thuê GPU bên ngoài để tìm được chỗ thuê hợp lý hơn.
Như kết quả tìm kiếm của AIFI thì hiện tại có trang <a href="https://vast.ai">vast.ai</a> cung cấp khá nhiều sự lựa chọn cho thuê ở mức giá thấp hơn 5 USD/hour.</p>

<h2 id="còn-lời-giải-nào-khác">Còn lời giải nào khác?</h2>

<p>Nhìn chung tự build thì có hai khả năng:</p>
<ul>
  <li><strong>Mua đồ sẵn</strong> như DGX<sup id="fnref:1:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup><sup id="fnref:2:1" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup><sup id="fnref:3:1" role="doc-noteref"><a href="#fn:3" class="footnote" rel="footnote">3</a></sup> thì các bạn cứ chuẩn bị 100k Mỹ kim trở lên.</li>
  <li><strong>Mua bộ phận về tự ráp</strong> thì các bác tham khảo cấu hình của DGX rồi độ lại tùy theo nhu cầu. Tuy nhiên, chắc chỉ giảm được tiền công, và tối ưu một chút kiểu DGX dùng nhiều RAM thì mình giảm RAM xuống. Nói chung chắc cũng phải 50K Mỹ Kim.</li>
</ul>

<p>Về cá nhân, tôi thiên về thuê!
Nếu tự build thì mua mấy cái RTX/GTX dòng Ti là ổn rồi.
Tuy nhiên nếu bài toán lớn thì bạn bắt buộc phải dùng data center GPU thì lúc ấy phải có <strong>TIỀN</strong>!</p>

<h1 id="kết-luận">Kết luận</h1>

<h1 id="tài-liệu-tham-khảo">Tài liệu tham khảo</h1>

<ol class="bibliography"><li><span id="dosovitskiy2020image">Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S., Uskoreit, J. and Houlsby, N. 2020. An image is worth 16x16 words: Transformers for image recognition at scale. <i>arXiv preprint arXiv:2010.11929</i>. (2020).</span><a class="details" href="https://wanted2.github.io/bibliography/dosovitskiy2020image/">Details</a></li>
<li><span id="carion2020end">Carion, N., Massa, F., Synnaeve, G., Usunier, N., Kirillov, A. and Zagoruyko, S. 2020. End-to-end object detection with transformers. <i>European conference on computer vision</i> (2020), 213–229.</span><a class="details" href="https://wanted2.github.io/bibliography/carion2020end/">Details</a></li>
<li><span id="gao2021fast">Gao, P., Zheng, M., Wang, X., Dai, J. and Li, H. 2021. Fast convergence of detr with spatially modulated co-attention. <i>Proceedings of the IEEE/CVF International Conference on Computer Vision</i> (2021), 3621–3630.</span><a class="details" href="https://wanted2.github.io/bibliography/gao2021fast/">Details</a></li>
<li><span id="ge2021yolox">Ge, Z., Liu, S., Wang, F., Li, Z. and Sun, J. 2021. Yolox: Exceeding yolo series in 2021. <i>arXiv preprint arXiv:2107.08430</i>. (2021).</span><a class="details" href="https://wanted2.github.io/bibliography/ge2021yolox/">Details</a></li>
<li><span id="lin2014microsoft">Lin, T.-Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., Dollár, P. and Zitnick, C.L. 2014. Microsoft coco: Common objects in context. <i>European conference on computer vision</i> (2014), 740–755.</span><a class="details" href="https://wanted2.github.io/bibliography/lin2014microsoft/">Details</a></li>
<li><span id="kuznetsova2020open">Kuznetsova, A., Rom, H., Alldrin, N., Uijlings, J., Krasin, I., Pont-Tuset, J., Kamali, S., Popov, S., Malloci, M., Kolesnikov, A., Duerig, T. and Ferrari, V. 2020. The open images dataset v4. <i>International Journal of Computer Vision</i>. 128, 7 (2020), 1956–1981.</span><a class="details" href="https://wanted2.github.io/bibliography/kuznetsova2020open/">Details</a></li></ol>
<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p><a href="https://www.nvidia.com/en-us/data-center/dgx-1/">https://www.nvidia.com/en-us/data-center/dgx-1/</a> <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a> <a href="#fnref:1:1" class="reversefootnote" role="doc-backlink">&#8617;<sup>2</sup></a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p><a href="https://www.nvidia.com/en-us/data-center/dgx-2/">https://www.nvidia.com/en-us/data-center/dgx-2/</a> <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a> <a href="#fnref:2:1" class="reversefootnote" role="doc-backlink">&#8617;<sup>2</sup></a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p><a href="https://www.nvidia.com/en-us/data-center/dgx-a100/">https://www.nvidia.com/en-us/data-center/dgx-a100/</a> <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a> <a href="#fnref:3:1" class="reversefootnote" role="doc-backlink">&#8617;<sup>2</sup></a></p>
    </li>
  </ol>
</div>

            </div>

            <!-- Rating -->
            

            <!-- Post Date -->
            <p>
            <small>
                <span class="post-date"><time class="post-date" datetime="2022-02-12">12 Feb 2022</time></span>           
                
                </small>
            </p>

            <!-- Post Categories -->
            <div class="after-post-cats">
                <ul class="tags mb-4">
                    
                    
                    <li>
                        <a class="smoothscroll" href="https://wanted2.github.io/categories#Artificial-Intelligence">Artificial Intelligence</a>
                    </li>
                    
                    <li>
                        <a class="smoothscroll" href="https://wanted2.github.io/categories#Computer-Vision">Computer Vision</a>
                    </li>
                    
                    <li>
                        <a class="smoothscroll" href="https://wanted2.github.io/categories#Tiếng-Việt,-日本語">Tiếng Việt, 日本語</a>
                    </li>
                    
                </ul>
            </div>
            <!-- End Categories -->

            <!-- Post Tags -->
            <div class="after-post-tags">
                <ul class="tags">
                    
                    
                    <li>
                        <a class="smoothscroll" href="https://wanted2.github.io/tags#BERT">#BERT</a>
                    </li>
                    
                    <li>
                        <a class="smoothscroll" href="https://wanted2.github.io/tags#Image-Segmentation">#Image Segmentation</a>
                    </li>
                    
                    <li>
                        <a class="smoothscroll" href="https://wanted2.github.io/tags#Object-Detection">#Object Detection</a>
                    </li>
                    
                    <li>
                        <a class="smoothscroll" href="https://wanted2.github.io/tags#Object-Recognition">#Object Recognition</a>
                    </li>
                    
                    <li>
                        <a class="smoothscroll" href="https://wanted2.github.io/tags#Self-supervised-learning">#Self-supervised learning</a>
                    </li>
                    
                    <li>
                        <a class="smoothscroll" href="https://wanted2.github.io/tags#Sequence-to-sequence">#Sequence-to-sequence</a>
                    </li>
                    
                    <li>
                        <a class="smoothscroll" href="https://wanted2.github.io/tags#Temporal-Segmentation">#Temporal Segmentation</a>
                    </li>
                    
                    <li>
                        <a class="smoothscroll" href="https://wanted2.github.io/tags#Transformer">#Transformer</a>
                    </li>
                    
                    <li>
                        <a class="smoothscroll" href="https://wanted2.github.io/tags#Vision-Transformer">#Vision Transformer</a>
                    </li>
                    
                    <li>
                        <a class="smoothscroll" href="https://wanted2.github.io/tags#seq2seq">#seq2seq</a>
                    </li>
                    
                </ul>
            </div>
            <!-- End Tags -->

            <!-- Prev/Next -->
            <div class="row PageNavigation d-flex justify-content-between font-weight-bold">
            
            <a class="prev d-block col-md-6" href="https://wanted2.github.io//rapidapi/"> &laquo; RapidAPI and RapidAPI Hub</a>
            
            
            <div class="clearfix"></div>
            </div>
            <!-- End Categories -->

        </div>
        <!-- End Post -->

    </div>
</div>
<!-- End Article
================================================== -->

<!-- Begin Comments
================================================== -->

    <div class="container">
        <div id="comments" class="row justify-content-center mb-5">
            <div class="col-md-8">
                <section class="disqus">
    <div id="disqus_thread"></div>
    <script type="text/javascript">
        var disqus_shortname = 'caineng'; 
        var disqus_developer = 0;
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = window.location.protocol + '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</section>

            </div>
        </div>
    </div>

<!--End Comments
================================================== -->

<!-- Review with LD-JSON, adapt it for your needs if you like, but make sure you test the generated HTML source code first: 
https://search.google.com/structured-data/testing-tool/u/0/
================================================== -->

</div>


<!-- Bottom Alert Bar
================================================== -->
<div class="alertbar">
	<div class="container text-center">
		<span><img src="https://wanted2.github.io/assets/images/favicon.ico" alt="AiFi" style="max-height: 48px;" /> &nbsp; Never miss a <b>story</b> from us, subscribe to our newsletter</span>
        <form action="https://caineng.us20.list-manage.com/subscribe/post?u=76342d3d74a6807aac5aec0d7&id=b5645e19be" method="post" name="mc-embedded-subscribe-form" class="wj-contact-form validate" target="_blank" novalidate>
            <div class="mc-field-group">
            <input type="email" placeholder="Email" name="EMAIL" class="required email" id="mce-EMAIL" autocomplete="on" required>
            <input type="submit" value="Subscribe" name="subscribe" class="heart">
            </div>
        </form>
	</div>
</div>

    
</div>

<!-- Categories Jumbotron
================================================== -->
<div class="jumbotron fortags">
	<div class="d-md-flex h-100">
		<div class="col-md-4 transpdark align-self-center text-center h-100">
            <div class="d-md-flex align-items-center justify-content-center h-100">
                <h2 class="d-md-block align-self-center py-1 font-weight-light">Explore <span class="d-none d-md-inline">→</span></h2>
            </div>
		</div>
		<div class="col-md-8 p-5 align-self-center text-center">
            
            
                
                    <a class="mt-1 mb-1" href="https://wanted2.github.io/categories#Site-Reliable-Engineering">Site Reliable Engineering (5)</a>
                
                    <a class="mt-1 mb-1" href="https://wanted2.github.io/categories#Software-Engineering">Software Engineering (17)</a>
                
                    <a class="mt-1 mb-1" href="https://wanted2.github.io/categories#Computer-Vision">Computer Vision (5)</a>
                
                    <a class="mt-1 mb-1" href="https://wanted2.github.io/categories#Artificial-Intelligence">Artificial Intelligence (11)</a>
                
                    <a class="mt-1 mb-1" href="https://wanted2.github.io/categories#Tiếng-Việt,-日本語">Tiếng Việt, 日本語 (11)</a>
                
                    <a class="mt-1 mb-1" href="https://wanted2.github.io/categories#Project-Management">Project Management (23)</a>
                
            
            
		</div>
	</div>
</div>

<!-- Begin Footer
================================================== -->
<footer class="footer">
    <div class="container">
        <div class="row">
            <div class="col-md-6 col-sm-6 text-center text-lg-left">
                Copyright © 2022 AiFi 
            </div>
            <div class="col-md-6 col-sm-6 text-center text-lg-right">    
                <a target="_blank" href="https://www.wowthemes.net/mediumish-free-jekyll-template/">Mediumish Jekyll Theme</a> by WowThemes.net
            </div>
        </div>
    </div>
</footer>
<!-- End Footer
================================================== -->

</div> <!-- /.site-content -->

<!-- Scripts
================================================== -->

<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js" integrity="sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut" crossorigin="anonymous"></script>

<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js" integrity="sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k" crossorigin="anonymous"></script>

<script src="https://wanted2.github.io/assets/js/mediumish.js"></script>


<script src="https://wanted2.github.io/assets/js/lazyload.js"></script>


<script src="https://wanted2.github.io/assets/js/ie10-viewport-bug-workaround.js"></script> 


<script id="dsq-count-scr" src="//caineng.disqus.com/count.js"></script>


</body>
</html>
