<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<link rel="icon" href="https://wanted2.github.io/assets/images/favicon.ico">

<title>Seq2Seq và kiến trúc Encoder-Decoder | AiFi</title>

 
    
        <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=G-2CDTCF0EP6" crossorigin="anonymous"></script>
        <script>
            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());

            gtag('config', 'G-2CDTCF0EP6');
        </script>
    


<!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Seq2Seq và kiến trúc Encoder-Decoder | AiFi</title>
<meta name="generator" content="Jekyll v4.2.1" />
<meta property="og:title" content="Seq2Seq và kiến trúc Encoder-Decoder" />
<meta name="author" content="tuan" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Hôm trước ngồi đọc về GAN thấy nhiều bài trên vài ngàn tới 20,000 trích dẫn, hôm nay đọc tiếp cái sequence-to-sequence (Seq2Seq) cũng thấy có cả 30k-40k cũng có. Thế nên là cái Seq2Seq này cũng phải theo bài cũ: chỉ đọc những cái có trung bình trên 300 citations/năm (GAN thì ngưỡng threshold là 200 citations/năm, nhưng sang cái Seq2Seq này là chỉ cần tìm hiểu những bài có độ tăng trưởng trên 300 trích dẫn/năm). Chứ đọc làm sao mà hết được? Ví dụ mấy bài từ năm 2018 mà tính đến nay 2022 là 4 năm mà dưới 1200 trích dẫn là nhìn chung độ tăng trưởng thấp. Tập hợp lại những papers có độ tăng trưởng mạnh từ tầm 2013 trở lại thì liên quan tới chủ để này tầm hơn trăm tấm, nói chung thượng vàng hạ cám. Có bài như bài gốc Transformer (Attention is all you need, [12]) mới ra đời từ 2017 mà đã hơn 35k trích dẫn! Seq2Seq [12, 12, 12] là một giải pháp kiến trúc được dùng khá nhiều trong các bài toán NLP và vision như Neural Machine Translation (NMT, [12]), Question-Answering (QA, [12]), Visual Question Answering (VQA, [12]), Text Summarization (TS, [12, 12]) và Video-To-Text (VTT, [12]). Bài toán Image Captioning thì cũng có thể ứng dụng seq2seq nếu thông minh hơn một tí, sử dụng object detector để detect attributes và coi attribute sequence đó thành input vào seq2seq như trong bài Semantic Attention (SA) [12] hay Densecap [12]. Nên nhìn chung là seq2seq là 1 technique mà có thể dùng vào nhiều nhiệm vụ và rất hữu dụng [12]." />
<meta property="og:description" content="Hôm trước ngồi đọc về GAN thấy nhiều bài trên vài ngàn tới 20,000 trích dẫn, hôm nay đọc tiếp cái sequence-to-sequence (Seq2Seq) cũng thấy có cả 30k-40k cũng có. Thế nên là cái Seq2Seq này cũng phải theo bài cũ: chỉ đọc những cái có trung bình trên 300 citations/năm (GAN thì ngưỡng threshold là 200 citations/năm, nhưng sang cái Seq2Seq này là chỉ cần tìm hiểu những bài có độ tăng trưởng trên 300 trích dẫn/năm). Chứ đọc làm sao mà hết được? Ví dụ mấy bài từ năm 2018 mà tính đến nay 2022 là 4 năm mà dưới 1200 trích dẫn là nhìn chung độ tăng trưởng thấp. Tập hợp lại những papers có độ tăng trưởng mạnh từ tầm 2013 trở lại thì liên quan tới chủ để này tầm hơn trăm tấm, nói chung thượng vàng hạ cám. Có bài như bài gốc Transformer (Attention is all you need, [12]) mới ra đời từ 2017 mà đã hơn 35k trích dẫn! Seq2Seq [12, 12, 12] là một giải pháp kiến trúc được dùng khá nhiều trong các bài toán NLP và vision như Neural Machine Translation (NMT, [12]), Question-Answering (QA, [12]), Visual Question Answering (VQA, [12]), Text Summarization (TS, [12, 12]) và Video-To-Text (VTT, [12]). Bài toán Image Captioning thì cũng có thể ứng dụng seq2seq nếu thông minh hơn một tí, sử dụng object detector để detect attributes và coi attribute sequence đó thành input vào seq2seq như trong bài Semantic Attention (SA) [12] hay Densecap [12]. Nên nhìn chung là seq2seq là 1 technique mà có thể dùng vào nhiều nhiệm vụ và rất hữu dụng [12]." />
<meta property="og:site_name" content="AiFi" />
<meta property="og:image" content="/https://wanted2.github.io/assets/images/san01.jpg" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-02-01T00:00:00+09:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="/https://wanted2.github.io/assets/images/san01.jpg" />
<meta property="twitter:title" content="Seq2Seq và kiến trúc Encoder-Decoder" />
<script type="application/ld+json">
{"headline":"Seq2Seq và kiến trúc Encoder-Decoder","dateModified":"2022-02-01T00:00:00+09:00","datePublished":"2022-02-01T00:00:00+09:00","description":"Hôm trước ngồi đọc về GAN thấy nhiều bài trên vài ngàn tới 20,000 trích dẫn, hôm nay đọc tiếp cái sequence-to-sequence (Seq2Seq) cũng thấy có cả 30k-40k cũng có. Thế nên là cái Seq2Seq này cũng phải theo bài cũ: chỉ đọc những cái có trung bình trên 300 citations/năm (GAN thì ngưỡng threshold là 200 citations/năm, nhưng sang cái Seq2Seq này là chỉ cần tìm hiểu những bài có độ tăng trưởng trên 300 trích dẫn/năm). Chứ đọc làm sao mà hết được? Ví dụ mấy bài từ năm 2018 mà tính đến nay 2022 là 4 năm mà dưới 1200 trích dẫn là nhìn chung độ tăng trưởng thấp. Tập hợp lại những papers có độ tăng trưởng mạnh từ tầm 2013 trở lại thì liên quan tới chủ để này tầm hơn trăm tấm, nói chung thượng vàng hạ cám. Có bài như bài gốc Transformer (Attention is all you need, [12]) mới ra đời từ 2017 mà đã hơn 35k trích dẫn! Seq2Seq [12, 12, 12] là một giải pháp kiến trúc được dùng khá nhiều trong các bài toán NLP và vision như Neural Machine Translation (NMT, [12]), Question-Answering (QA, [12]), Visual Question Answering (VQA, [12]), Text Summarization (TS, [12, 12]) và Video-To-Text (VTT, [12]). Bài toán Image Captioning thì cũng có thể ứng dụng seq2seq nếu thông minh hơn một tí, sử dụng object detector để detect attributes và coi attribute sequence đó thành input vào seq2seq như trong bài Semantic Attention (SA) [12] hay Densecap [12]. Nên nhìn chung là seq2seq là 1 technique mà có thể dùng vào nhiều nhiệm vụ và rất hữu dụng [12].","mainEntityOfPage":{"@type":"WebPage","@id":"/https://wanted2.github.io/seq2seq/"},"image":"/https://wanted2.github.io/assets/images/san01.jpg","url":"/https://wanted2.github.io/seq2seq/","author":{"@type":"Person","name":"tuan"},"publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"/https://wanted2.github.io/assets/images/favicon.ico"},"name":"tuan"},"@type":"BlogPosting","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous">
    
<link href="https://wanted2.github.io/assets/css/screen.css" rel="stylesheet">

<link href="https://wanted2.github.io/assets/css/main.css" rel="stylesheet">

<script src="https://wanted2.github.io/assets/js/jquery.min.js"></script>
<script src="https://kit.fontawesome.com/d0b91d895e.js" crossorigin="anonymous"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        processEscapes: true
    }
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript" crossorigin="anonymous"></script>
<script src="https://d3js.org/d3.v4.js" crossorigin="anonymous"></script>
<!-- <script src="https://bl.ocks.org/mbostock/raw/4061502/0a200ddf998aa75dfdb1ff32e16b680a15e5cb01/box.js" crossorigin="anonymous"></script> -->
</head>


<body class="layout-post">
	<!-- defer loading of font and font awesome -->
	<noscript id="deferred-styles">
		<link href="https://fonts.googleapis.com/css?family=Righteous%7CMerriweather:300,300i,400,400i,700,700i" rel="stylesheet">
		<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.13/css/all.css" integrity="sha384-DNOHZ68U8hZfKXOrtjWvjxusGo9WQnrNx2sqG0tfsghAvtVlRW3tvkXWZh58N9jp" crossorigin="anonymous">
	</noscript>


<!-- Begin Menu Navigation
================================================== -->
<nav class="navbar navbar-expand-lg navbar-light bg-white fixed-top mediumnavigation nav-down">

    <div class="container pr-0">

    <!-- Begin Logo -->
    <a class="navbar-brand" href="https://wanted2.github.io/">
    <img src="https://wanted2.github.io/assets/images/favicon.ico" alt="AiFi">
    </a>
    <!-- End Logo -->

    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarMediumish" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
    </button>

    <div class="collapse navbar-collapse" id="navbarMediumish">

        <!-- Begin Menu -->

            <ul class="navbar-nav ml-auto">

                
                <li class="nav-item">
                
                <a class="nav-link" href="https://wanted2.github.io/">Blog</a>
                </li>

                <li class="nav-item">
                <a class="nav-link" href="https://wanted2.github.io/about">About</a>
                </li>

                <li class="nav-item">
                <a class="nav-link" href="https://wanted2.github.io/projects">Projects</a>
                </li>

                <!-- <li class="nav-item">
                <a target="_blank" class="nav-link" href="https://bootstrapstarter.com/bootstrap-templates/template-mediumish-bootstrap-jekyll/"> Docs</a>
                </li>

                <li class="nav-item">
                <a target="_blank" class="nav-link" href="https://www.wowthemes.net/themes/mediumish-wordpress/"><i class="fab fa-wordpress-simple"></i> WP Version</a>
                </li>

                <li class="nav-item">
                <a target="_blank" class="nav-link" href="https://www.wowthemes.net/themes/mediumish-ghost/"><i class="fab fa-snapchat-ghost"></i> Ghost Version</a>
                </li>

                <li class="nav-item">
                <a target="_blank" class="nav-link" href="https://github.com/wowthemesnet/mediumish-theme-jekyll"><i class="fab fa-github"></i> Fork on Github</a>
                </li> -->

                <!-- <script src="https://wanted2.github.io/assets/js/lunr.js"></script>


<style>
    .lunrsearchresult .title {color: #d9230f;}
    .lunrsearchresult .url {color: silver;}
    .lunrsearchresult a {display: block; color: #777;}
    .lunrsearchresult a:hover, .lunrsearchresult a:focus {text-decoration: none;}
    .lunrsearchresult a:hover .title {text-decoration: underline;}
</style>


<form class="bd-search" onSubmit="return lunr_search(document.getElementById('lunrsearch').value);">
    <input type="text" class="form-control text-small launch-modal-search" id="lunrsearch" name="q" maxlength="255" value="" placeholder="Type and enter..."/>
</form>

<div id="lunrsearchresults">
    <ul></ul>
</div>

<script src="https://wanted2.github.io/assets/js/lunrsearchengine.js"></script> -->

            </ul>

        <!-- End Menu -->

    </div>

    </div>
</nav>
<!-- End Navigation
================================================== -->

<div class="site-content">

<div class="container">

<!-- Site Title
================================================== -->
<div class="mainheading">
    <h1 class="sitetitle">AiFi</h1>
    <p class="lead">
        An AI Engineer's blog
    </p>
</div>

<!-- Content
================================================== -->
<div class="main-content">
    <!-- Begin Article
================================================== -->
<div class="container">
    <div class="row">

        <!-- Post Share -->
        <div class="col-md-2 pl-0">
            <div class="share sticky-top sticky-top-offset">
    <p>
        Share
    </p>
    <ul>
        <li class="ml-1 mr-1">
            <a target="_blank" href="https://twitter.com/intent/tweet?text=Seq2Seq và kiến trúc Encoder-Decoder&url=https://wanted2.github.io/seq2seq/" onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
                <i class="fab fa-twitter"></i>
            </a>
        </li>

        <li class="ml-1 mr-1">
            <a target="_blank" href="https://facebook.com/sharer.php?u=https://wanted2.github.io/seq2seq/" onclick="window.open(this.href, 'facebook-share', 'width=550,height=435');return false;">
                <i class="fab fa-facebook-f"></i>
            </a>
        </li>

        <li class="ml-1 mr-1">
            <a target="_blank" href="https://www.linkedin.com/shareArticle?mini=true&url=https://wanted2.github.io/seq2seq/" onclick="window.open(this.href, 'width=550,height=435');return false;">
                <i class="fab fa-linkedin-in"></i>
            </a>
        </li>

        <li class="ml-1 mr-1">
            <a target="_blank" href="mailto:?subject=Seq2Seq và kiến trúc Encoder-Decoder&body=https://wanted2.github.io/seq2seq/" onclick="window.open(this.href, 'width=550,height=435');return false;">
                <i class="fas fa-envelope"></i>
            </a>
        </li>

    </ul>
    
    <div class="sep">
    </div>
    <ul>
        <li>
        <a class="small smoothscroll" href="#disqus_thread"></a>
        </li>
    </ul>
    
</div>

        </div>

        <!-- Post -->
        

        <div class="col-md-9 flex-first flex-md-unordered">
            <div class="mainheading">

                <!-- Author Box -->
                
                <div class="row post-top-meta">
                    <div class="col-xs-12 col-md-2 col-lg-2 text-left mb-4 mb-md-0">
                        
                        <img class="author-thumb" src="https://wanted2.github.io/assets/images/favicon.png" alt="AiFi">
                        
                    </div>
                    <div class="col-xs-12 col-md-10 col-lg-10 text-right">
                        <a target="_blank" class="link-dark" href="">AiFi</a>
                        <!-- <a target="_blank" href="" class="btn follow">Follow</a> -->
                        <!-- LikeBtn.com BEGIN -->
                        <span class="likebtn-wrapper" 
                            data-site_id="61cfccd36fd08b2d68c1929e"
                            data-theme="custom" 
                            data-icon_l_url="/assets/images/OK_EM.png" 
                            data-icon_l_url_v="/assets/images/OK_EM_clicked.png" 
                            data-identifier="/seq2seq/" 
                            data-show_like_label="false" 
                            data-like_enabled="false" 
                            data-dislike_enabled="false" 
                            data-icon_dislike_show="false" 
                            data-voting_cancelable="false" 
                            data-counter_show="true"
                            data-counter_frmt="comma"></span>
                        <script>(function(d,e,s){if(d.getElementById("likebtn_wjs"))return;a=d.createElement(e);m=d.getElementsByTagName(e)[0];a.async=1;a.id="likebtn_wjs";a.src=s;m.parentNode.insertBefore(a, m)})(document,"script","//w.likebtn.com/js/w/widget.js");</script>
                        <!-- LikeBtn.com END -->
                        <span class="author-description"></span>
                    </div>
                </div>
                

                <!-- Post Title -->
                <h1 class="posttitle">Seq2Seq và kiến trúc Encoder-Decoder</h1>

            </div>

            <!-- Adsense if enabled from _config.yml (change your pub id and slot) -->
            
            <!-- End Adsense -->

            <!-- Post Featured Image -->
            

            
            <img class="featured-image img-fluid lazyimg" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAMAAAACCAQAAAA3fa6RAAAADklEQVR42mNkAANGCAUAACMAA2w/AMgAAAAASUVORK5CYII=" data-src="https://wanted2.github.io/assets/images/san01.jpg" alt="Seq2Seq và kiến trúc Encoder-Decoder">
            

            
            <!-- End Featured Image -->

            <!-- Post Content -->
            <div class="article-post">
                <!-- Toc if any -->
                
                    
                    <div class="toc mt-4 mb-4 lead">
                        <h3 class="font-weight-bold">Summary</h3>
                        <ul>
  <li><a href="#giới-thiệu-model-seq2seq">Giới thiệu model Seq2Seq</a>
    <ul>
      <li><a href="#recurrent-neural-nets-long-short-term-memory-và-gated-recurrent-units">Recurrent Neural Nets, Long-Short Term Memory và Gated Recurrent Units</a></li>
      <li><a href="#kiến-trúc-seq2seq-s2s">Kiến trúc Seq2Seq (S2S)</a></li>
      <li><a href="#anh-em-nhà-bert">Anh em nhà BERT</a></li>
    </ul>
  </li>
  <li><a href="#ứng-dụng">Ứng dụng</a>
    <ul>
      <li><a href="#neural-machine-translation-nmt">Neural Machine Translation (NMT)</a></li>
      <li><a href="#text-summarization">Text Summarization</a></li>
      <li><a href="#qa-và-vqa">QA và VQA</a></li>
      <li><a href="#video-to-text-và-image-captioning">Video-to-Text và Image Captioning</a></li>
    </ul>
  </li>
  <li><a href="#kết-luận">Kết luận</a></li>
  <li><a href="#tài-liệu-tham-khảo">Tài liệu tham khảo</a></li>
</ul>
                    </div>
                
                <!-- End Toc -->
                <blockquote>
  <p><a href="/aws-account/">Hôm trước ngồi đọc về GAN thấy nhiều bài trên vài ngàn tới 20,000 trích dẫn</a>, hôm nay đọc tiếp cái <code class="language-plaintext highlighter-rouge">sequence-to-sequence</code> (<code class="language-plaintext highlighter-rouge">Seq2Seq</code>) cũng thấy có cả 30k-40k cũng có.
Thế nên là cái <code class="language-plaintext highlighter-rouge">Seq2Seq</code> này cũng phải theo bài cũ: chỉ đọc những cái có trung bình trên 300 citations/năm (GAN thì ngưỡng threshold là 200 citations/năm, nhưng sang cái <code class="language-plaintext highlighter-rouge">Seq2Seq</code> này là chỉ cần tìm hiểu những bài có độ tăng trưởng trên 300 trích dẫn/năm).
Chứ đọc làm sao mà hết được?
Ví dụ mấy bài từ năm 2018 mà tính đến nay 2022 là 4 năm mà dưới 1200 trích dẫn là nhìn chung độ tăng trưởng thấp.
Tập hợp lại những papers có độ tăng trưởng mạnh từ tầm 2013 trở lại thì liên quan tới chủ để này tầm hơn trăm tấm, nói chung thượng vàng hạ cám. 
Có bài như bài gốc Transformer (Attention is all you need, <a class="citation" href="#vaswani2017attention">[1]</a>) mới ra đời từ 2017 mà đã hơn 35k trích dẫn!</p>
</blockquote>

<p><code class="language-plaintext highlighter-rouge">Seq2Seq</code> <a class="citation" href="#kalchbrenner2013recurrent">[2, 3, 4]</a> là một giải pháp kiến trúc được dùng khá nhiều trong các bài toán NLP và vision như Neural Machine Translation (NMT, <a class="citation" href="#sutskever2014sequence">[3]</a>), Question-Answering (QA, <a class="citation" href="#rajpurkar2016squad">[5]</a>), Visual Question Answering (VQA, <a class="citation" href="#antol2015vqa">[6]</a>), Text Summarization (TS, <a class="citation" href="#rush2015neural">[7, 8]</a>) và Video-To-Text (VTT, <a class="citation" href="#venugopalan2015sequence">[9]</a>).
Bài toán Image Captioning thì cũng có thể ứng dụng <code class="language-plaintext highlighter-rouge">seq2seq</code> nếu thông minh hơn một tí, sử dụng object detector để detect attributes và coi attribute sequence đó thành input vào <code class="language-plaintext highlighter-rouge">seq2seq</code> như trong bài <em>Semantic Attention (SA) <a class="citation" href="#you2016image">[10]</a></em> hay <em>Densecap <a class="citation" href="#johnson2016densecap">[11]</a></em>.
Nên nhìn chung là <code class="language-plaintext highlighter-rouge">seq2seq</code> là 1 technique mà có thể dùng vào nhiều nhiệm vụ và rất hữu dụng <a class="citation" href="#luong2015multi">[12]</a>.
<!--more--></p>

<h1 id="giới-thiệu-model-seq2seq">Giới thiệu model Seq2Seq</h1>

<p>Nỗi lòng người làm thày mà hướng dẫn sinh viên thì tùy level mà kỳ vọng thì nó cũng khác nhau, và với những level cao như postdoc là luôn có sự mong muốn nhất định.
Đó là phải vượt qua <code class="language-plaintext highlighter-rouge">thử thách (challenges)</code> của thày.
Thì cái challenge đây có hai nghĩa là cuộc thi và thử thách, thì nói thực là cuộc thi không cần đâu, chỉ cần vượt qua thử thách tối thiểu của thày trong cái kỹ năng làm nghiên cứu thôi là <code class="language-plaintext highlighter-rouge">ok em</code> rồi.</p>

<p>Trong thực tế kinh nghiệm thì tôi thấy mấy cái thử thách cũng không phức tạp lắm đâu, đặc biệt là trong lĩnh vực NLP+Vision này thì tôi thấy cũng chỉ có vài bài như Image Captioning, Video-to-Text hay VQA.
Code thì nhan nhản trong cộng đồng nghiên cứu (đặc thù của ngạch nghiên cứu là kế thừa, vì người ta công bố mà mình không dùng thì phí), rồi tài liệu thì mảng NLP với Vision các ông cũng publish trên ArXiV với mấy hội nghị open, chứ nào có giấu giếm gì nhau?
Thế mà không hiểu vì sao vẫn không vượt qua được cho thày?
Xem lại rốt cuộc là tôi nghĩ thì có lẽ nên thêm câu hỏi sau vào bộ dữ liệu QA:</p>

<blockquote>
  <p>Q: Không làm muốn có ăn thì ăn gì bây giờ?
A: ??? (câu hỏi tự luận nha)
Context: Hãy xem video của Prof. Huan Rose</p>
</blockquote>

<p>Thì nhìn chung là <code class="language-plaintext highlighter-rouge">seq2seq</code> là một model thử thách như vậy.
Với những bài đặc biệt chỉ của NLP như NMT, Text Summarization hay QA thì <code class="language-plaintext highlighter-rouge">seq2seq</code> đã mở ra hẳn cả một mảng riêng mà về sau còn có thêm mấy cái pretraining encoder/decoder như BERT, AlBERT, RoBERT, BART, … mà chủ yếu là representation learning.</p>

<blockquote>
  <p>Mô hình <code class="language-plaintext highlighter-rouge">seq2seq</code> đơn giản chỉ gồm một chuỗi input $\mathbb{x}_1, \mathbb{x}_2, \ldots, \mathbb{x}_m$. 
Chuỗi này đương nhiên là biểu diễn vector (embedding) sau khi đã preprocessing qua tokenizer và thay thế từ không có trong vocabulảy bởi <code class="language-plaintext highlighter-rouge">UNK</code>.
Sau đó là <strong>encoder</strong> với các trạng thái $\mathbb{h}_1, \mathbb{h}_2, \ldots, \mathbb{h}_m$ cũng như biểu diễn đầu ra của encoder là $\mathbb{z}_1, \mathbb{z}_2, \ldots, \mathbb{z}_m$.
Encoder chính là một mạng trí tuệ nhân tạo dạng Long-Short Term Memory (LSTM) mà chúng ta sẽ nói sau.
Bây giờ thì chúng ta cần aggregate chuỗi biểu diễn đầu ra của encoder thành biến vector \(\mathbb{c}_t=\sum_{i=1}^m\alpha_i^t\mathbb{z}_i\).
Ở mỗi bước \(t\) thì <strong>decoder</strong> LSTM sẽ nhận input là output của bước \(t-1\) là \(\mathbb{g}_{t-1}\) và biến context \(\mathbb{c}_t\) để đưa ra output \(\mathbb{g}_t\).</p>

\[\mathbb{g}_t=\mbox{LSTM}\left(\mathbb{g}_{t-1},\mathbb{c}_t\right)\]

  <p>ứng với mỗi \(\mathbb{g}_t\) sẽ được giải mã thành một ký tự trong ngôn ngữ đầu ra.
Quá trình này kết thúc khi ký tự <code class="language-plaintext highlighter-rouge">EOS</code> được giải mã ra.
Chuỗi đầu vào \(\mathbb{x}_i\) và chuỗi đầu ra của decoder \(\mathbb{g}_j\) có thể có độ dài khác nhau.</p>
</blockquote>

<p>Trong bài toán NMT, thì chuỗi đầu vào có thể là tiếng Anh và chuỗi đầu ra là tiếng Nhật.
Nhưng ngược lại thì sẽ cần tokenizer bằng tiếng Nhật.
Trong bài toán Text Summarization (TS), thì cả đầu ra và đầu vào đều sẽ cùng ngôn ngữ, nhưng đầu ra sẽ là một chuỗi ngắn gọn xúc tích hơn.
Cái gọi là <code class="language-plaintext highlighter-rouge">ngắn gọn, xúc tích hơn</code> sẽ được định nghĩa và học thông qua dữ liệu.
Thì NMT có bộ WMT2014, WMT2017, còn TS thì có bộ DUC.
Còn bài toán QA thì chuỗi đầu vào là một câu hỏi còn đầu ra là 1 câu trả lời.
Cái hay của QA là đôi khi có thêm chuỗi context (hay gọi là gợi ý), ví dụ như hỏi <code class="language-plaintext highlighter-rouge">Bạn sống ở đâu?</code> thì có thêm context là <code class="language-plaintext highlighter-rouge">Tôi sống ở Nhật</code> thì máy sẽ trả lời luôn là <code class="language-plaintext highlighter-rouge">Nhật</code>.
QA thì có bộ SQuAD v1 và v2 với hơn trăm ngàn bộ câu hỏi (nghe như luyện thì TOEIC).
Metrics đánh giá thì có cái BLUE-4 score, CIDEr, ROGUE là có thể dùng để đánh giá chuỗi đầu ra có phù hợp không.
Chúng ta sẽ đi sâu thêm vào từng chi tiết sau.</p>

<p>Các task trong NLP thì là như vậy, dữ liệu, code và metrics hầu như có sẵn.
Thì cũng là kết nối với Vision là khoảng CVPR tầm 2015-2016 gì đó có mấy cái Workshops nói về làm sao để có thể tích hợp nhiều modal (multi-modal) để đưa ra những giải pháp tốt hơn.
Mọc ra trước mắt lúc đó thì có 3 tasks nằm trong định hướng: Image Captioning, Video-to-Text và VQA.
Nói chung nghe lúc đó có vẻ mới, nhưng chỉ có task là mới thôi chứ còn những cái để thực thi những task ấy các sếp promote các task ấy lên họ đã chuẩn bị hết rồi.
Technique thì có sẵn <code class="language-plaintext highlighter-rouge">seq2seq</code>, CNN, RNN, LSTM, Faster R-CNN để extract attributes dưới dạng object detections, …
Metrics thì vì output vẫn là chuỗi text nên lại xài lại BLUE-4, CIDEr rồi ROGUE thôi.
Nên coi như nền tảng rất sẵn rồi, chỉ nhảy vào làm thí nghiệm và viết paper rồi … ăn!</p>

<p><em>Vậy tại sao vẫn cứ không đến nơi đến chốn được?</em></p>

<ol>
  <li>Tôi nghĩ vấn đề đầu tiên lúc làm Image Captioning là thiếu <code class="language-plaintext highlighter-rouge">alignment</code>.</li>
  <li>Lúc làm cái Video-to-Text thì cái visual semantic embedding (VSE) là không có. Mà nói thẳng ra thì cái ấy chính mình <code class="language-plaintext highlighter-rouge">chủ động</code> nghĩ ra mà làm chứ?</li>
  <li>CÒn cái VQA thì lúc ấy nói thật là hai cái captioning với VTT nó đã <code class="language-plaintext highlighter-rouge">bết bát</code> sẵn rồi thì sẽ rất khó vì bản thân VQA tuy chỉ thay cái context là text bởi hình ảnh, nhưng chất lượng detector, rồi alignment mà hai bước trên chưa làm tốt thì sang đến VQA coi như … vỡ trận.</li>
</ol>

<p>Tuy nhiên, nếu ở vào vai trò anh Postdoc mà làm cái mảng này tôi vẫn sẽ đề xuất luồng làm việc <code class="language-plaintext highlighter-rouge">Image Captioning --&gt; Video-to-Text --&gt; VQA</code>.
Bởi luồng làm việc này nó theo chiều hướng tích lùy dần know-how để làm việc ngày càng tốt hơn.
Thứ hai, là vì nó có một vài điểm trigger giữa chừng nên nếu làm postdoc các bạn có thể submit bài báo tại các thời điểm ấy như là làm Image Captioning xong thì 1 bài, …
<strong>Nhưng rốt cuộc cái quan trọng nhất vẫn là phải có làm có ăn.</strong>
Còn không muốn làm thì hỏi giáo sư Huấn để biết phải làm gì.</p>

<h2 id="recurrent-neural-nets-long-short-term-memory-và-gated-recurrent-units">Recurrent Neural Nets, Long-Short Term Memory và Gated Recurrent Units</h2>

<h2 id="kiến-trúc-seq2seq-s2s">Kiến trúc Seq2Seq (S2S)</h2>

<h2 id="anh-em-nhà-bert">Anh em nhà BERT</h2>

<h1 id="ứng-dụng">Ứng dụng</h1>

<h2 id="neural-machine-translation-nmt">Neural Machine Translation (NMT)</h2>

<h2 id="text-summarization">Text Summarization</h2>

<h2 id="qa-và-vqa">QA và VQA</h2>

<h2 id="video-to-text-và-image-captioning">Video-to-Text và Image Captioning</h2>

<h1 id="kết-luận">Kết luận</h1>

<h1 id="tài-liệu-tham-khảo">Tài liệu tham khảo</h1>

<ol class="bibliography"><li><span id="vaswani2017attention">Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, Ł. and Polosukhin, I. 2017. Attention is all you need. <i>Advances in neural information processing systems</i> (2017), 5998–6008.</span><a class="details" href="https://wanted2.github.io/bibliography/vaswani2017attention/">Details</a></li>
<li><span id="kalchbrenner2013recurrent">Kalchbrenner, N. and Blunsom, P. 2013. Recurrent continuous translation models. <i>Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing (EMNLP), Seattle, USA. Association for Computational Linguistics</i> (2013).</span><a class="details" href="https://wanted2.github.io/bibliography/kalchbrenner2013recurrent/">Details</a></li>
<li><span id="sutskever2014sequence">Sutskever, I., Vinyals, O. and Le, Q.V.V. 2014. Sequence to sequence learning with neural networks. <i>Advances in Neural Information Processing Systems</i> (2014), 3104–3112.</span><a class="details" href="https://wanted2.github.io/bibliography/sutskever2014sequence/">Details</a></li>
<li><span id="cho2014learning">Cho, K., Merrienboer, B. van, Gulcehre, C., Bougares, F., Schwenk, H. and Bengio, Y. 2014. Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation. <i>arXiv preprint arXiv:1406.1078</i>. (2014).</span><a class="details" href="https://wanted2.github.io/bibliography/cho2014learning/">Details</a></li>
<li><span id="rajpurkar2016squad">Rajpurkar, P., Zhang, J., Lopyrev, K. and Liang, P. 2016. SQuAD: 100,000+ Questions for Machine Comprehension of Text. <i>Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</i> (2016), 2383–2392.</span><a class="details" href="https://wanted2.github.io/bibliography/rajpurkar2016squad/">Details</a></li>
<li><span id="antol2015vqa">Antol, S., Agrawal, A., Lu, J., Mitchell, M., Batra, D., Zitnick, C.L. and Parikh, D. 2015. Vqa: Visual question answering. <i>Proceedings of the IEEE international conference on computer vision</i> (2015), 2425–2433.</span><a class="details" href="https://wanted2.github.io/bibliography/antol2015vqa/">Details</a></li>
<li><span id="rush2015neural">Rush, A.M., Chopra, S. and Weston, J. 2015. A Neural Attention Model for Abstractive Sentence Summarization. <i>Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</i> (2015), 379–389.</span><a class="details" href="https://wanted2.github.io/bibliography/rush2015neural/">Details</a></li>
<li><span id="ranzato2015sequence">Ranzato, M.A., Chopra, S., Auli, M. and Zaremba, W. 2015. Sequence level training with recurrent neural networks. <i>arXiv preprint arXiv:1511.06732</i>. (2015).</span><a class="details" href="https://wanted2.github.io/bibliography/ranzato2015sequence/">Details</a></li>
<li><span id="venugopalan2015sequence">Venugopalan, S., Rohrbach, M., Donahue, J., Mooney, R., Darrell, T. and Saenko, K. 2015. Sequence to sequence-video to text. <i>Proceedings of the IEEE international conference on computer vision</i> (2015), 4534–4542.</span><a class="details" href="https://wanted2.github.io/bibliography/venugopalan2015sequence/">Details</a></li>
<li><span id="you2016image">You, Q., Jin, H., Wang, Z., Fang, C. and Luo, J. 2016. Image captioning with semantic attention. <i>Proceedings of the IEEE conference on computer vision and pattern recognition</i> (2016), 4651–4659.</span><a class="details" href="https://wanted2.github.io/bibliography/you2016image/">Details</a></li>
<li><span id="johnson2016densecap">Johnson, J., Karpathy, A. and Fei-Fei, L. 2016. Densecap: Fully convolutional localization networks for dense captioning. <i>Proceedings of the IEEE conference on computer vision and pattern recognition</i> (2016), 4565–4574.</span><a class="details" href="https://wanted2.github.io/bibliography/johnson2016densecap/">Details</a></li>
<li><span id="luong2015multi">Luong, M.-T., Le, Q.V., Sutskever, I., Vinyals, O. and Kaiser, L. 2015. Multi-task sequence to sequence learning. <i>arXiv preprint arXiv:1511.06114</i>. (2015).</span><a class="details" href="https://wanted2.github.io/bibliography/luong2015multi/">Details</a></li></ol>

            </div>

            <!-- Rating -->
            

            <!-- Post Date -->
            <p>
            <small>
                <span class="post-date"><time class="post-date" datetime="2022-02-01">01 Feb 2022</time></span>           
                
                </small>
            </p>

            <!-- Post Categories -->
            <div class="after-post-cats">
                <ul class="tags mb-4">
                    
                    
                    <li>
                        <a class="smoothscroll" href="https://wanted2.github.io/categories#Artificial-Intelligence">Artificial Intelligence</a>
                    </li>
                    
                    <li>
                        <a class="smoothscroll" href="https://wanted2.github.io/categories#Tiếng-Việt,-日本語">Tiếng Việt, 日本語</a>
                    </li>
                    
                </ul>
            </div>
            <!-- End Categories -->

            <!-- Post Tags -->
            <div class="after-post-tags">
                <ul class="tags">
                    
                    
                    <li>
                        <a class="smoothscroll" href="https://wanted2.github.io/tags#Encoder-Decoder">#Encoder-Decoder</a>
                    </li>
                    
                    <li>
                        <a class="smoothscroll" href="https://wanted2.github.io/tags#Long-Short-Term-Memory">#Long-Short Term Memory</a>
                    </li>
                    
                    <li>
                        <a class="smoothscroll" href="https://wanted2.github.io/tags#Machine-learning">#Machine learning</a>
                    </li>
                    
                    <li>
                        <a class="smoothscroll" href="https://wanted2.github.io/tags#Neural-Machine-Translation">#Neural Machine Translation</a>
                    </li>
                    
                    <li>
                        <a class="smoothscroll" href="https://wanted2.github.io/tags#Recurrent-Neural-Networks">#Recurrent Neural Networks</a>
                    </li>
                    
                    <li>
                        <a class="smoothscroll" href="https://wanted2.github.io/tags#Seq2Seq">#Seq2Seq</a>
                    </li>
                    
                    <li>
                        <a class="smoothscroll" href="https://wanted2.github.io/tags#Sequence-to-Sequence">#Sequence-to-Sequence</a>
                    </li>
                    
                </ul>
            </div>
            <!-- End Tags -->

            <!-- Prev/Next -->
            <div class="row PageNavigation d-flex justify-content-between font-weight-bold">
            
            <a class="prev d-block col-md-6" href="https://wanted2.github.io//ml-ids/"> &laquo; Machine Learning for Network Intrusion Detection: From Local to Production</a>
            
            
            <div class="clearfix"></div>
            </div>
            <!-- End Categories -->

        </div>
        <!-- End Post -->

    </div>
</div>
<!-- End Article
================================================== -->

<!-- Begin Comments
================================================== -->

    <div class="container">
        <div id="comments" class="row justify-content-center mb-5">
            <div class="col-md-8">
                <section class="disqus">
    <div id="disqus_thread"></div>
    <script type="text/javascript">
        var disqus_shortname = 'caineng'; 
        var disqus_developer = 0;
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = window.location.protocol + '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</section>

            </div>
        </div>
    </div>

<!--End Comments
================================================== -->

<!-- Review with LD-JSON, adapt it for your needs if you like, but make sure you test the generated HTML source code first: 
https://search.google.com/structured-data/testing-tool/u/0/
================================================== -->

</div>


<!-- Bottom Alert Bar
================================================== -->
<div class="alertbar">
	<div class="container text-center">
		<span><img src="https://wanted2.github.io/assets/images/favicon.ico" alt="AiFi" style="max-height: 48px;" /> &nbsp; Never miss a <b>story</b> from us, subscribe to our newsletter</span>
        <form action="https://caineng.us20.list-manage.com/subscribe/post?u=76342d3d74a6807aac5aec0d7&id=b5645e19be" method="post" name="mc-embedded-subscribe-form" class="wj-contact-form validate" target="_blank" novalidate>
            <div class="mc-field-group">
            <input type="email" placeholder="Email" name="EMAIL" class="required email" id="mce-EMAIL" autocomplete="on" required>
            <input type="submit" value="Subscribe" name="subscribe" class="heart">
            </div>
        </form>
	</div>
</div>

    
</div>

<!-- Categories Jumbotron
================================================== -->
<div class="jumbotron fortags">
	<div class="d-md-flex h-100">
		<div class="col-md-4 transpdark align-self-center text-center h-100">
            <div class="d-md-flex align-items-center justify-content-center h-100">
                <h2 class="d-md-block align-self-center py-1 font-weight-light">Explore <span class="d-none d-md-inline">→</span></h2>
            </div>
		</div>
		<div class="col-md-8 p-5 align-self-center text-center">
            
            
                
                    <a class="mt-1 mb-1" href="https://wanted2.github.io/categories#Site-Reliable-Engineering">Site Reliable Engineering (16)</a>
                
                    <a class="mt-1 mb-1" href="https://wanted2.github.io/categories#Software-Engineering">Software Engineering (37)</a>
                
                    <a class="mt-1 mb-1" href="https://wanted2.github.io/categories#Computer-Vision">Computer Vision (5)</a>
                
                    <a class="mt-1 mb-1" href="https://wanted2.github.io/categories#Artificial-Intelligence">Artificial Intelligence (18)</a>
                
                    <a class="mt-1 mb-1" href="https://wanted2.github.io/categories#Tiếng-Việt,-日本語">Tiếng Việt, 日本語 (36)</a>
                
                    <a class="mt-1 mb-1" href="https://wanted2.github.io/categories#Project-Management">Project Management (34)</a>
                
            
            
		</div>
	</div>
</div>

<!-- Begin Footer
================================================== -->
<footer class="footer">
    <div class="container">
        <div class="row">
            <div class="col-md-6 col-sm-6 text-center text-lg-left">
                Copyright © 2022 AiFi 
            </div>
            <div class="col-md-6 col-sm-6 text-center text-lg-right">    
                <a target="_blank" href="https://www.wowthemes.net/mediumish-free-jekyll-template/">Mediumish Jekyll Theme</a> by WowThemes.net
            </div>
        </div>
    </div>
</footer>
<!-- End Footer
================================================== -->

</div> <!-- /.site-content -->

<!-- Scripts
================================================== -->

<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js" integrity="sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut" crossorigin="anonymous"></script>

<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js" integrity="sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k" crossorigin="anonymous"></script>

<script src="https://wanted2.github.io/assets/js/mediumish.js"></script>


<script src="https://wanted2.github.io/assets/js/lazyload.js"></script>


<script src="https://wanted2.github.io/assets/js/ie10-viewport-bug-workaround.js"></script> 


<script id="dsq-count-scr" src="//caineng.disqus.com/count.js"></script>


</body>
</html>
