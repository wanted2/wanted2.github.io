
var documents = [{
    "id": 0,
    "url": "https://wanted2.github.io/404.html",
    "title": "404",
    "body": "404 Page does not exist!Please use the search bar at the top or visit our homepage! "
    }, {
    "id": 1,
    "url": "https://wanted2.github.io/about",
    "title": "Tuan Nguyen-Anh",
    "body": "Contacts: tuan. nguyenanh. brse@gmail. com| Curriculum Vitae: English Experience: Bridge System Engineer/Project Management/Product Owner/Scrum Master/Techlead/TeamleadSystem engineering/Web development      Backend: Java SpringBoot, Scala Playframework, PHP Laravel, Python Flask/Django, . etc.     Frontend: VueJS, ReactJS, AngularJS, Svelte, jQuery, . etc.     Cloud: AWS, Google GCP, Azure    DevOps, SRE, . etc.     Artificial Intelligence/Internet of Things/Computer Vision/Machine Learning "
    }, {
    "id": 2,
    "url": "https://wanted2.github.io/categories",
    "title": "Categories",
    "body": ""
    }, {
    "id": 3,
    "url": "https://wanted2.github.io/",
    "title": "Home",
    "body": "      Featured:                                                                                                                                                                                                           Speech and Sequence-to-sequence                              :               Như trong bài viết trước thì chúng ta đã tìm hiểu và biết trong mảng NLP cũng như Vision-Language (VL) thì seq2seq đều đang làm chủ. Trong bài viết này chúng ta sẽ tìm hiểu 1 mảng khác mà seq2seq và các hậu duệ (thuộc dòng dõi Transformer [18] và . . . :                                                                                                                                                                       AiFi                                06 Feb 2022                                                                                                                                                                                                                                                                                                                        Machine Learning for Network Intrusion Detection: From Local to Production                              :               Network Intrusion Detection System Network intrusion detection system (NIDS) is an independent platform that examines network traffic patterns to identify intrusions for an entire network. It needs to be placed at a choke point where all tra. . . :                                                                                                                                                                       AiFi                                29 Jan 2022                                                                                                                                                                                                                                                                                                                        4 điều nên làm để quản lý tài khoản AWS                              :                Những tri thức cơ bản như làm thế nào quản lý mật khẩu với đặt mật khẩu như thế nào thì có lẽ các em tự chủ động thiết lập nhé. Trong bài viết này chúng ta sẽ tập trung vào 4 chức năng mang tính nâng cao (advanced) của bảo mật tài khoản AWS. . . . :                                                                                                                                                                       AiFi                                16 Jan 2022                                                                                                                                                                                                                                                                                                                  Cán cân thu nhập: hàn lâm, khởi nghiệp và công ty                              :                Cộng đồng mạng xã hội hiện đại gần đây có nổ ra tranh cãi về câu nói Có làm thì mới có ăn, cái loại không làm mà lại muốn có ăn thì chỉ có ăn … của tác giả Huấn Hoa Hồng. Những bô lão của cộng đồng hàm lâm như Giáo sư kiêm lính thủy đánh bạc Ti. . . :                                                                                                                                                                       AiFi                                10 Jan 2022                                                                                                                                        All Stories:                                                                                                     Speech and Sequence-to-sequence              :       Như trong bài viết trước thì chúng ta đã tìm hiểu và biết trong mảng NLP cũng như Vision-Language (VL) thì seq2seq đều đang làm chủ. Trong bài viết này chúng ta sẽ tìm hiểu 1 mảng khác mà seq2seq và các hậu duệ (thuộc dòng dõi Transformer [18] và . . . :                                                                               AiFi                06 Feb 2022                                                                                                                                    Seq2Seq và kiến trúc Encoder-Decoder              :       Seq2Seq [51, 51, 51] là một giải pháp kiến trúc được dùng khá nhiều trong các bài toán NLP và vision như Neural Machine Translation (NMT, [51]), Question-Answering (QA, [51]), Visual Question Answering (VQA, [51, 51]), Text Summarization (TS, [51,. . . :                                                                               AiFi                01 Feb 2022                                                                                                                                    Machine Learning for Network Intrusion Detection: From Local to Production              :       Network Intrusion Detection System Network intrusion detection system (NIDS) is an independent platform that examines network traffic patterns to identify intrusions for an entire network. It needs to be placed at a choke point where all tra. . . :                                                                               AiFi                29 Jan 2022                                               &laquo; Prev       1        2        3      Next &raquo; "
    }, {
    "id": 4,
    "url": "https://wanted2.github.io/projects",
    "title": "Projects and Demos",
    "body": "Projects: Demos: AI demos "
    }, {
    "id": 5,
    "url": "https://wanted2.github.io/bibliography/trauring1963automatic/",
    "title": "Automatic comparison of finger-ridge patterns",
    "body": "  Trauring, M. 1963. Automatic comparison of finger-ridge patterns. Nature. 197, 4871 (1963), 938–940.                                                                                             @article{trauring1963automatic, title = {Automatic comparison of finger-ridge patterns}, author = {Trauring, Mitchell}, journal = {Nature}, volume = {197}, number = {4871}, pages = {938--940}, year = {1963}, publisher = {Springer}}                                                        "
    }, {
    "id": 6,
    "url": "https://wanted2.github.io/bibliography/jain201650/",
    "title": "50 years of biometric research: Accomplishments, challenges, and opportunities",
    "body": "  Jain, A. K. , Nandakumar, K. and Ross, A. 2016. 50 years of biometric research: Accomplishments, challenges, and opportunities. Pattern recognition letters. 79, (2016), 80–105.                                                                                             @article{jain201650, title = {50 years of biometric research: Accomplishments, challenges, and opportunities}, author = {Jain, Anil K and Nandakumar, Karthik and Ross, Arun}, journal = {Pattern recognition letters}, volume = {79}, pages = {80--105}, year = {2016}, publisher = {Elsevier}}                                                        "
    }, {
    "id": 7,
    "url": "https://wanted2.github.io/bibliography/holdsworth2008token/",
    "title": "Token for use in online electronic transactions",
    "body": "  Holdsworth, J. 2008. Token for use in online electronic transactions. Google Patents.   US Patent 7,437,757                                                                                            @misc{holdsworth2008token, title = {Token for use in online electronic transactions}, author = {Holdsworth, John}, year = {2008}, month = oct, publisher = {Google Patents}, note = {US Patent 7,437,757}}                                                        "
    }, {
    "id": 8,
    "url": "https://wanted2.github.io/bibliography/grother2018ongoing/",
    "title": "Ongoing face recognition vendor test (FRVT) part 1: Verification",
    "body": "  Grother, P. , Ngan, M. , Hanaoka, K. , Yang, J. C. and Hom, A. 2022. Ongoing face recognition vendor test (FRVT) part 1: Verification. US Department of Commerce, National Institute of Standards and Technology.                                                                                             @book{grother2018ongoing, author = {Grother, Patrick and Ngan, Mei and Hanaoka, Kayee and Yang, Joyce C. and Hom, Austin}, title = {Ongoing face recognition vendor test (FRVT) part 1: Verification}, publisher = {US Department of Commerce, National Institute of Standards and Technology}, year = {2022}}                                                        "
    }, {
    "id": 9,
    "url": "https://wanted2.github.io/bibliography/boyd2003protocols/",
    "title": "Protocols for authentication and key establishment",
    "body": "  Boyd, C. , Mathuria, A. and Stebila, D. 2003. Protocols for authentication and key establishment. Springer.                                                                                             @book{boyd2003protocols, title = {Protocols for authentication and key establishment}, author = {Boyd, Colin and Mathuria, Anish and Stebila, Douglas}, volume = {1}, year = {2003}, publisher = {Springer}}                                                        "
    }, {
    "id": 10,
    "url": "https://wanted2.github.io/bibliography/pankanti2002individuality/",
    "title": "On the individuality of fingerprints",
    "body": "  Pankanti, S. , Prabhakar, S. and Jain, A. K. 2002. On the individuality of fingerprints. Pattern Analysis and Machine Intelligence, IEEE Transactions on. 24, 8 (2002), 1010–1025.                                                                                             @article{pankanti2002individuality, title = {On the individuality of fingerprints}, author = {Pankanti, S. and Prabhakar, S. and Jain, A. K. }, journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on}, volume = {24}, number = {8}, pages = {1010--1025}, year = {2002}, publisher = {IEEE}}                                                        "
    }, {
    "id": 11,
    "url": "https://wanted2.github.io/bibliography/ometov2018multi/",
    "title": "Multi-factor authentication: A survey",
    "body": "  Ometov, A. , Bezzateev, S. , Mäkitalo, N. , Andreev, S. , Mikkonen, T. and Koucheryavy, Y. 2018. Multi-factor authentication: A survey. Cryptography. 2, 1 (2018), 1.                                                                                             @article{ometov2018multi, title = {Multi-factor authentication: A survey}, author = {Ometov, Aleksandr and Bezzateev, Sergey and M{\ a}kitalo, Niko and Andreev, Sergey and Mikkonen, Tommi and Koucheryavy, Yevgeni}, journal = {Cryptography}, volume = {2}, number = {1}, pages = {1}, year = {2018}, publisher = {Multidisciplinary Digital Publishing Institute}}                                                        "
    }, {
    "id": 12,
    "url": "https://wanted2.github.io/bibliography/ngu2016iot/",
    "title": "IoT middleware: A survey on issues and enabling technologies",
    "body": "  Ngu, A. H. , Gutierrez, M. , Metsis, V. , Nepal, S. and Sheng, Q. Z. 2016. IoT middleware: A survey on issues and enabling technologies. IEEE Internet of Things Journal. 4, 1 (2016), 1–20.                                                                                             @article{ngu2016iot, title = {IoT middleware: A survey on issues and enabling technologies}, author = {Ngu, Anne H and Gutierrez, Mario and Metsis, Vangelis and Nepal, Surya and Sheng, Quan Z}, journal = {IEEE Internet of Things Journal}, volume = {4}, number = {1}, pages = {1--20}, year = {2016}, publisher = {IEEE}}                                                        "
    }, {
    "id": 13,
    "url": "https://wanted2.github.io/bibliography/mahakian2020aws/",
    "title": "AWS GovCloud Resource and Cost Analysis",
    "body": "  Mahakian, J. , Holmdahl, S. , Bada, Q. , Silva, S. and Tretler, Z. 2020. AWS GovCloud Resource and Cost Analysis. The MITRE Corporation.                                                                                             @techreport{mahakian2020aws, title = {AWS GovCloud Resource and Cost Analysis}, author = {Mahakian, Joseph and Holmdahl, Scott and Bada, Quadri and Silva, Steffani and Tretler, Zach}, year = {2020}, institution = {The MITRE Corporation}}                                                        "
    }, {
    "id": 14,
    "url": "https://wanted2.github.io/bibliography/AdobeCre15_online/",
    "title": "Adobe Creative Cloud All Apps",
    "body": "  Adobe Adobe Creative Cloud All Apps.   (Accessed on 12/19/2021)                                                                                            @misc{AdobeCre15:online, author = {Adobe}, title = {Adobe Creative Cloud All Apps}, howpublished = {\url{https://www. adobe. com/creativecloud/all-apps. html}}, month = {}, year = {}, note = {(Accessed on 12/19/2021)}}                                                        "
    }, {
    "id": 15,
    "url": "https://wanted2.github.io/bibliography/Kirillov_2019_CVPR/",
    "title": "Panoptic Segmentation",
    "body": "  Kirillov, A. , He, K. , Girshick, R. , Rother, C. and Dollar, P. 2019. Panoptic Segmentation. Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) (Jun. 2019).                                                                                             @inproceedings{Kirillov_2019_CVPR, author = {Kirillov, Alexander and He, Kaiming and Girshick, Ross and Rother, Carsten and Dollar, Piotr}, title = {Panoptic Segmentation}, booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, month = jun, year = {2019}}                                                        "
    }, {
    "id": 16,
    "url": "https://wanted2.github.io/bibliography/AmazonLo59_online/",
    "title": "Amazon Lookout for Equipment - Amazon Web Services",
    "body": "  Amazon Lookout for Equipment - Amazon Web Services.   (Accessed on 03/06/2021)                                                                                            @misc{AmazonLo59:online, author = {}, title = {Amazon Lookout for Equipment - Amazon Web Services}, howpublished = {\url{https://aws. amazon. com/jp/lookout-for-equipment/}}, month = {}, year = {}, note = {(Accessed on 03/06/2021)}}                                                        "
    }, {
    "id": 17,
    "url": "https://wanted2.github.io/bibliography/Applicat67_online/",
    "title": "Application of Computer Vision in Precision Agriculture & Farming | by Vikram Singh Bisen | VSINGHBISEN | Medium",
    "body": "  Application of Computer Vision in Precision Agriculture &amp; Farming | by Vikram Singh Bisen | VSINGHBISEN | Medium.   (Accessed on 03/06/2021)                                                                                            @misc{Applicat67:online, author = {}, title = {Application of Computer Vision in Precision Agriculture \&amp; Farming | by Vikram Singh Bisen | VSINGHBISEN | Medium}, howpublished = {\url{https://webcache. googleusercontent. com/search?q=cache:vzxIOTUqiOEJ:https://medium. com/vsinghbisen/application-of-computer-vision-in-precision-agriculture-farming-79b0600d5a5d+}}, month = {}, year = {}, note = {(Accessed on 03/06/2021)}}                                                        "
    }, {
    "id": 18,
    "url": "https://wanted2.github.io/bibliography/TIAN20201/",
    "title": "Computer vision technology in agricultural automation –A review",
    "body": "  Tian, H. , Wang, T. , Liu, Y. , Qiao, X. and Li, Y. 2020. Computer vision technology in agricultural automation –A review. Information Processing in Agriculture. 7, 1 (2020), 1–19. DOI:https://doi. org/10. 1016/j. inpa. 2019. 09. 006.     DOI                                                                                            @article{TIAN20201, title = {Computer vision technology in agricultural automation --A review}, journal = {Information Processing in Agriculture}, volume = {7}, number = {1}, pages = {1-19}, year = {2020}, issn = {2214-3173}, doi = {10. 1016/j. inpa. 2019. 09. 006}, url = {https://www. sciencedirect. com/science/article/pii/S2214317319301751}, author = {Tian, Hongkun and Wang, Tianhai and Liu, Yadong and Qiao, Xi and Li, Yanzhou}, keywords = {Computer vision, Image processing, Agricultural automation, Intelligent detection}}                                                        "
    }, {
    "id": 19,
    "url": "https://wanted2.github.io/bibliography/HumbleOb26_online/",
    "title": "Humble Object at XUnitPatterns.com",
    "body": "  Humble Object at XUnitPatterns. com. http://xunitpatterns. com/Humble%20Object. html.   (Accessed on 08/04/2021)                                                                                            @misc{HumbleOb26:online, author = {}, title = {Humble Object at XUnitPatterns. com}, howpublished = {http://xunitpatterns. com/Humble%20Object. html}, month = {}, year = {}, note = {(Accessed on 08/04/2021)}}                                                        "
    }, {
    "id": 20,
    "url": "https://wanted2.github.io/bibliography/cleanarch/",
    "title": "Clean Architecture - A Craftman’s Guide to Software Structure and Design",
    "body": "  Martin, R. C. 2017. Clean Architecture - A Craftman’s Guide to Software Structure and Design. Prentice Hall.                                                                                             @book{cleanarch, author = {Martin, Robert C. }, title = {Clean Architecture - A Craftman's Guide to Software Structure and Design}, publisher = {Prentice Hall}, year = {2017}}                                                        "
    }, {
    "id": 21,
    "url": "https://wanted2.github.io/bibliography/martin2009clean/",
    "title": "Clean code: a handbook of agile software craftsmanship",
    "body": "  Martin, R. C. 2009. Clean code: a handbook of agile software craftsmanship. Pearson Education.                                                                                             @book{martin2009clean, title = {Clean code: a handbook of agile software craftsmanship}, author = {Martin, Robert C}, year = {2009}, publisher = {Pearson Education}}                                                        "
    }, {
    "id": 22,
    "url": "https://wanted2.github.io/bibliography/martin2007professionalism/",
    "title": "Professionalism and test-driven development",
    "body": "  Martin, R. C. 2007. Professionalism and test-driven development. IEEE Software. 24, 3 (2007), 32–36.                                                                                             @article{martin2007professionalism, title = {Professionalism and test-driven development}, author = {Martin, Robert C}, journal = {IEEE Software}, volume = {24}, number = {3}, pages = {32--36}, year = {2007}, publisher = {IEEE}}                                                        "
    }, {
    "id": 23,
    "url": "https://wanted2.github.io/bibliography/binder2000testing/",
    "title": "Testing object-oriented systems: models, patterns, and tools",
    "body": "  Binder, R. 2000. Testing object-oriented systems: models, patterns, and tools. Addison-Wesley Professional.                                                                                             @book{binder2000testing, title = {Testing object-oriented systems: models, patterns, and tools}, author = {Binder, Robert}, year = {2000}, publisher = {Addison-Wesley Professional}}                                                        "
    }, {
    "id": 24,
    "url": "https://wanted2.github.io/bibliography/abstraction1988hierarchy/",
    "title": "Data Abstraction and Hierarchy",
    "body": "  Liskov, B. 1988. Data Abstraction and Hierarchy. SIGPLAN Notices. 23, 5 (1988), 17–34.                                                                                             @article{abstraction1988hierarchy, title = {Data Abstraction and Hierarchy}, author = {Liskov, Barbara}, journal = {SIGPLAN Notices}, volume = {23}, number = {5}, pages = {17--34}, year = {1988}}                                                        "
    }, {
    "id": 25,
    "url": "https://wanted2.github.io/bibliography/NeverCom29_online/",
    "title": "Never Compromise on Identity",
    "body": "  Auth0 Never Compromise on Identity. https://auth0. com/user-management.   (Accessed on 03/13/2021)                                                                                            @misc{NeverCom29:online, author = {Auth0}, title = {Never Compromise on Identity}, howpublished = {https://auth0. com/user-management}, month = {}, year = {}, note = {(Accessed on 03/13/2021)}}                                                        "
    }, {
    "id": 26,
    "url": "https://wanted2.github.io/bibliography/buildvsb19_online/",
    "title": "Build vs Buy: Guide to Identity Management",
    "body": "  Auth0 Whitepaper Build vs Buy: Guide to Identity Management.   (Accessed on 03/13/2021)                                                                                            @misc{buildvsb19:online, author = {{Auth0 Whitepaper}}, title = {Build vs Buy: Guide to Identity Management}, howpublished = {}, month = {}, year = {}, note = {(Accessed on 03/13/2021)}}                                                        "
    }, {
    "id": 27,
    "url": "https://wanted2.github.io/bibliography/AmazonCo96_online/",
    "title": "Amazon Cognito – Đăng nhập và đăng ký cho người dùng đơn giản và bảo mật | Amazon Web Services (AWS)",
    "body": "  Services, A. W. Amazon Cognito – Đăng nhập và đăng ký cho người dùng đơn giản và bảo mật | Amazon Web Services (AWS). https://aws. amazon. com/vi/cognito/.   (Accessed on 03/13/2021)                                                                                            @misc{AmazonCo96:online, author = {Services, Amazon Web}, title = {Amazon Cognito – Đăng nhập và đăng ký cho người dùng đơn giản và bảo mật | Amazon Web Services (AWS)}, howpublished = {https://aws. amazon. com/vi/cognito/}, month = {}, year = {}, note = {(Accessed on 03/13/2021)}}                                                        "
    }, {
    "id": 28,
    "url": "https://wanted2.github.io/bibliography/Identity83_online/",
    "title": "Identity and Access documentation | Microsoft Docs",
    "body": "  Microsoft Identity and Access documentation | Microsoft Docs. https://docs. microsoft. com/en-us/windows-server/identity/identity-and-access.   (Accessed on 03/13/2021)                                                                                            @misc{Identity83:online, author = {Microsoft}, title = {Identity and Access documentation | Microsoft Docs}, howpublished = {https://docs. microsoft. com/en-us/windows-server/identity/identity-and-access}, month = {}, year = {}, note = {(Accessed on 03/13/2021)}}                                                        "
    }, {
    "id": 29,
    "url": "https://wanted2.github.io/bibliography/Identity68_online/",
    "title": "Identity Platform  |  ID プラットフォーム  |  Google Cloud",
    "body": "  Cloud, G. Identity Platform  |  ID プラットフォーム  |  Google Cloud. https://cloud. google. com/identity-platform/.   (Accessed on 03/13/2021)                                                                                            @misc{Identity68:online, author = {Cloud, Google}, title = {Identity Platform  |  ID プラットフォーム  |  Google Cloud}, howpublished = {https://cloud. google. com/identity-platform/}, month = {}, year = {}, note = {(Accessed on 03/13/2021)}}                                                        "
    }, {
    "id": 30,
    "url": "https://wanted2.github.io/bibliography/AzureBoa68_online/",
    "title": "Azure Boards | Microsoft Azure",
    "body": "  Azure Boards | Microsoft Azure.   (Accessed on 11/07/2021)                                                                                            @misc{AzureBoa68:online, author = {}, title = {Azure Boards | Microsoft Azure}, howpublished = {\url{https://azure. microsoft. com/en-us/services/devops/boards/}}, month = {}, year = {}, note = {(Accessed on 11/07/2021)}}                                                        "
    }, {
    "id": 31,
    "url": "https://wanted2.github.io/bibliography/meredith2017project/",
    "title": "Project management: a strategic managerial approach",
    "body": "  Meredith, J. R. , Shafer, S. M. and Mantel Jr, S. J. 2017. Project management: a strategic managerial approach. John Wiley &amp; Sons.                                                                                             @book{meredith2017project, title = {Project management: a strategic managerial approach}, author = {Meredith, Jack R and Shafer, Scott M and Mantel Jr, Samuel J}, year = {2017}, publisher = {John Wiley \&amp; Sons}}                                                        "
    }, {
    "id": 32,
    "url": "https://wanted2.github.io/bibliography/AzureRep87_online/",
    "title": "Azure Repos – Git Repositories | Microsoft Azure",
    "body": "  Azure Repos – Git Repositories | Microsoft Azure.   (Accessed on 11/07/2021)                                                                                            @misc{AzureRep87:online, author = {}, title = {Azure Repos – Git Repositories | Microsoft Azure}, howpublished = {\url{https://azure. microsoft. com/en-us/services/devops/repos/}}, month = {}, year = {}, note = {(Accessed on 11/07/2021)}}                                                        "
    }, {
    "id": 33,
    "url": "https://wanted2.github.io/bibliography/AzurePip74_online/",
    "title": "Azure Pipelines | Microsoft Azure",
    "body": "  Azure Pipelines | Microsoft Azure.   (Accessed on 11/07/2021)                                                                                            @misc{AzurePip74:online, author = {}, title = {Azure Pipelines | Microsoft Azure}, howpublished = {\url{https://azure. microsoft. com/en-us/services/devops/pipelines/}}, month = {}, year = {}, note = {(Accessed on 11/07/2021)}}                                                        "
    }, {
    "id": 34,
    "url": "https://wanted2.github.io/bibliography/AzureArt12_online/",
    "title": "Azure Artifacts | Microsoft Azure",
    "body": "  Azure Artifacts | Microsoft Azure.   (Accessed on 11/07/2021)                                                                                            @misc{AzureArt12:online, author = {}, title = {Azure Artifacts | Microsoft Azure}, howpublished = {\url{https://azure. microsoft. com/en-us/services/devops/artifacts/}}, month = {}, year = {}, note = {(Accessed on 11/07/2021)}}                                                        "
    }, {
    "id": 35,
    "url": "https://wanted2.github.io/bibliography/AzureTes7_online/",
    "title": "Azure Test Plans | Microsoft Azure",
    "body": "  Azure Test Plans | Microsoft Azure.   (Accessed on 11/07/2021)                                                                                            @misc{AzureTes7:online, author = {}, title = {Azure Test Plans | Microsoft Azure}, howpublished = {\url{https://azure. microsoft. com/en-us/services/devops/test-plans/}}, month = {}, year = {}, note = {(Accessed on 11/07/2021)}}                                                        "
    }, {
    "id": 36,
    "url": "https://wanted2.github.io/bibliography/AzureDev1_online/",
    "title": "Azure DevOps Services Pricing | Microsoft Azure",
    "body": "  Azure DevOps Services Pricing | Microsoft Azure.   (Accessed on 11/07/2021)                                                                                            @misc{AzureDev1:online, author = {}, title = {Azure DevOps Services Pricing | Microsoft Azure}, howpublished = {\url{https://azure. microsoft. com/en-us/pricing/details/devops/azure-devops-services/}}, month = {}, year = {}, note = {(Accessed on 11/07/2021)}}                                                        "
    }, {
    "id": 37,
    "url": "https://wanted2.github.io/bibliography/Definiti31_online/",
    "title": "Definition of Done - Visual Studio Marketplace",
    "body": "  Definition of Done - Visual Studio Marketplace.   (Accessed on 11/07/2021)                                                                                            @misc{Definiti31:online, author = {}, title = {Definition of Done - Visual Studio Marketplace}, howpublished = {\url{https://marketplace. visualstudio. com/items?itemName=agile-extensions. dod&amp;ssr=false#overview}}, month = {}, year = {}, note = {(Accessed on 11/07/2021)}}                                                        "
    }, {
    "id": 38,
    "url": "https://wanted2.github.io/bibliography/ProductV55_online/",
    "title": "Product Vision - Visual Studio Marketplace",
    "body": "  Product Vision - Visual Studio Marketplace.   (Accessed on 11/07/2021)                                                                                            @misc{ProductV55:online, author = {}, title = {Product Vision - Visual Studio Marketplace}, howpublished = {\url{https://marketplace. visualstudio. com/items?itemName=agile-extensions. product-vision}}, month = {}, year = {}, note = {(Accessed on 11/07/2021)}}                                                        "
    }, {
    "id": 39,
    "url": "https://wanted2.github.io/bibliography/BacklogE28_online/",
    "title": "Backlog Essentials - Visual Studio Marketplace",
    "body": "  Backlog Essentials - Visual Studio Marketplace.   (Accessed on 11/07/2021)                                                                                            @misc{BacklogE28:online, author = {}, title = {Backlog Essentials - Visual Studio Marketplace}, howpublished = {\url{https://marketplace. visualstudio. com/items?itemName=agile-extensions. backlog-essentials&amp;ssr=false#overview}}, month = {}, year = {}, note = {(Accessed on 11/07/2021)}}                                                        "
    }, {
    "id": 40,
    "url": "https://wanted2.github.io/bibliography/mediumco31_online/",
    "title": "medium.com",
    "body": "  medium. com.   (Accessed on 11/07/2021)                                                                                            @misc{mediumco31:online, author = {}, title = {medium. com}, howpublished = {\url{https://medium. com/boston-product/the-true-definition-of-done-c6c254a0ff3e}}, month = {}, year = {}, note = {(Accessed on 11/07/2021)}}                                                        "
    }, {
    "id": 41,
    "url": "https://wanted2.github.io/bibliography/soh2020overview/",
    "title": "Overview of Azure Platform as a Service",
    "body": "  Soh, J. , Copeland, M. , Puca, A. and Harris, M. 2020. Overview of Azure Platform as a Service. Microsoft Azure. Springer. 43–55.                                                                                             @incollection{soh2020overview, title = {Overview of Azure Platform as a Service}, author = {Soh, Julian and Copeland, Marshall and Puca, Anthony and Harris, Micheleen}, booktitle = {Microsoft Azure}, pages = {43--55}, year = {2020}, publisher = {Springer}}                                                        "
    }, {
    "id": 42,
    "url": "https://wanted2.github.io/bibliography/witte2019event/",
    "title": "Event-driven workflows for large-scale seismic imaging in the cloud",
    "body": "  Witte, P. A. , Louboutin, M. , Modzelewski, H. , Jones, C. , Selvage, J. and Herrmann, F. J. 2019. Event-driven workflows for large-scale seismic imaging in the cloud. SEG Technical Program Expanded Abstracts 2019. Society of Exploration Geophysicists. 3984–3988.                                                                                             @incollection{witte2019event, title = {Event-driven workflows for large-scale seismic imaging in the cloud}, author = {Witte, Philipp A and Louboutin, Mathias and Modzelewski, Henryk and Jones, Charles and Selvage, James and Herrmann, Felix J}, booktitle = {SEG Technical Program Expanded Abstracts 2019}, pages = {3984--3988}, year = {2019}, publisher = {Society of Exploration Geophysicists}}                                                        "
    }, {
    "id": 43,
    "url": "https://wanted2.github.io/bibliography/balaji2018benchmarking/",
    "title": "Benchmarking automatic machine learning frameworks",
    "body": "  Balaji, A. and Allen, A. 2018. Benchmarking automatic machine learning frameworks. arXiv preprint arXiv:1808. 06492. (2018).                                                                                             @article{balaji2018benchmarking, title = {Benchmarking automatic machine learning frameworks}, author = {Balaji, Adithya and Allen, Alexander}, journal = {arXiv preprint arXiv:1808. 06492}, year = {2018}}                                                        "
    }, {
    "id": 44,
    "url": "https://wanted2.github.io/bibliography/risco2021gpu/",
    "title": "GPU-Enabled Serverless Workflows for Efficient Multimedia Processing",
    "body": "  Risco, S. and Moltó, G. 2021. GPU-Enabled Serverless Workflows for Efficient Multimedia Processing. Applied Sciences. 11, 4 (2021), 1438.                                                                                             @article{risco2021gpu, title = {GPU-Enabled Serverless Workflows for Efficient Multimedia Processing}, author = {Risco, Sebasti{\'a}n and Molt{\'o}, Germ{\'a}n}, journal = {Applied Sciences}, volume = {11}, number = {4}, pages = {1438}, year = {2021}, publisher = {Multidisciplinary Digital Publishing Institute}}                                                        "
    }, {
    "id": 45,
    "url": "https://wanted2.github.io/bibliography/qureshi2019reduce/",
    "title": "Reduce Cost of Batch Processing Microsoft Azure Cloud",
    "body": "  Qureshi, A. N. 2019. Reduce Cost of Batch Processing Microsoft Azure Cloud. JETIR-International Journal of Emerging Technologies and Innovative Research. (2019), 2349–5162.                                                                                             @article{qureshi2019reduce, title = {Reduce Cost of Batch Processing Microsoft Azure Cloud}, author = {Qureshi, Asfak N}, journal = {JETIR-International Journal of Emerging Technologies and Innovative Research}, pages = {2349--5162}, year = {2019}}                                                        "
    }, {
    "id": 46,
    "url": "https://wanted2.github.io/bibliography/WhatIsAW85_online/",
    "title": "What Is AWS Batch? - AWS Batch",
    "body": "  What Is AWS Batch? - AWS Batch. https://docs. aws. amazon. com/batch/latest/userguide/what-is-batch. html.   (Accessed on 08/23/2021)                                                                                            @misc{WhatIsAW85:online, author = {}, title = {What Is AWS Batch? - AWS Batch}, howpublished = {https://docs. aws. amazon. com/batch/latest/userguide/what-is-batch. html}, month = {}, year = {}, note = {(Accessed on 08/23/2021)}}                                                        "
    }, {
    "id": 47,
    "url": "https://wanted2.github.io/bibliography/Computee29_online/",
    "title": "Compute environment parameters - AWS Batch",
    "body": "  Compute environment parameters - AWS Batch. https://docs. aws. amazon. com/batch/latest/userguide/compute_environment_parameters. html.   (Accessed on 08/23/2021)                                                                                            @misc{Computee29:online, author = {}, title = {Compute environment parameters - AWS Batch}, howpublished = {https://docs. aws. amazon. com/batch/latest/userguide/compute_environment_parameters. html}, month = {}, year = {}, note = {(Accessed on 08/23/2021)}}                                                        "
    }, {
    "id": 48,
    "url": "https://wanted2.github.io/bibliography/BatchCom43_online/",
    "title": "Batch - Compute job scheduling service | Microsoft Azure",
    "body": "  Batch - Compute job scheduling service | Microsoft Azure. https://azure. microsoft. com/en-us/services/batch/.   (Accessed on 08/24/2021)                                                                                            @misc{BatchCom43:online, author = {}, title = {Batch - Compute job scheduling service | Microsoft Azure}, howpublished = {https://azure. microsoft. com/en-us/services/batch/}, month = {}, year = {}, note = {(Accessed on 08/24/2021)}}                                                        "
    }, {
    "id": 49,
    "url": "https://wanted2.github.io/bibliography/Configur92_online/",
    "title": "Configure bitbucket-pipelines.yml | Bitbucket Cloud | Atlassian Support",
    "body": "  Configure bitbucket-pipelines. yml | Bitbucket Cloud | Atlassian Support. https://support. atlassian. com/bitbucket-cloud/docs/configure-bitbucket-pipelinesyml/.   (Accessed on 07/23/2021)                                                                                            @misc{Configur92:online, author = {}, title = {Configure bitbucket-pipelines. yml | Bitbucket Cloud | Atlassian Support}, howpublished = {https://support. atlassian. com/bitbucket-cloud/docs/configure-bitbucket-pipelinesyml/}, month = {}, year = {}, note = {(Accessed on 07/23/2021)}}                                                        "
    }, {
    "id": 50,
    "url": "https://wanted2.github.io/bibliography/Setupand33_online/",
    "title": "Set up and use runners for Linux | Bitbucket Cloud | Atlassian Support",
    "body": "  Set up and use runners for Linux | Bitbucket Cloud | Atlassian Support. https://support. atlassian. com/bitbucket-cloud/docs/set-up-and-use-runners-for-linux/.   (Accessed on 07/23/2021)                                                                                            @misc{Setupand33:online, author = {}, title = {Set up and use runners for Linux | Bitbucket Cloud | Atlassian Support}, howpublished = {https://support. atlassian. com/bitbucket-cloud/docs/set-up-and-use-runners-for-linux/}, month = {}, year = {}, note = {(Accessed on 07/23/2021)}}                                                        "
    }, {
    "id": 51,
    "url": "https://wanted2.github.io/bibliography/TheC4mod76_online/",
    "title": "The C4 model for visualising software architecture",
    "body": "  The C4 model for visualising software architecture. https://c4model. com/.   (Accessed on 09/05/2021)                                                                                            @misc{TheC4mod76:online, author = {}, title = {The C4 model for visualising software architecture}, howpublished = {https://c4model. com/}, month = {}, year = {}, note = {(Accessed on 09/05/2021)}}                                                        "
    }, {
    "id": 52,
    "url": "https://wanted2.github.io/bibliography/ArchiOp50_online/",
    "title": "Archi – Open Source ArchiMate Modelling",
    "body": "  Archi – Open Source ArchiMate Modelling. https://www. archimatetool. com/.   (Accessed on 09/05/2021)                                                                                            @misc{ArchiOp50:online, author = {}, title = {Archi – Open Source ArchiMate Modelling}, howpublished = {https://www. archimatetool. com/}, month = {}, year = {}, note = {(Accessed on 09/05/2021)}}                                                        "
    }, {
    "id": 53,
    "url": "https://wanted2.github.io/bibliography/brown2013software/",
    "title": "Software architecture for developers",
    "body": "  Brown, S. 2013. Software architecture for developers. Coding the Architecture. (2013).                                                                                             @article{brown2013software, title = {Software architecture for developers}, author = {Brown, Simon}, journal = {Coding the Architecture}, year = {2013}}                                                        "
    }, {
    "id": 54,
    "url": "https://wanted2.github.io/bibliography/LexModel37_online/",
    "title": "LexModelsV2 – Boto3 Docs 1.18.6 documentation",
    "body": "  LexModelsV2 – Boto3 Docs 1. 18. 6 documentation. https://boto3. amazonaws. com/v1/documentation/api/latest/reference/services/lexv2-models. html.   (Accessed on 07/25/2021)                                                                                            @misc{LexModel37:online, author = {}, title = {LexModelsV2 -- Boto3 Docs 1. 18. 6 documentation}, howpublished = {https://boto3. amazonaws. com/v1/documentation/api/latest/reference/services/lexv2-models. html}, month = {}, year = {}, note = {(Accessed on 07/25/2021)}}                                                        "
    }, {
    "id": 55,
    "url": "https://wanted2.github.io/bibliography/Buildado59_online/",
    "title": "Build a document search bot using Amazon Lex and Amazon Elasticsearch Service | AWS Machine Learning Blog",
    "body": "  Jain, A. and Kulkarni, R. Build a document search bot using Amazon Lex and Amazon Elasticsearch Service | AWS Machine Learning Blog. https://aws. amazon. com/jp/blogs/machine-learning/build-a-document-search-bot-using-amazon-lex-and-amazon-elasticsearch-service/.   (Accessed on 07/25/2021)                                                                                            @misc{Buildado59:online, author = {Jain, Akash and Kulkarni, Rahul}, title = {Build a document search bot using Amazon Lex and Amazon Elasticsearch Service | AWS Machine Learning Blog}, howpublished = {https://aws. amazon. com/jp/blogs/machine-learning/build-a-document-search-bot-using-amazon-lex-and-amazon-elasticsearch-service/}, month = {}, year = {}, note = {(Accessed on 07/25/2021)}}                                                        "
    }, {
    "id": 56,
    "url": "https://wanted2.github.io/bibliography/DeployaW32_online/",
    "title": "Deploy a Web UI for Your Chatbot  | AWS Machine Learning Blog",
    "body": "  Atoa, O. and Strahan, B. Deploy a Web UI for Your Chatbot  | AWS Machine Learning Blog. https://aws. amazon. com/jp/blogs/machine-learning/deploy-a-web-ui-for-your-chatbot/.   (Accessed on 07/25/2021)                                                                                            @misc{DeployaW32:online, author = {Atoa, Oliver and Strahan, Bob}, title = {Deploy a Web UI for Your Chatbot  | AWS Machine Learning Blog}, howpublished = {https://aws. amazon. com/jp/blogs/machine-learning/deploy-a-web-ui-for-your-chatbot/}, month = {}, year = {}, note = {(Accessed on 07/25/2021)}}                                                        "
    }, {
    "id": 57,
    "url": "https://wanted2.github.io/bibliography/vmcaws/",
    "title": "The Business Value of Running Applications on VMware Cloud on AWS in VMware Hybrid Cloud Environments",
    "body": "  Villars, R. L. , Mohan, D. and Marden, M. 2020. The Business Value of Running Applications on VMware Cloud on AWS in VMware Hybrid Cloud Environments. VMware.                                                                                             @misc{vmcaws, title = {The Business Value of Running Applications on VMware Cloud on AWS in VMware Hybrid Cloud Environments}, author = {Villars, Richard L. and Mohan, Deepak and Marden, Matthew}, year = {2020}, publisher = {VMware}, howpublished = {https://www. vmware. com/content/dam/learn/en/amer/fy21/pdf/691726_2020_Business_Value_Running_Applications_VMware_Cloud_AWS_VMware_Hybrid_Cloud_Environments. pdf}}                                                        "
    }, {
    "id": 58,
    "url": "https://wanted2.github.io/bibliography/vmcawsy/",
    "title": "VMware Cloud on AWS: Tech Deep Dive Webinar",
    "body": "  Cloud, V. M. 2018. VMware Cloud on AWS: Tech Deep Dive Webinar.                                                                                             @misc{vmcawsy, author = {Cloud, VMware}, title = {VMware Cloud on AWS: Tech Deep Dive Webinar}, howpublished = {\url{https://www. youtube. com/watch?v=R4Uq53rtPIE}}, year = {2018}}                                                        "
    }, {
    "id": 59,
    "url": "https://wanted2.github.io/bibliography/vmcawst/",
    "title": "VMware Cloud on AWS: Deployment, Migration, and Configuration of Oracle Workloads",
    "body": "  Cloud, V. M. VMware Cloud on AWS: Deployment, Migration, and Configuration of Oracle Workloads.   Accessed at \today                                                                                            @misc{vmcawst, author = {Cloud, VMware}, title = {VMware Cloud on AWS: Deployment, Migration, and Configuration of Oracle Workloads}, howpublished = {\url{https://docs. vmware. com/en/VMware-Cloud-on-AWS/solutions/index. html}}, note = {Accessed at \today}}                                                        "
    }, {
    "id": 60,
    "url": "https://wanted2.github.io/bibliography/gu2016incorporating/",
    "title": "Incorporating Copying Mechanism in Sequence-to-Sequence Learning",
    "body": "  Gu, J. , Lu, Z. , Li, H. and Li, V. O. K. 2016. Incorporating Copying Mechanism in Sequence-to-Sequence Learning.                                                                                             @misc{gu2016incorporating, title = {Incorporating Copying Mechanism in Sequence-to-Sequence Learning}, author = {Gu, Jiatao and Lu, Zhengdong and Li, Hang and Li, Victor O. K. }, year = {2016}, eprint = {1603. 06393}, archiveprefix = {arXiv}, primaryclass = {cs. CL}}                                                        "
    }, {
    "id": 61,
    "url": "https://wanted2.github.io/bibliography/bahdanau2014neural/",
    "title": "Neural machine translation by jointly learning to align and translate",
    "body": "  Bahdanau, D. , Cho, K. and Bengio, Y. 2014. Neural machine translation by jointly learning to align and translate. arXiv preprint arXiv:1409. 0473. (2014).                                                                                             @article{bahdanau2014neural, title = {Neural machine translation by jointly learning to align and translate}, author = {Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua}, journal = {arXiv preprint arXiv:1409. 0473}, year = {2014}}                                                        "
    }, {
    "id": 62,
    "url": "https://wanted2.github.io/bibliography/granger1969investigating/",
    "title": "Investigating causal relations by econometric models and cross-spectral methods",
    "body": "  Granger, C. W. J. 1969. Investigating causal relations by econometric models and cross-spectral methods. Econometrica: journal of the Econometric Society. (1969), 424–438.                                                                                             @article{granger1969investigating, title = {Investigating causal relations by econometric models and cross-spectral methods}, author = {Granger, Clive WJ}, journal = {Econometrica: journal of the Econometric Society}, pages = {424--438}, year = {1969}, publisher = {JSTOR}}                                                        "
    }, {
    "id": 63,
    "url": "https://wanted2.github.io/bibliography/feige1979casual/",
    "title": "The casual causal relationship between money and income: Some caveats for time series analysis",
    "body": "  Feige, E. L. and Pearce, D. K. 1979. The casual causal relationship between money and income: Some caveats for time series analysis. The Review of Economics and Statistics. (1979), 521–533.                                                                                             @article{feige1979casual, title = {The casual causal relationship between money and income: Some caveats for time series analysis}, author = {Feige, Edgar L and Pearce, Douglas K}, journal = {The Review of Economics and Statistics}, pages = {521--533}, year = {1979}, publisher = {JSTOR}}                                                        "
    }, {
    "id": 64,
    "url": "https://wanted2.github.io/bibliography/thurman1988chickens/",
    "title": "Chickens, eggs, and causality, or which came first",
    "body": "  Thurman, W. N. , Fisher, M. E. and others 1988. Chickens, eggs, and causality, or which came first. American journal of agricultural economics. 70, 2 (1988), 237–238.                                                                                             @article{thurman1988chickens, title = {Chickens, eggs, and causality, or which came first}, author = {Thurman, Walter N and Fisher, Mark E and others}, journal = {American journal of agricultural economics}, volume = {70}, number = {2}, pages = {237--238}, year = {1988}, publisher = {Agricultural and Applied Economics Association}}                                                        "
    }, {
    "id": 65,
    "url": "https://wanted2.github.io/bibliography/TheProdu24_online/",
    "title": "The Productivity–Pay Gap | Economic Policy Institute",
    "body": "  The Productivity–Pay Gap | Economic Policy Institute.   (Accessed on 11/21/2021)                                                                                            @misc{TheProdu24:online, author = {}, title = {The Productivity–Pay Gap | Economic Policy Institute}, howpublished = {\url{https://www. epi. org/productivity-pay-gap/}}, month = {}, year = {}, note = {(Accessed on 11/21/2021)}}                                                        "
    }, {
    "id": 66,
    "url": "https://wanted2.github.io/bibliography/ipa01/",
    "title": "情報システムの障害状況 - 2019 年後半データ",
    "body": "  松田 晃一, 村岡 恭昭 and 齋藤 毅 2019. 情報システムの障害状況 - 2019 年後半データ. IPA社会基盤センター.                                                                                             @techreport{ipa01, author = {松田, 晃一 and 村岡, 恭昭 and 齋藤, 毅}, title = {情報システムの障害状況 - 2019 年後半データ}, institution = {IPA社会基盤センター}, year = {2019}}                                                        "
    }, {
    "id": 67,
    "url": "https://wanted2.github.io/bibliography/ipa02/",
    "title": "情報システムの障害状況一覧：IPA 独立行政法人 情報処理推進機構",
    "body": "  情報処理推進機構 情報システムの障害状況一覧：IPA 独立行政法人 情報処理推進機構.   (Accessed on 12/19/2021)                                                                                            @misc{ipa02, author = {情報処理推進機構}, title = {情報システムの障害状況一覧：IPA 独立行政法人 情報処理推進機構}, howpublished = {\url{https://www. ipa. go. jp/sec/system/system_fault. html}}, month = {}, year = {}, note = {(Accessed on 12/19/2021)}}                                                        "
    }, {
    "id": 68,
    "url": "https://wanted2.github.io/bibliography/ipa03/",
    "title": "プレス発表　重要インフラを支えるシステムの障害情報や対策を分析した2種類の教訓集を公開：IPA 独立行政法人 情報処理推進機構",
    "body": "  情報処理推進機構 プレス発表　重要インフラを支えるシステムの障害情報や対策を分析した2種類の教訓集を公開：IPA 独立行政法人 情報処理推進機構.   (Accessed on 12/19/2021)                                                                                            @misc{ipa03, author = {情報処理推進機構}, title = {プレス発表　重要インフラを支えるシステムの障害情報や対策を分析した2種類の教訓集を公開：IPA 独立行政法人 情報処理推進機構}, howpublished = {\url{https://www. ipa. go. jp/about/press/20140513. html}}, month = {}, year = {}, note = {(Accessed on 12/19/2021)}}                                                        "
    }, {
    "id": 69,
    "url": "https://wanted2.github.io/bibliography/chiba01/",
    "title": "セキュリティ対策に関するお願い｜安心してご利用いただくために｜千葉銀行",
    "body": "  千葉銀行 セキュリティ対策に関するお願い｜安心してご利用いただくために｜千葉銀行.   (Accessed on 12/19/2021)                                                                                            @misc{chiba01, author = {千葉銀行}, title = {セキュリティ対策に関するお願い｜安心してご利用いただくために｜千葉銀行}, howpublished = {\url{https://www. chibabank. co. jp/webeb/security/internet/}}, month = {}, year = {}, note = {(Accessed on 12/19/2021)}}                                                        "
    }, {
    "id": 70,
    "url": "https://wanted2.github.io/bibliography/AWSLambd88_online/",
    "title": "AWS Lambda – Serverless Compute - Amazon Web Services",
    "body": "  AWS Lambda – Serverless Compute - Amazon Web Services. https://aws. amazon. com/lambda/.   (Accessed on 04/03/2021)                                                                                            @misc{AWSLambd88:online, author = {}, title = {AWS Lambda – Serverless Compute - Amazon Web Services}, howpublished = {https://aws. amazon. com/lambda/}, month = {}, year = {}, note = {(Accessed on 04/03/2021)}}                                                        "
    }, {
    "id": 71,
    "url": "https://wanted2.github.io/bibliography/Creating27_online/",
    "title": "Creating faster AWS Lambda functions with AVX2 | AWS Compute Blog",
    "body": "  Creating faster AWS Lambda functions with AVX2 | AWS Compute Blog. https://aws. amazon. com/blogs/compute/creating-faster-aws-lambda-functions-with-avx2/.   (Accessed on 04/03/2021)                                                                                            @misc{Creating27:online, author = {}, title = {Creating faster AWS Lambda functions with AVX2 | AWS Compute Blog}, howpublished = {https://aws. amazon. com/blogs/compute/creating-faster-aws-lambda-functions-with-avx2/}, month = {}, year = {}, note = {(Accessed on 04/03/2021)}}                                                        "
    }, {
    "id": 72,
    "url": "https://wanted2.github.io/bibliography/Parallel52_online/",
    "title": "Parallel Processing in Python with AWS Lambda | AWS Compute Blog",
    "body": "  Parallel Processing in Python with AWS Lambda | AWS Compute Blog. https://aws. amazon. com/blogs/compute/parallel-processing-in-python-with-aws-lambda/.   (Accessed on 04/03/2021)                                                                                            @misc{Parallel52:online, author = {}, title = {Parallel Processing in Python with AWS Lambda | AWS Compute Blog}, howpublished = {https://aws. amazon. com/blogs/compute/parallel-processing-in-python-with-aws-lambda/}, month = {}, year = {}, note = {(Accessed on 04/03/2021)}}                                                        "
    }, {
    "id": 73,
    "url": "https://wanted2.github.io/bibliography/AmazonSa17_online/",
    "title": "Amazon SageMaker – Machine Learning – Amazon Web Services",
    "body": "  Amazon SageMaker – Machine Learning – Amazon Web Services. https://aws. amazon. com/sagemaker/.   (Accessed on 04/03/2021)                                                                                            @misc{AmazonSa17:online, author = {}, title = {Amazon SageMaker – Machine Learning – Amazon Web Services}, howpublished = {https://aws. amazon. com/sagemaker/}, month = {}, year = {}, note = {(Accessed on 04/03/2021)}}                                                        "
    }, {
    "id": 74,
    "url": "https://wanted2.github.io/bibliography/NamedEnt13_online/",
    "title": "Named Entity Recognition · Prodigy · An annotation tool for AI, Machine Learning & NLP",
    "body": "  Named Entity Recognition · Prodigy · An annotation tool for AI, Machine Learning &amp; NLP. https://prodi. gy/docs/named-entity-recognition.   (Accessed on 04/03/2021)                                                                                            @misc{NamedEnt13:online, author = {}, title = {Named Entity Recognition · Prodigy · An annotation tool for AI, Machine Learning \&amp; NLP}, howpublished = {https://prodi. gy/docs/named-entity-recognition}, month = {}, year = {}, note = {(Accessed on 04/03/2021)}}                                                        "
    }, {
    "id": 75,
    "url": "https://wanted2.github.io/bibliography/NamedEnt0_online/",
    "title": "Named Entity Recognition - Cohen Courses",
    "body": "  Named Entity Recognition - Cohen Courses. http://curtis. ml. cmu. edu/w/courses/index. php/Named_Entity_Recognition.   (Accessed on 04/03/2021)                                                                                            @misc{NamedEnt0:online, author = {}, title = {Named Entity Recognition - Cohen Courses}, howpublished = {http://curtis. ml. cmu. edu/w/courses/index. php/Named_Entity_Recognition}, month = {}, year = {}, note = {(Accessed on 04/03/2021)}}                                                        "
    }, {
    "id": 76,
    "url": "https://wanted2.github.io/bibliography/googlese65_online/",
    "title": "google/sentencepiece: Unsupervised text tokenizer for Neural Network-based text generation.",
    "body": "  google/sentencepiece: Unsupervised text tokenizer for Neural Network-based text generation. https://github. com/google/sentencepiece.   (Accessed on 04/03/2021)                                                                                            @misc{googlese65:online, author = {}, title = {google/sentencepiece: Unsupervised text tokenizer for Neural Network-based text generation. }, howpublished = {https://github. com/google/sentencepiece}, month = {}, year = {}, note = {(Accessed on 04/03/2021)}}                                                        "
    }, {
    "id": 77,
    "url": "https://wanted2.github.io/bibliography/sennrich-etal-2016-neural/",
    "title": "Neural Machine Translation of Rare Words with Subword Units",
    "body": "  Sennrich, R. , Haddow, B. and Birch, A. 2016. Neural Machine Translation of Rare Words with Subword Units. Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) (Berlin, Germany, Aug. 2016), 1715–1725.     DOI                                                                                            @inproceedings{sennrich-etal-2016-neural, title = {Neural Machine Translation of Rare Words with Subword Units}, author = {Sennrich, Rico and Haddow, Barry and Birch, Alexandra}, booktitle = {Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, month = aug, year = {2016}, address = {Berlin, Germany}, publisher = {Association for Computational Linguistics}, url = {https://www. aclweb. org/anthology/P16-1162}, doi = {10. 18653/v1/P16-1162}, pages = {1715--1725}}                                                        "
    }, {
    "id": 78,
    "url": "https://wanted2.github.io/bibliography/DBLP_journals/corr/abs-1804-10959/",
    "title": "Subword Regularization: Improving Neural Network Translation Models
                   with Multiple Subword Candidates",
    "body": "  Kudo, T. 2018. Subword Regularization: Improving Neural Network Translation Models          with Multiple Subword Candidates. CoRR. abs/1804. 10959, (2018).                                                                                             @article{DBLP:journals/corr/abs-1804-10959, author = {Kudo, Taku}, title = {Subword Regularization: Improving Neural Network Translation Models           with Multiple Subword Candidates}, journal = {CoRR}, volume = {abs/1804. 10959}, year = {2018}, url = {http://arxiv. org/abs/1804. 10959}, archiveprefix = {arXiv}, eprint = {1804. 10959}, timestamp = {Mon, 13 Aug 2018 16:48:57 +0200}, biburl = {https://dblp. org/rec/journals/corr/abs-1804-10959. bib}, bibsource = {dblp computer science bibliography, https://dblp. org}}                                                        "
    }, {
    "id": 79,
    "url": "https://wanted2.github.io/bibliography/TheStanf29_online/",
    "title": "The Stanford Question Answering Dataset",
    "body": "  The Stanford Question Answering Dataset. https://rajpurkar. github. io/SQuAD-explorer/.   (Accessed on 04/03/2021)                                                                                            @misc{TheStanf29:online, author = {}, title = {The Stanford Question Answering Dataset}, howpublished = {https://rajpurkar. github. io/SQuAD-explorer/}, month = {}, year = {}, note = {(Accessed on 04/03/2021)}}                                                        "
    }, {
    "id": 80,
    "url": "https://wanted2.github.io/bibliography/DBLP_journals/corr/abs-1909-11942/",
    "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language
                   Representations",
    "body": "  Lan, Z. , Chen, M. , Goodman, S. , Gimpel, K. , Sharma, P. and Soricut, R. 2019. ALBERT: A Lite BERT for Self-supervised Learning of Language          Representations. CoRR. abs/1909. 11942, (2019).                                                                                             @article{DBLP:journals/corr/abs-1909-11942, author = {Lan, Zhenzhong and Chen, Mingda and Goodman, Sebastian and Gimpel, Kevin and Sharma, Piyush and Soricut, Radu}, title = {{ALBERT:} {A} Lite {BERT} for Self-supervised Learning of Language           Representations}, journal = {CoRR}, volume = {abs/1909. 11942}, year = {2019}, url = {http://arxiv. org/abs/1909. 11942}, archiveprefix = {arXiv}, eprint = {1909. 11942}, timestamp = {Fri, 27 Sep 2019 13:04:21 +0200}, biburl = {https://dblp. org/rec/journals/corr/abs-1909-11942. bib}, bibsource = {dblp computer science bibliography, https://dblp. org}}                                                        "
    }, {
    "id": 81,
    "url": "https://wanted2.github.io/bibliography/spaCyIn92_online/",
    "title": "spaCy: Industrial-strength Natural Language Processing in Python",
    "body": "  spaCy: Industrial-strength Natural Language Processing in Python. https://spacy. io/.   (Accessed on 04/03/2021)                                                                                            @misc{spaCyIn92:online, author = {}, title = {spaCy: Industrial-strength Natural Language Processing in Python}, howpublished = {https://spacy. io/}, month = {}, year = {}, note = {(Accessed on 04/03/2021)}}                                                        "
    }, {
    "id": 82,
    "url": "https://wanted2.github.io/bibliography/ApacheMX35_online/",
    "title": "Apache MXNet on AWS",
    "body": "  Apache MXNet on AWS. https://aws. amazon. com/mxnet/.   (Accessed on 04/03/2021)                                                                                            @misc{ApacheMX35:online, author = {}, title = {Apache MXNet on AWS}, howpublished = {https://aws. amazon. com/mxnet/}, month = {}, year = {}, note = {(Accessed on 04/03/2021)}}                                                        "
    }, {
    "id": 83,
    "url": "https://wanted2.github.io/bibliography/ApacheMX2_online/",
    "title": "Apache MXNet | A flexible and efficient library for deep learning.",
    "body": "  Apache MXNet | A flexible and efficient library for deep learning. https://mxnet. apache. org/versions/1. 8. 0/.   (Accessed on 04/03/2021)                                                                                            @misc{ApacheMX2:online, author = {}, title = {Apache MXNet | A flexible and efficient library for deep learning. }, howpublished = {https://mxnet. apache. org/versions/1. 8. 0/}, month = {}, year = {}, note = {(Accessed on 04/03/2021)}}                                                        "
    }, {
    "id": 84,
    "url": "https://wanted2.github.io/bibliography/DBLP_journals/corr/abs-1810-04805/",
    "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language
                   Understanding",
    "body": "  Devlin, J. , Chang, M. -W. , Lee, K. and Toutanova, K. 2018. BERT: Pre-training of Deep Bidirectional Transformers for Language          Understanding. CoRR. abs/1810. 04805, (2018).                                                                                             @article{DBLP:journals/corr/abs-1810-04805, author = {Devlin, Jacob and Chang, Ming{-}Wei and Lee, Kenton and Toutanova, Kristina}, title = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language           Understanding}, journal = {CoRR}, volume = {abs/1810. 04805}, year = {2018}, url = {http://arxiv. org/abs/1810. 04805}, archiveprefix = {arXiv}, eprint = {1810. 04805}, timestamp = {Tue, 30 Oct 2018 20:39:56 +0100}, biburl = {https://dblp. org/rec/journals/corr/abs-1810-04805. bib}, bibsource = {dblp computer science bibliography, https://dblp. org}}                                                        "
    }, {
    "id": 85,
    "url": "https://wanted2.github.io/bibliography/BERT--glu8_online/",
    "title": "BERT – gluonnlp 0.10.0 documentation",
    "body": "  BERT – gluonnlp 0. 10. 0 documentation. https://nlp. gluon. ai/model_zoo/bert/index. html.   (Accessed on 04/03/2021)                                                                                            @misc{BERT--glu8:online, author = {}, title = {BERT -- gluonnlp 0. 10. 0 documentation}, howpublished = {https://nlp. gluon. ai/model_zoo/bert/index. html}, month = {}, year = {}, note = {(Accessed on 04/03/2021)}}                                                        "
    }, {
    "id": 86,
    "url": "https://wanted2.github.io/bibliography/GluonNLP52_online/",
    "title": "GluonNLP: NLP made easy – gluonnlp 0.10.0 documentation",
    "body": "  GluonNLP: NLP made easy – gluonnlp 0. 10. 0 documentation. https://nlp. gluon. ai/index. html.   (Accessed on 04/03/2021)                                                                                            @misc{GluonNLP52:online, author = {}, title = {GluonNLP: NLP made easy -- gluonnlp 0. 10. 0 documentation}, howpublished = {https://nlp. gluon. ai/index. html}, month = {}, year = {}, note = {(Accessed on 04/03/2021)}}                                                        "
    }, {
    "id": 87,
    "url": "https://wanted2.github.io/bibliography/Whatisth14_online/",
    "title": "What is the AWS Serverless Application Model (AWS SAM)? - AWS Serverless Application Model",
    "body": "  What is the AWS Serverless Application Model (AWS SAM)? - AWS Serverless Application Model. https://docs. aws. amazon. com/serverless-application-model/latest/developerguide/what-is-sam. html.   (Accessed on 04/03/2021)                                                                                            @misc{Whatisth14:online, author = {}, title = {What is the AWS Serverless Application Model (AWS SAM)? - AWS Serverless Application Model}, howpublished = {https://docs. aws. amazon. com/serverless-application-model/latest/developerguide/what-is-sam. html}, month = {}, year = {}, note = {(Accessed on 04/03/2021)}}                                                        "
    }, {
    "id": 88,
    "url": "https://wanted2.github.io/bibliography/Managing69_online/",
    "title": "Managing concurrency for a Lambda function - AWS Lambda",
    "body": "  Managing concurrency for a Lambda function - AWS Lambda. https://docs. aws. amazon. com/lambda/latest/dg/configuration-concurrency. html.   (Accessed on 04/04/2021)                                                                                            @misc{Managing69:online, author = {}, title = {Managing concurrency for a Lambda function - AWS Lambda}, howpublished = {https://docs. aws. amazon. com/lambda/latest/dg/configuration-concurrency. html}, month = {}, year = {}, note = {(Accessed on 04/04/2021)}}                                                        "
    }, {
    "id": 89,
    "url": "https://wanted2.github.io/bibliography/SelfSupe2_online/",
    "title": "Self Supervised Representation Learning in NLP",
    "body": "  Self Supervised Representation Learning in NLP. https://amitness. com/2020/05/self-supervised-learning-nlp/.   (Accessed on 04/04/2021)                                                                                            @misc{SelfSupe2:online, author = {}, title = {Self Supervised Representation Learning in NLP}, howpublished = {https://amitness. com/2020/05/self-supervised-learning-nlp/}, month = {}, year = {}, note = {(Accessed on 04/04/2021)}}                                                        "
    }, {
    "id": 90,
    "url": "https://wanted2.github.io/bibliography/ThisisLe25_online/",
    "title": "This is Lean |",
    "body": "  This is Lean |.   (Accessed on 11/28/2021)                                                                                            @misc{ThisisLe25:online, author = {}, title = {This is Lean |}, howpublished = {\url{https://thisislean. com/}}, month = {}, year = {}, note = {(Accessed on 11/28/2021)}}                                                        "
    }, {
    "id": 91,
    "url": "https://wanted2.github.io/bibliography/bourque2004swebok/",
    "title": "SWEBOK",
    "body": "  Bourque, P. and Fairley, R. 2004. SWEBOK. Nd: IEEE Computer society. (2004).                                                                                             @article{bourque2004swebok, title = {SWEBOK}, author = {Bourque, Pierre and Fairley, R}, journal = {Nd: IEEE Computer society}, year = {2004}}                                                        "
    }, {
    "id": 92,
    "url": "https://wanted2.github.io/bibliography/cunningham1992wycash/",
    "title": "The WyCash portfolio management system",
    "body": "  Cunningham, W. 1992. The WyCash portfolio management system. ACM SIGPLAN OOPS Messenger. 4, 2 (1992), 29–30.                                                                                             @article{cunningham1992wycash, title = {The WyCash portfolio management system}, author = {Cunningham, Ward}, journal = {ACM SIGPLAN OOPS Messenger}, volume = {4}, number = {2}, pages = {29--30}, year = {1992}, publisher = {ACM New York, NY, USA}}                                                        "
    }, {
    "id": 93,
    "url": "https://wanted2.github.io/bibliography/behutiye2017analyzing/",
    "title": "Analyzing the concept of technical debt in the context of agile software development: A systematic literature review",
    "body": "  Behutiye, W. N. , Rodrı́guez Pilar, Oivo, M. and Tosun, A. 2017. Analyzing the concept of technical debt in the context of agile software development: A systematic literature review. Information and Software Technology. 82, (2017), 139–158.                                                                                             @article{behutiye2017analyzing, title = {Analyzing the concept of technical debt in the context of agile software development: A systematic literature review}, author = {Behutiye, Woubshet Nema and Rodr{\'\i}guez, Pilar and Oivo, Markku and Tosun, Ay{\c{s}}e}, journal = {Information and Software Technology}, volume = {82}, pages = {139--158}, year = {2017}, publisher = {Elsevier}}                                                        "
    }, {
    "id": 94,
    "url": "https://wanted2.github.io/bibliography/GoogleAI54_online/",
    "title": "Google AI Blog: MediaPipe Holistic – Simultaneous Face, Hand and Pose Prediction, on Device",
    "body": "  Google AI Blog: MediaPipe Holistic – Simultaneous Face, Hand and Pose Prediction, on Device. https://ai. googleblog. com/2020/12/mediapipe-holistic-simultaneous-face. html.   (Accessed on 05/22/2021)                                                                                            @misc{GoogleAI54:online, author = {}, title = {Google AI Blog: MediaPipe Holistic -- Simultaneous Face, Hand and Pose Prediction, on Device}, howpublished = {https://ai. googleblog. com/2020/12/mediapipe-holistic-simultaneous-face. html}, month = {}, year = {}, note = {(Accessed on 05/22/2021)}}                                                        "
    }, {
    "id": 95,
    "url": "https://wanted2.github.io/bibliography/3Datamod65_online/",
    "title": "3. Data model – Python 3.9.6 documentation - Metaclasses",
    "body": "  3. Data model – Python 3. 9. 6 documentation - Metaclasses. https://docs. python. org/3/reference/datamodel. html#metaclasses.   (Accessed on 07/11/2021)                                                                                            @misc{3Datamod65:online, author = {}, title = {3. Data model -- Python 3. 9. 6 documentation - Metaclasses}, howpublished = {https://docs. python. org/3/reference/datamodel. html#metaclasses}, month = {}, year = {}, note = {(Accessed on 07/11/2021)}}                                                        "
    }, {
    "id": 96,
    "url": "https://wanted2.github.io/bibliography/Decorato8_online/",
    "title": "Decorator",
    "body": "  Decorator. https://refactoring. guru/design-patterns/decorator.   (Accessed on 07/11/2021)                                                                                            @misc{Decorato8:online, author = {}, title = {Decorator}, howpublished = {https://refactoring. guru/design-patterns/decorator}, month = {}, year = {}, note = {(Accessed on 07/11/2021)}}                                                        "
    }, {
    "id": 97,
    "url": "https://wanted2.github.io/bibliography/MLKitGoo18_online/",
    "title": "ML Kit  |  Google Developers",
    "body": "  ML Kit  |  Google Developers. https://developers. google. com/ml-kit.   (Accessed on 05/31/2021)                                                                                            @misc{MLKitGoo18:online, author = {}, title = {ML Kit  |  Google Developers}, howpublished = {https://developers. google. com/ml-kit}, month = {}, year = {}, note = {(Accessed on 05/31/2021)}}                                                        "
    }, {
    "id": 98,
    "url": "https://wanted2.github.io/bibliography/CameraXA49_online/",
    "title": "CameraX  |  Android デベロッパー  |  Android Developers",
    "body": "  CameraX  |  Android デベロッパー  |  Android Developers. https://developer. android. com/jetpack/androidx/releases/camera.   (Accessed on 05/31/2021)                                                                                            @misc{CameraXA49:online, author = {}, title = {CameraX  |  Android デベロッパー  |  Android Developers}, howpublished = {https://developer. android. com/jetpack/androidx/releases/camera}, month = {}, year = {}, note = {(Accessed on 05/31/2021)}}                                                        "
    }, {
    "id": 99,
    "url": "https://wanted2.github.io/bibliography/Algorith20_online/",
    "title": "Algorithmia - Deploy AI at Scale",
    "body": "  Algorithmia - Deploy AI at Scale. https://algorithmia. com/.   (Accessed on 08/15/2021)                                                                                            @misc{Algorith20:online, author = {}, title = {Algorithmia - Deploy AI at Scale}, howpublished = {https://algorithmia. com/}, month = {}, year = {}, note = {(Accessed on 08/15/2021)}}                                                        "
    }, {
    "id": 100,
    "url": "https://wanted2.github.io/bibliography/alla2021mlops/",
    "title": "What Is MLOps?",
    "body": "  Alla, S. and Adari, S. K. 2021. What Is MLOps? Beginning MLOps with MLFlow. Springer. 79–124.                                                                                             @incollection{alla2021mlops, title = {What Is MLOps?}, author = {Alla, Sridhar and Adari, Suman Kalyan}, booktitle = {Beginning MLOps with MLFlow}, pages = {79--124}, year = {2021}, publisher = {Springer}}                                                        "
    }, {
    "id": 101,
    "url": "https://wanted2.github.io/bibliography/makinen2021needs/",
    "title": "Who Needs MLOps: What Data Scientists Seek to Accomplish and How Can MLOps Help?",
    "body": "  Mäkinen, S. , Skogström, H. , Laaksonen, E. and Mikkonen, T. 2021. Who Needs MLOps: What Data Scientists Seek to Accomplish and How Can MLOps Help? arXiv preprint arXiv:2103. 08942. (2021).                                                                                             @article{makinen2021needs, title = {Who Needs MLOps: What Data Scientists Seek to Accomplish and How Can MLOps Help?}, author = {M{\ a}kinen, Sasu and Skogstr{\ o}m, Henrik and Laaksonen, Eero and Mikkonen, Tommi}, journal = {arXiv preprint arXiv:2103. 08942}, year = {2021}}                                                        "
    }, {
    "id": 102,
    "url": "https://wanted2.github.io/bibliography/raj2020edge/",
    "title": "Edge MLOps framework for AIoT applications",
    "body": "  Raj, E. 2020. Edge MLOps framework for AIoT applications. Arcada University of Applied Sciences.                                                                                             @masterthesis{raj2020edge, title = {Edge MLOps framework for AIoT applications}, author = {Raj, Emmanuel}, year = {2020}, school = {Arcada University of Applied Sciences}}                                                        "
    }, {
    "id": 103,
    "url": "https://wanted2.github.io/bibliography/martin2007professionalisn/",
    "title": "Professionalism and test-driven development",
    "body": "  Martin, R. C. 2007. Professionalism and test-driven development. IEEE Software. 24, 3 (2007), 32–36.                                                                                             @article{martin2007professionalisn, title = {Professionalism and test-driven development}, author = {Martin, Robert C}, journal = {IEEE Software}, volume = {24}, number = {3}, pages = {32--36}, year = {2007}, publisher = {IEEE}}                                                        "
    }, {
    "id": 104,
    "url": "https://wanted2.github.io/bibliography/FaceReco66_online/",
    "title": "Face Recognition - Algorithm by cv - Algorithmia",
    "body": "  Face Recognition - Algorithm by cv - Algorithmia. https://algorithmia. com/algorithms/cv/FaceRecognition/docs.   (Accessed on 08/15/2021)                                                                                            @misc{FaceReco66:online, author = {}, title = {Face Recognition - Algorithm by cv - Algorithmia}, howpublished = {https://algorithmia. com/algorithms/cv/FaceRecognition/docs}, month = {}, year = {}, note = {(Accessed on 08/15/2021)}}                                                        "
    }, {
    "id": 105,
    "url": "https://wanted2.github.io/bibliography/reportsa37_online/",
    "title": "OpenFace: A general-purpose face recognition library with mobile applications",
    "body": "  Brandon Amos, M. S. , Bartosz Ludwiczuk 2016. OpenFace: A general-purpose face recognition library with mobile applications. http://reports-archive. adm. cs. cmu. edu/anon/anon/2016/CMU-CS-16-118. pdf.   (Accessed on 08/15/2021)                                                                                            @techreport{reportsa37:online, author = {Brandon Amos, Bartosz Ludwiczuk, Mahadev Satyanarayanan}, title = {OpenFace: A general-purpose face recognition library with mobile applications}, howpublished = {http://reports-archive. adm. cs. cmu. edu/anon/anon/2016/CMU-CS-16-118. pdf}, month = jun, year = {2016}, note = {(Accessed on 08/15/2021)}, institution = {School of Computer Science, Carnegie Mellon University}}                                                        "
    }, {
    "id": 106,
    "url": "https://wanted2.github.io/bibliography/HostedDa90_online/",
    "title": "Hosted Data - Algorithmia Developer Center",
    "body": "  Hosted Data - Algorithmia Developer Center. https://algorithmia. com/developers/data/hosted.   (Accessed on 08/15/2021)                                                                                            @misc{HostedDa90:online, author = {}, title = {Hosted Data - Algorithmia Developer Center}, howpublished = {https://algorithmia. com/developers/data/hosted}, month = {}, year = {}, note = {(Accessed on 08/15/2021)}}                                                        "
    }, {
    "id": 107,
    "url": "https://wanted2.github.io/bibliography/LogManag44_online/",
    "title": "Log Management | CSRC",
    "body": "  US Department of Commerce, Technology Administration, National Institute of Standards and Technology Log Management | CSRC.   (Accessed on 12/12/2021)                                                                                            @misc{LogManag44:online, author = {{US Department of Commerce, Technology Administration, National Institute of Standards and Technology}}, title = {Log Management | CSRC}, howpublished = {\url{https://csrc. nist. gov/Projects/log-management}}, month = {}, year = {}, note = {(Accessed on 12/12/2021)}}                                                        "
    }, {
    "id": 108,
    "url": "https://wanted2.github.io/bibliography/M213156_online/",
    "title": "M-21-31: Memorandum for the Heads of Executive Departments and Agencies",
    "body": "  Executive Office of the President Office of Management and Budget 2021. M-21-31: Memorandum for the Heads of Executive Departments and Agencies.   (Accessed on 12/12/2021)                                                                                            @misc{M213156:online, author = {{Executive Office of the President Office of Management and Budget}}, title = {M-21-31:~Memorandum for the Heads of Executive Departments and Agencies}, howpublished = {\url{https://www. whitehouse. gov/wp-content/uploads/2021/08/M-21-31-Improving-the-Federal-Governments-Investigative-and-Remediation-Capabilities-Related-to-Cybersecurity-Incidents. pdf}}, month = aug, year = {2021}, note = {(Accessed on 12/12/2021)}}                                                        "
    }, {
    "id": 109,
    "url": "https://wanted2.github.io/bibliography/kent2006guide/",
    "title": "Guide to Computer Security Log Management: Recommendations of the National Institute of Standards and Technology",
    "body": "  Kent, K. A. and Souppaya, M. 2006. Guide to Computer Security Log Management: Recommendations of the National Institute of Standards and Technology. US Department of Commerce, Technology Administration, National Institute of Standards and Technology.                                                                                             @book{kent2006guide, title = {Guide to Computer Security Log Management:~Recommendations of the National Institute of Standards and Technology}, author = {Kent, Karen Ann and Souppaya, Murugiah}, year = {2006}, publisher = {US Department of Commerce, Technology Administration, National Institute of Standards and Technology}}                                                        "
    }, {
    "id": 110,
    "url": "https://wanted2.github.io/bibliography/DBLP_journals/corr/BodlaSCD17/",
    "title": "Improving Object Detection With One Line of Code",
    "body": "  Bodla, N. , Singh, B. , Chellappa, R. and Davis, L. S. 2017. Improving Object Detection With One Line of Code. CoRR. abs/1704. 04503, (2017).                                                                                             @article{DBLP:journals/corr/BodlaSCD17, author = {Bodla, Navaneeth and Singh, Bharat and Chellappa, Rama and Davis, Larry S. }, title = {Improving Object Detection With One Line of Code}, journal = {CoRR}, volume = {abs/1704. 04503}, year = {2017}, url = {http://arxiv. org/abs/1704. 04503}, archiveprefix = {arXiv}, eprint = {1704. 04503}, timestamp = {Mon, 13 Aug 2018 16:48:23 +0200}, biburl = {https://dblp. org/rec/journals/corr/BodlaSCD17. bib}, bibsource = {dblp computer science bibliography, https://dblp. org}}                                                        "
    }, {
    "id": 111,
    "url": "https://wanted2.github.io/bibliography/qin2017dual/",
    "title": "A dual-stage attention-based recurrent neural network for time series prediction",
    "body": "  Qin, Y. , Song, D. , Cheng, H. , Cheng, W. , Jiang, G. and Cottrell, G. W. 2017. A dual-stage attention-based recurrent neural network for time series prediction. Proceedings of the 26th International Joint Conference on Artificial Intelligence (2017), 2627–2633.                                                                                             @inproceedings{qin2017dual, title = {A dual-stage attention-based recurrent neural network for time series prediction}, author = {Qin, Yao and Song, Dongjin and Cheng, Haifeng and Cheng, Wei and Jiang, Guofei and Cottrell, Garrison W}, booktitle = {Proceedings of the 26th International Joint Conference on Artificial Intelligence}, pages = {2627--2633}, year = {2017}}                                                        "
    }, {
    "id": 112,
    "url": "https://wanted2.github.io/bibliography/kim2016sequence/",
    "title": "Sequence-Level Knowledge Distillation",
    "body": "  Kim, Y. and Rush, A. M. 2016. Sequence-Level Knowledge Distillation. Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing (2016), 1317–1327.                                                                                             @inproceedings{kim2016sequence, title = {Sequence-Level Knowledge Distillation}, author = {Kim, Yoon and Rush, Alexander M}, booktitle = {Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing}, pages = {1317--1327}, year = {2016}}                                                        "
    }, {
    "id": 113,
    "url": "https://wanted2.github.io/bibliography/lample2018phrase/",
    "title": "Phrase-Based & Neural Unsupervised Machine Translation",
    "body": "  Lample, G. , Ott, M. , Conneau, A. , Denoyer, L. and Ranzato, M. A. 2018. Phrase-Based &amp; Neural Unsupervised Machine Translation. Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (2018), 5039–5049.                                                                                             @inproceedings{lample2018phrase, title = {Phrase-Based \&amp; Neural Unsupervised Machine Translation}, author = {Lample, Guillaume and Ott, Myle and Conneau, Alexis and Denoyer, Ludovic and Ranzato, Marc’Aurelio}, booktitle = {Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing}, pages = {5039--5049}, year = {2018}}                                                        "
    }, {
    "id": 114,
    "url": "https://wanted2.github.io/bibliography/gatt2018survey/",
    "title": "Survey of the state of the art in natural language generation: Core tasks, applications and evaluation",
    "body": "  Gatt, A. and Krahmer, E. 2018. Survey of the state of the art in natural language generation: Core tasks, applications and evaluation. Journal of Artificial Intelligence Research. 61, (2018), 65–170.                                                                                             @article{gatt2018survey, title = {Survey of the state of the art in natural language generation: Core tasks, applications and evaluation}, author = {Gatt, Albert and Krahmer, Emiel}, journal = {Journal of Artificial Intelligence Research}, volume = {61}, pages = {65--170}, year = {2018}}                                                        "
    }, {
    "id": 115,
    "url": "https://wanted2.github.io/bibliography/peters2017semi/",
    "title": "Semi-supervised sequence tagging with bidirectional language models",
    "body": "  Peters, M. E. , Ammar, W. , Bhagavatula, C. and Power, R. 2017. Semi-supervised sequence tagging with bidirectional language models. arXiv preprint arXiv:1705. 00108. (2017).                                                                                             @article{peters2017semi, title = {Semi-supervised sequence tagging with bidirectional language models}, author = {Peters, Matthew E and Ammar, Waleed and Bhagavatula, Chandra and Power, Russell}, journal = {arXiv preprint arXiv:1705. 00108}, year = {2017}}                                                        "
    }, {
    "id": 116,
    "url": "https://wanted2.github.io/bibliography/press2017using/",
    "title": "Using the Output Embedding to Improve Language Models",
    "body": "  Press, O. and Wolf, L. 2017. Using the Output Embedding to Improve Language Models. Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers (2017), 157–163.                                                                                             @inproceedings{press2017using, title = {Using the Output Embedding to Improve Language Models}, author = {Press, Ofir and Wolf, Lior}, booktitle = {Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers}, pages = {157--163}, year = {2017}}                                                        "
    }, {
    "id": 117,
    "url": "https://wanted2.github.io/bibliography/dong2016language/",
    "title": "Language to logical form with neural attention",
    "body": "  Dong, L. and Lapata, M. 2016. Language to logical form with neural attention. 54th Annual Meeting of the Association for Computational Linguistics (2016), 33–43.                                                                                             @inproceedings{dong2016language, title = {Language to logical form with neural attention}, author = {Dong, Li and Lapata, Mirella}, booktitle = {54th Annual Meeting of the Association for Computational Linguistics}, pages = {33--43}, year = {2016}, organization = {Association for Computational Linguistics (ACL)}}                                                        "
    }, {
    "id": 118,
    "url": "https://wanted2.github.io/bibliography/devlin2014fast/",
    "title": "Fast and robust neural network joint models for statistical machine translation",
    "body": "  Devlin, J. , Zbib, R. , Huang, Z. , Lamar, T. , Schwartz, R. and Makhoul, J. 2014. Fast and robust neural network joint models for statistical machine translation. proceedings of the 52nd annual meeting of the Association for Computational Linguistics (Volume 1: Long Papers) (2014), 1370–1380.                                                                                             @inproceedings{devlin2014fast, title = {Fast and robust neural network joint models for statistical machine translation}, author = {Devlin, Jacob and Zbib, Rabih and Huang, Zhongqiang and Lamar, Thomas and Schwartz, Richard and Makhoul, John}, booktitle = {proceedings of the 52nd annual meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, pages = {1370--1380}, year = {2014}}                                                        "
    }, {
    "id": 119,
    "url": "https://wanted2.github.io/bibliography/yu2016video/",
    "title": "Video paragraph captioning using hierarchical recurrent neural networks",
    "body": "  Yu, H. , Wang, J. , Huang, Z. , Yang, Y. and Xu, W. 2016. Video paragraph captioning using hierarchical recurrent neural networks. Proceedings of the IEEE conference on computer vision and pattern recognition (2016), 4584–4593.                                                                                             @inproceedings{yu2016video, title = {Video paragraph captioning using hierarchical recurrent neural networks}, author = {Yu, Haonan and Wang, Jiang and Huang, Zhiheng and Yang, Yi and Xu, Wei}, booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition}, pages = {4584--4593}, year = {2016}}                                                        "
    }, {
    "id": 120,
    "url": "https://wanted2.github.io/bibliography/vinyals2015order/",
    "title": "Order matters: Sequence to sequence for sets",
    "body": "  Vinyals, O. , Bengio, S. and Kudlur, M. 2015. Order matters: Sequence to sequence for sets. arXiv preprint arXiv:1511. 06391. (2015).                                                                                             @article{vinyals2015order, title = {Order matters: Sequence to sequence for sets}, author = {Vinyals, Oriol and Bengio, Samy and Kudlur, Manjunath}, journal = {arXiv preprint arXiv:1511. 06391}, year = {2015}}                                                        "
    }, {
    "id": 121,
    "url": "https://wanted2.github.io/bibliography/ling2015finding/",
    "title": "Finding Function in Form: Compositional Character Models for Open Vocabulary Word Representation",
    "body": "  Ling, W. , Dyer, C. , Black, A. W. , Trancoso, I. , Fermandez, R. , Amir, S. , Marujo, L. and Luı́s Tiago 2015. Finding Function in Form: Compositional Character Models for Open Vocabulary Word Representation. Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (2015), 1520–1530.                                                                                             @inproceedings{ling2015finding, title = {Finding Function in Form: Compositional Character Models for Open Vocabulary Word Representation}, author = {Ling, Wang and Dyer, Chris and Black, Alan W and Trancoso, Isabel and Fermandez, Ram{\'o}n and Amir, Silvio and Marujo, Luis and Lu{\'\i}s, Tiago}, booktitle = {Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing}, pages = {1520--1530}, year = {2015}}                                                        "
    }, {
    "id": 122,
    "url": "https://wanted2.github.io/bibliography/li2017deep/",
    "title": "Deep reinforcement learning: An overview",
    "body": "  Li, Y. 2017. Deep reinforcement learning: An overview. arXiv preprint arXiv:1701. 07274. (2017).                                                                                             @article{li2017deep, title = {Deep reinforcement learning: An overview}, author = {Li, Yuxi}, journal = {arXiv preprint arXiv:1701. 07274}, year = {2017}}                                                        "
    }, {
    "id": 123,
    "url": "https://wanted2.github.io/bibliography/tu2016modeling/",
    "title": "Modeling Coverage for Neural Machine Translation",
    "body": "  Tu, Z. , Lu, Z. , Liu, Y. , Liu, X. and Li, H. 2016. Modeling Coverage for Neural Machine Translation. Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) (2016), 76–85.                                                                                             @inproceedings{tu2016modeling, title = {Modeling Coverage for Neural Machine Translation}, author = {Tu, Zhaopeng and Lu, Zhengdong and Liu, Yang and Liu, Xiaohua and Li, Hang}, booktitle = {Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, pages = {76--85}, year = {2016}}                                                        "
    }, {
    "id": 124,
    "url": "https://wanted2.github.io/bibliography/luong2015addressing/",
    "title": "Addressing the Rare Word Problem in Neural Machine Translation",
    "body": "  Luong, M. -T. , Sutskever, I. , Le, Q. , Vinyals, O. and Zaremba, W. 2015. Addressing the Rare Word Problem in Neural Machine Translation. Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers) (2015), 11–19.                                                                                             @inproceedings{luong2015addressing, title = {Addressing the Rare Word Problem in Neural Machine Translation}, author = {Luong, Minh-Thang and Sutskever, Ilya and Le, Quoc and Vinyals, Oriol and Zaremba, Wojciech}, booktitle = {Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)}, pages = {11--19}, year = {2015}}                                                        "
    }, {
    "id": 125,
    "url": "https://wanted2.github.io/bibliography/koehn2017six/",
    "title": "Six Challenges for Neural Machine Translation",
    "body": "  Koehn, P. and Knowles, R. 2017. Six Challenges for Neural Machine Translation. First Workshop on Neural Machine Translation (2017), 28–39.                                                                                             @inproceedings{koehn2017six, title = {Six Challenges for Neural Machine Translation}, author = {Koehn, Philipp and Knowles, Rebecca}, booktitle = {First Workshop on Neural Machine Translation}, pages = {28--39}, year = {2017}, organization = {Association for Computational Linguistics}}                                                        "
    }, {
    "id": 126,
    "url": "https://wanted2.github.io/bibliography/kulkarni2016hierarchical/",
    "title": "Hierarchical deep reinforcement learning: Integrating temporal abstraction and intrinsic motivation",
    "body": "  Kulkarni, T. D. , Narasimhan, K. , Saeedi, A. and Tenenbaum, J. 2016. Hierarchical deep reinforcement learning: Integrating temporal abstraction and intrinsic motivation. Advances in neural information processing systems. 29, (2016), 3675–3683.                                                                                             @article{kulkarni2016hierarchical, title = {Hierarchical deep reinforcement learning: Integrating temporal abstraction and intrinsic motivation}, author = {Kulkarni, Tejas D and Narasimhan, Karthik and Saeedi, Ardavan and Tenenbaum, Josh}, journal = {Advances in neural information processing systems}, volume = {29}, pages = {3675--3683}, year = {2016}}                                                        "
    }, {
    "id": 127,
    "url": "https://wanted2.github.io/bibliography/sordoni2015neural/",
    "title": "A Neural Network Approach to Context-Sensitive Generation of Conversational Responses",
    "body": "  Sordoni, A. , Galley, M. , Auli, M. , Brockett, C. , Ji, Y. , Mitchell, M. , Nie, J. -Y. , Gao, J. and Dolan, W. B. 2015. A Neural Network Approach to Context-Sensitive Generation of Conversational Responses. Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (2015), 196–205.                                                                                             @inproceedings{sordoni2015neural, title = {A Neural Network Approach to Context-Sensitive Generation of Conversational Responses}, author = {Sordoni, Alessandro and Galley, Michel and Auli, Michael and Brockett, Chris and Ji, Yangfeng and Mitchell, Margaret and Nie, Jian-Yun and Gao, Jianfeng and Dolan, William B}, booktitle = {Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies}, pages = {196--205}, year = {2015}}                                                        "
    }, {
    "id": 128,
    "url": "https://wanted2.github.io/bibliography/baltruvsaitis2018multimodal/",
    "title": "Multimodal machine learning: A survey and taxonomy",
    "body": "  Baltrušaitis, T. , Ahuja, C. and Morency, L. -P. 2018. Multimodal machine learning: A survey and taxonomy. IEEE transactions on pattern analysis and machine intelligence. 41, 2 (2018), 423–443.                                                                                             @article{baltruvsaitis2018multimodal, title = {Multimodal machine learning: A survey and taxonomy}, author = {Baltru{\v{s}}aitis, Tadas and Ahuja, Chaitanya and Morency, Louis-Philippe}, journal = {IEEE transactions on pattern analysis and machine intelligence}, volume = {41}, number = {2}, pages = {423--443}, year = {2018}, publisher = {IEEE}}                                                        "
    }, {
    "id": 129,
    "url": "https://wanted2.github.io/bibliography/jean2015using/",
    "title": "On Using Very Large Target Vocabulary for Neural Machine Translation",
    "body": "  Jean, S. , Cho, K. , Memisevic, R. and Bengio, Y. 2015. On Using Very Large Target Vocabulary for Neural Machine Translation. Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers) (2015), 1–10.                                                                                             @inproceedings{jean2015using, title = {On Using Very Large Target Vocabulary for Neural Machine Translation}, author = {Jean, S{\'e}bastien and Cho, Kyunghyun and Memisevic, Roland and Bengio, Yoshua}, booktitle = {Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)}, pages = {1--10}, year = {2015}}                                                        "
    }, {
    "id": 130,
    "url": "https://wanted2.github.io/bibliography/vinyals2015grammar/",
    "title": "Grammar as a foreign language",
    "body": "  Vinyals, O. , Kaiser, Ł. , Koo, T. , Petrov, S. , Sutskever, I. and Hinton, G. 2015. Grammar as a foreign language. Advances in neural information processing systems. 28, (2015), 2773–2781.                                                                                             @article{vinyals2015grammar, title = {Grammar as a foreign language}, author = {Vinyals, Oriol and Kaiser, {\L}ukasz and Koo, Terry and Petrov, Slav and Sutskever, Ilya and Hinton, Geoffrey}, journal = {Advances in neural information processing systems}, volume = {28}, pages = {2773--2781}, year = {2015}}                                                        "
    }, {
    "id": 131,
    "url": "https://wanted2.github.io/bibliography/gal2017phdthesis/",
    "title": "Uncertainty in Deep Learning",
    "body": "  Gal, Y. 2017. Uncertainty in Deep Learning. University of Cambridge.                                                                                             @phdthesis{gal2017phdthesis, author = {Gal, Yarin}, title = {Uncertainty in Deep Learning}, school = {University of Cambridge}, year = {2017}}                                                        "
    }, {
    "id": 132,
    "url": "https://wanted2.github.io/bibliography/shang2015neural/",
    "title": "Neural Responding Machine for Short-Text Conversation",
    "body": "  Shang, L. , Lu, Z. and Li, H. 2015. Neural Responding Machine for Short-Text Conversation. Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers) (2015), 1577–1586.                                                                                             @inproceedings{shang2015neural, title = {Neural Responding Machine for Short-Text Conversation}, author = {Shang, Lifeng and Lu, Zhengdong and Li, Hang}, booktitle = {Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)}, pages = {1577--1586}, year = {2015}}                                                        "
    }, {
    "id": 133,
    "url": "https://wanted2.github.io/bibliography/mao2014deep/",
    "title": "Deep captioning with multimodal recurrent neural networks (m-rnn)",
    "body": "  Mao, J. , Xu, W. , Yang, Y. , Wang, J. , Huang, Z. and Yuille, A. 2014. Deep captioning with multimodal recurrent neural networks (m-rnn). arXiv preprint arXiv:1412. 6632. (2014).                                                                                             @article{mao2014deep, title = {Deep captioning with multimodal recurrent neural networks (m-rnn)}, author = {Mao, Junhua and Xu, Wei and Yang, Yi and Wang, Jiang and Huang, Zhiheng and Yuille, Alan}, journal = {arXiv preprint arXiv:1412. 6632}, year = {2014}}                                                        "
    }, {
    "id": 134,
    "url": "https://wanted2.github.io/bibliography/kiros2014unifying/",
    "title": "Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models",
    "body": "  Kiros, R. , Salakhutdinov, R. and Zemel, R. S. 2014. Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models. arXiv preprint arXiv:1411. 2539. (2014).                                                                                             @article{kiros2014unifying, title = {Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models}, author = {Kiros, Ryan and Salakhutdinov, Ruslan and Zemel, Richard S}, journal = {arXiv preprint arXiv:1411. 2539}, year = {2014}}                                                        "
    }, {
    "id": 135,
    "url": "https://wanted2.github.io/bibliography/zhu2015aligning/",
    "title": "Aligning books and movies: Towards story-like visual explanations by watching movies and reading books",
    "body": "  Zhu, Y. , Kiros, R. , Zemel, R. , Salakhutdinov, R. , Urtasun, R. , Torralba, A. and Fidler, S. 2015. Aligning books and movies: Towards story-like visual explanations by watching movies and reading books. Proceedings of the IEEE international conference on computer vision (2015), 19–27.                                                                                             @inproceedings{zhu2015aligning, title = {Aligning books and movies: Towards story-like visual explanations by watching movies and reading books}, author = {Zhu, Yukun and Kiros, Ryan and Zemel, Rich and Salakhutdinov, Ruslan and Urtasun, Raquel and Torralba, Antonio and Fidler, Sanja}, booktitle = {Proceedings of the IEEE international conference on computer vision}, pages = {19--27}, year = {2015}}                                                        "
    }, {
    "id": 136,
    "url": "https://wanted2.github.io/bibliography/johnson2017google/",
    "title": "Google’s multilingual neural machine translation system: Enabling zero-shot translation",
    "body": "  Johnson, M. , Schuster, M. , Le, Q. V. , Krikun, M. , Wu, Y. , Chen, Z. , Thorat, N. , Viégas, F. , Wattenberg, M. , Corrado, G. and others 2017. Google’s multilingual neural machine translation system: Enabling zero-shot translation. Transactions of the Association for Computational Linguistics. 5, (2017), 339–351.                                                                                             @article{johnson2017google, title = {Google’s multilingual neural machine translation system: Enabling zero-shot translation}, author = {Johnson, Melvin and Schuster, Mike and Le, Quoc V and Krikun, Maxim and Wu, Yonghui and Chen, Zhifeng and Thorat, Nikhil and Vi{\'e}gas, Fernanda and Wattenberg, Martin and Corrado, Greg and others}, journal = {Transactions of the Association for Computational Linguistics}, volume = {5}, pages = {339--351}, year = {2017}, publisher = {MIT Press}}                                                        "
    }, {
    "id": 137,
    "url": "https://wanted2.github.io/bibliography/gal2016theoretically/",
    "title": "A theoretically grounded application of dropout in recurrent neural networks",
    "body": "  Gal, Y. and Ghahramani, Z. 2016. A theoretically grounded application of dropout in recurrent neural networks. Advances in neural information processing systems. 29, (2016), 1019–1027.                                                                                             @article{gal2016theoretically, title = {A theoretically grounded application of dropout in recurrent neural networks}, author = {Gal, Yarin and Ghahramani, Zoubin}, journal = {Advances in neural information processing systems}, volume = {29}, pages = {1019--1027}, year = {2016}}                                                        "
    }, {
    "id": 138,
    "url": "https://wanted2.github.io/bibliography/van2016pixel/",
    "title": "Pixel recurrent neural networks",
    "body": "  Van Oord, A. , Kalchbrenner, N. and Kavukcuoglu, K. 2016. Pixel recurrent neural networks. International Conference on Machine Learning (2016), 1747–1756.                                                                                             @inproceedings{van2016pixel, title = {Pixel recurrent neural networks}, author = {Van Oord, Aaron and Kalchbrenner, Nal and Kavukcuoglu, Koray}, booktitle = {International Conference on Machine Learning}, pages = {1747--1756}, year = {2016}, organization = {PMLR}}                                                        "
    }, {
    "id": 139,
    "url": "https://wanted2.github.io/bibliography/vinyals2015neural/",
    "title": "A neural conversational model",
    "body": "  Vinyals, O. and Le, Q. 2015. A neural conversational model. arXiv preprint arXiv:1506. 05869. (2015).                                                                                             @article{vinyals2015neural, title = {A neural conversational model}, author = {Vinyals, Oriol and Le, Quoc}, journal = {arXiv preprint arXiv:1506. 05869}, year = {2015}}                                                        "
    }, {
    "id": 140,
    "url": "https://wanted2.github.io/bibliography/koehn2009statistical/",
    "title": "Neural Machine Translation",
    "body": "  Koehn, P. 2009. Neural Machine Translation. Statistical Machine Translation. Cambridge University Press.                                                                                             @inbook{koehn2009statistical, author = {Koehn, Philipp}, title = {Neural Machine Translation}, booktitle = {Statistical Machine Translation}, chapter = {Neural Machine Translation}, year = {2009}, publisher = {Cambridge University Press}}                                                        "
    }, {
    "id": 141,
    "url": "https://wanted2.github.io/bibliography/zaremba2014recurrent/",
    "title": "Recurrent neural network regularization",
    "body": "  Zaremba, W. , Sutskever, I. and Vinyals, O. 2014. Recurrent neural network regularization. arXiv preprint arXiv:1409. 2329. (2014).                                                                                             @article{zaremba2014recurrent, title = {Recurrent neural network regularization}, author = {Zaremba, Wojciech and Sutskever, Ilya and Vinyals, Oriol}, journal = {arXiv preprint arXiv:1409. 2329}, year = {2014}}                                                        "
    }, {
    "id": 142,
    "url": "https://wanted2.github.io/bibliography/rush2015neural/",
    "title": "A Neural Attention Model for Abstractive Sentence Summarization",
    "body": "  Rush, A. M. , Chopra, S. and Weston, J. 2015. A Neural Attention Model for Abstractive Sentence Summarization. Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (2015), 379–389.                                                                                             @inproceedings{rush2015neural, title = {A Neural Attention Model for Abstractive Sentence Summarization}, author = {Rush, Alexander M and Chopra, Sumit and Weston, Jason}, booktitle = {Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing}, pages = {379--389}, year = {2015}}                                                        "
    }, {
    "id": 143,
    "url": "https://wanted2.github.io/bibliography/kiros2015skip/",
    "title": "Skip-thought vectors",
    "body": "  Kiros, R. , Zhu, Y. , Salakhutdinov, R. R. , Zemel, R. , Urtasun, R. , Torralba, A. and Fidler, S. 2015. Skip-thought vectors. Advances in neural information processing systems (2015), 3294–3302.                                                                                             @inproceedings{kiros2015skip, title = {Skip-thought vectors}, author = {Kiros, Ryan and Zhu, Yukun and Salakhutdinov, Russ R and Zemel, Richard and Urtasun, Raquel and Torralba, Antonio and Fidler, Sanja}, booktitle = {Advances in neural information processing systems}, pages = {3294--3302}, year = {2015}}                                                        "
    }, {
    "id": 144,
    "url": "https://wanted2.github.io/bibliography/kalchbrennerconvolutional/",
    "title": "A Convolutional Neural Network for Modelling Sentences",
    "body": "  Kalchbrenner, N. , Grefenstette, E. and Blunsom, P. 2014. A Convolutional Neural Network for Modelling Sentences. Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (2014), 212–217.                                                                                             @inproceedings{kalchbrennerconvolutional, author = {Kalchbrenner, Nal and Grefenstette, Edward and Blunsom, Phil}, title = {A Convolutional Neural Network for Modelling Sentences}, booktitle = {Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics}, pages = {212--217}, organization = {Association for Computational Linguistics}, year = {2014}}                                                        "
    }, {
    "id": 145,
    "url": "https://wanted2.github.io/bibliography/cho2014properties/",
    "title": "On the properties of neural machine translation: Encoder-decoder approaches",
    "body": "  Cho, K. , Merrienboer, B. van, Bahdanau, D. and Bengio, Y. 2014. On the properties of neural machine translation: Encoder-decoder approaches. Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation (SSST-8), 2014 (2014).                                                                                             @inproceedings{cho2014properties, title = {On the properties of neural machine translation: Encoder-decoder approaches}, author = {Cho, Kyunghyun and van Merrienboer, B and Bahdanau, Dzmitry and Bengio, Yoshua}, booktitle = {Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation (SSST-8), 2014}, year = {2014}}                                                        "
    }, {
    "id": 146,
    "url": "https://wanted2.github.io/bibliography/sennrich2016neural/",
    "title": "Neural Machine Translation of Rare Words with Subword Units",
    "body": "  Sennrich, R. , Haddow, B. and Birch, A. 2016. Neural Machine Translation of Rare Words with Subword Units. Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) (2016), 1715–1725.                                                                                             @inproceedings{sennrich2016neural, title = {Neural Machine Translation of Rare Words with Subword Units}, author = {Sennrich, Rico and Haddow, Barry and Birch, Alexandra}, booktitle = {Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, pages = {1715--1725}, year = {2016}}                                                        "
    }, {
    "id": 147,
    "url": "https://wanted2.github.io/bibliography/luong2015multi/",
    "title": "Multi-task sequence to sequence learning",
    "body": "  Luong, M. -T. , Le, Q. V. , Sutskever, I. , Vinyals, O. and Kaiser, L. 2015. Multi-task sequence to sequence learning. arXiv preprint arXiv:1511. 06114. (2015).                                                                                             @article{luong2015multi, title = {Multi-task sequence to sequence learning}, author = {Luong, Minh-Thang and Le, Quoc V and Sutskever, Ilya and Vinyals, Oriol and Kaiser, Lukasz}, journal = {arXiv preprint arXiv:1511. 06114}, year = {2015}}                                                        "
    }, {
    "id": 148,
    "url": "https://wanted2.github.io/bibliography/wu2016google/",
    "title": "Google’s neural machine translation system: Bridging the gap between human and machine translation",
    "body": "  Wu, Y. , Schuster, M. , Chen, Z. , Le, Q. V. , Norouzi, M. , Macherey, W. , Krikun, M. , Cao, Y. , Gao, Q. , Macherey, K. and others 2016. Google’s neural machine translation system: Bridging the gap between human and machine translation. arXiv preprint arXiv:1609. 08144. (2016).                                                                                             @article{wu2016google, title = {Google's neural machine translation system: Bridging the gap between human and machine translation}, author = {Wu, Yonghui and Schuster, Mike and Chen, Zhifeng and Le, Quoc V and Norouzi, Mohammad and Macherey, Wolfgang and Krikun, Maxim and Cao, Yuan and Gao, Qin and Macherey, Klaus and others}, journal = {arXiv preprint arXiv:1609. 08144}, year = {2016}}                                                        "
    }, {
    "id": 149,
    "url": "https://wanted2.github.io/bibliography/luong2015effective/",
    "title": "Effective approaches to attention-based neural machine translation",
    "body": "  Luong, M. -T. , Pham, H. and Manning, C. D. 2015. Effective approaches to attention-based neural machine translation. arXiv preprint arXiv:1508. 04025. (2015).                                                                                             @article{luong2015effective, title = {Effective approaches to attention-based neural machine translation}, author = {Luong, Minh-Thang and Pham, Hieu and Manning, Christopher D}, journal = {arXiv preprint arXiv:1508. 04025}, year = {2015}}                                                        "
    }, {
    "id": 150,
    "url": "https://wanted2.github.io/bibliography/xu2015show/",
    "title": "Show, attend and tell: Neural image caption generation with visual attention",
    "body": "  Xu, K. , Ba, J. , Kiros, R. , Cho, K. , Courville, A. , Salakhudinov, R. , Zemel, R. and Bengio, Y. 2015. Show, attend and tell: Neural image caption generation with visual attention. International conference on machine learning (2015), 2048–2057.                                                                                             @inproceedings{xu2015show, title = {Show, attend and tell: Neural image caption generation with visual attention}, author = {Xu, Kelvin and Ba, Jimmy and Kiros, Ryan and Cho, Kyunghyun and Courville, Aaron and Salakhudinov, Ruslan and Zemel, Rich and Bengio, Yoshua}, booktitle = {International conference on machine learning}, pages = {2048--2057}, year = {2015}, organization = {PMLR}}                                                        "
    }, {
    "id": 151,
    "url": "https://wanted2.github.io/bibliography/cho2014learning/",
    "title": "Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation",
    "body": "  Cho, K. , Merrienboer, B. van, Gulcehre, C. , Bougares, F. , Schwenk, H. and Bengio, Y. 2014. Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation. arXiv preprint arXiv:1406. 1078. (2014).                                                                                             @article{cho2014learning, title = {Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation}, author = {Cho, Kyunghyun and van Merrienboer, Bart and Gulcehre, Caglar and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua}, journal = {arXiv preprint arXiv:1406. 1078}, year = {2014}}                                                        "
    }, {
    "id": 152,
    "url": "https://wanted2.github.io/bibliography/goodfellow2016deep/",
    "title": "Deep learning",
    "body": "  Goodfellow, I. , Bengio, Y. and Courville, A. 2016. Deep learning. MIT press.                                                                                             @book{goodfellow2016deep, title = {Deep learning}, author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron}, year = {2016}, publisher = {MIT press}}                                                        "
    }, {
    "id": 153,
    "url": "https://wanted2.github.io/bibliography/werbos1990backpropagation/",
    "title": "Backpropagation through time: what it does and how to do it",
    "body": "  Werbos, P. J. 1990. Backpropagation through time: what it does and how to do it. Proceedings of the IEEE. 78, 10 (1990), 1550–1560.                                                                                             @article{werbos1990backpropagation, title = {Backpropagation through time: what it does and how to do it}, author = {Werbos, Paul J}, journal = {Proceedings of the IEEE}, volume = {78}, number = {10}, pages = {1550--1560}, year = {1990}, publisher = {IEEE}}                                                        "
    }, {
    "id": 154,
    "url": "https://wanted2.github.io/bibliography/bahdanau2015neural/",
    "title": "Neural machine translation by jointly learning to align and translate",
    "body": "  Bahdanau, D. , Cho, K. H. and Bengio, Y. 2015. Neural machine translation by jointly learning to align and translate. 3rd International Conference on Learning Representations, ICLR 2015 (2015).                                                                                             @inproceedings{bahdanau2015neural, title = {Neural machine translation by jointly learning to align and translate}, author = {Bahdanau, Dzmitry and Cho, Kyung Hyun and Bengio, Yoshua}, booktitle = {3rd International Conference on Learning Representations, ICLR 2015}, year = {2015}}                                                        "
    }, {
    "id": 155,
    "url": "https://wanted2.github.io/bibliography/sutskever2014sequence/",
    "title": "Sequence to sequence learning with neural networks",
    "body": "  Sutskever, I. , Vinyals, O. and Le, Q. V. V. 2014. Sequence to sequence learning with neural networks. Advances in Neural Information Processing Systems (2014), 3104–3112.                                                                                             @inproceedings{sutskever2014sequence, title = {Sequence to sequence learning with neural networks}, author = {Sutskever, Ilya and Vinyals, Oriol and Le, Quoc VV}, booktitle = {Advances in Neural Information Processing Systems}, pages = {3104--3112}, year = {2014}}                                                        "
    }, {
    "id": 156,
    "url": "https://wanted2.github.io/bibliography/kalchbrenner2013recurrent/",
    "title": "Recurrent continuous translation models",
    "body": "  Kalchbrenner, N. and Blunsom, P. 2013. Recurrent continuous translation models. Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing (EMNLP), Seattle, USA. Association for Computational Linguistics (2013).                                                                                             @inproceedings{kalchbrenner2013recurrent, title = {Recurrent continuous translation models}, author = {Kalchbrenner, Nal and Blunsom, Phil}, booktitle = {Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing (EMNLP), Seattle, USA. Association for Computational Linguistics}, year = {2013}}                                                        "
    }, {
    "id": 157,
    "url": "https://wanted2.github.io/bibliography/hsu2004entrepreneurs/",
    "title": "What do entrepreneurs pay for venture capital affiliation?",
    "body": "  Hsu, D. H. 2004. What do entrepreneurs pay for venture capital affiliation? The journal of finance. 59, 4 (2004), 1805–1844.                                                                                             @article{hsu2004entrepreneurs, title = {What do entrepreneurs pay for venture capital affiliation?}, author = {Hsu, David H}, journal = {The journal of finance}, volume = {59}, number = {4}, pages = {1805--1844}, year = {2004}, publisher = {Wiley Online Library}}                                                        "
    }, {
    "id": 158,
    "url": "https://wanted2.github.io/bibliography/mollick2014dynamics/",
    "title": "The dynamics of crowdfunding: An exploratory study",
    "body": "  Mollick, E. 2014. The dynamics of crowdfunding: An exploratory study. Journal of business venturing. 29, 1 (2014), 1–16.                                                                                             @article{mollick2014dynamics, title = {The dynamics of crowdfunding: An exploratory study}, author = {Mollick, Ethan}, journal = {Journal of business venturing}, volume = {29}, number = {1}, pages = {1--16}, year = {2014}, publisher = {Elsevier}}                                                        "
    }, {
    "id": 159,
    "url": "https://wanted2.github.io/bibliography/bruneel2010investigating/",
    "title": "Investigating the factors that diminish the barriers to university–industry collaboration",
    "body": "  Bruneel, J. , d’Este, P. and Salter, A. 2010. Investigating the factors that diminish the barriers to university–industry collaboration. Research policy. 39, 7 (2010), 858–868.                                                                                             @article{bruneel2010investigating, title = {Investigating the factors that diminish the barriers to university--industry collaboration}, author = {Bruneel, Johan and d’Este, Pablo and Salter, Ammon}, journal = {Research policy}, volume = {39}, number = {7}, pages = {858--868}, year = {2010}, publisher = {Elsevier}}                                                        "
    }, {
    "id": 160,
    "url": "https://wanted2.github.io/bibliography/stern2004scientists/",
    "title": "Do scientists pay to be scientists?",
    "body": "  Stern, S. 2004. Do scientists pay to be scientists? Management science. 50, 6 (2004), 835–853.                                                                                             @article{stern2004scientists, title = {Do scientists pay to be scientists?}, author = {Stern, Scott}, journal = {Management science}, volume = {50}, number = {6}, pages = {835--853}, year = {2004}, publisher = {INFORMS}}                                                        "
    }, {
    "id": 161,
    "url": "https://wanted2.github.io/bibliography/currall2005pay/",
    "title": "Pay satisfaction and organizational outcomes",
    "body": "  Currall, S. C. , Towler, A. J. , Judge, T. A. and Kohn, L. 2005. Pay satisfaction and organizational outcomes. Personnel psychology. 58, 3 (2005), 613–640.                                                                                             @article{currall2005pay, title = {Pay satisfaction and organizational outcomes}, author = {Currall, Steven C and Towler, Annette J and Judge, Timothy A and Kohn, Laura}, journal = {Personnel psychology}, volume = {58}, number = {3}, pages = {613--640}, year = {2005}, publisher = {Wiley Online Library}}                                                        "
    }, {
    "id": 162,
    "url": "https://wanted2.github.io/bibliography/aastebro2013does/",
    "title": "Does academic entrepreneurship pay?",
    "body": "  Åstebro, T. , Braunerhjelm, P. and Broström, A. 2013. Does academic entrepreneurship pay? Industrial and Corporate Change. 22, 1 (2013), 281–311.                                                                                             @article{aastebro2013does, title = {Does academic entrepreneurship pay?}, author = {{\AA}stebro, Thomas and Braunerhjelm, Pontus and Brostr{\ o}m, Anders}, journal = {Industrial and Corporate Change}, volume = {22}, number = {1}, pages = {281--311}, year = {2013}, publisher = {Oxford University Press}}                                                        "
    }, {
    "id": 163,
    "url": "https://wanted2.github.io/bibliography/dorner2017wages/",
    "title": "Wages in high-tech start-ups–Do academic spin-offs pay a wage premium?",
    "body": "  Dorner, M. , Fryges, H. and Schopen, K. 2017. Wages in high-tech start-ups–Do academic spin-offs pay a wage premium? Research Policy. 46, 1 (2017), 1–18.                                                                                             @article{dorner2017wages, title = {Wages in high-tech start-ups--Do academic spin-offs pay a wage premium?}, author = {Dorner, Matthias and Fryges, Helmut and Schopen, Kathrin}, journal = {Research Policy}, volume = {46}, number = {1}, pages = {1--18}, year = {2017}, publisher = {Elsevier}}                                                        "
    }, {
    "id": 164,
    "url": "https://wanted2.github.io/bibliography/kim2018there/",
    "title": "Is there a startup wage premium? Evidence from MIT graduates",
    "body": "  Kim, J. D. 2018. Is there a startup wage premium? Evidence from MIT graduates. Research Policy. 47, 3 (2018), 637–649.                                                                                             @article{kim2018there, title = {Is there a startup wage premium? Evidence from MIT graduates}, author = {Kim, J Daniel}, journal = {Research Policy}, volume = {47}, number = {3}, pages = {637--649}, year = {2018}, publisher = {Elsevier}}                                                        "
    }, {
    "id": 165,
    "url": "https://wanted2.github.io/bibliography/homfeldt2019suppliers/",
    "title": "Suppliers versus start-ups: Where do better innovation ideas come from?",
    "body": "  Homfeldt, F. , Rese, A. and Simon, F. 2019. Suppliers versus start-ups: Where do better innovation ideas come from? Research policy. 48, 7 (2019), 1738–1757.                                                                                             @article{homfeldt2019suppliers, title = {Suppliers versus start-ups: Where do better innovation ideas come from?}, author = {Homfeldt, Felix and Rese, Alexandra and Simon, Franz}, journal = {Research policy}, volume = {48}, number = {7}, pages = {1738--1757}, year = {2019}, publisher = {Elsevier}}                                                        "
    }, {
    "id": 166,
    "url": "https://wanted2.github.io/bibliography/block2018quantity/",
    "title": "Quantity and quality of jobs by entrepreneurial firms",
    "body": "  Block, J. H. , Fisch, C. O. and Van Praag, M. 2018. Quantity and quality of jobs by entrepreneurial firms. Oxford Review of Economic Policy. 34, 4 (2018), 565–583.                                                                                             @article{block2018quantity, title = {Quantity and quality of jobs by entrepreneurial firms}, author = {Block, Joern H and Fisch, Christian O and Van Praag, Mirjam}, journal = {Oxford Review of Economic Policy}, volume = {34}, number = {4}, pages = {565--583}, year = {2018}, publisher = {Oxford University Press UK}}                                                        "
    }, {
    "id": 167,
    "url": "https://wanted2.github.io/bibliography/rodriguez2018role/",
    "title": "The role of knowledge spillovers on the university spin-offs innovation",
    "body": "  Rodrı́guez-Gulı́as Marı́a Jesús, Fernández-López, S. , Rodeiro-Pazos, D. , Corsi, C. and Prencipe, A. 2018. The role of knowledge spillovers on the university spin-offs innovation. Science and Public Policy. 45, 6 (2018), 875–883.                                                                                             @article{rodriguez2018role, title = {The role of knowledge spillovers on the university spin-offs innovation}, author = {Rodr{\'\i}guez-Gul{\'\i}as, Mar{\'\i}a Jes{\'u}s and Fern{\'a}ndez-L{\'o}pez, Sara and Rodeiro-Pazos, David and Corsi, Christian and Prencipe, Antonio}, journal = {Science and Public Policy}, volume = {45}, number = {6}, pages = {875--883}, year = {2018}, publisher = {Oxford University Press}}                                                        "
    }, {
    "id": 168,
    "url": "https://wanted2.github.io/bibliography/dianez2021drivers/",
    "title": "Drivers and implications of entrepreneurial orientation for academic spin-offs",
    "body": "  Diánez-González, J. P. , Camelo-Ordaz, C. and Fernández-Alles, M. 2021. Drivers and implications of entrepreneurial orientation for academic spin-offs. International Entrepreneurship and Management Journal. 17, 2 (2021), 1007–1035.                                                                                             @article{dianez2021drivers, title = {Drivers and implications of entrepreneurial orientation for academic spin-offs}, author = {Di{\'a}nez-Gonz{\'a}lez, Juan Pablo and Camelo-Ordaz, Carmen and Fern{\'a}ndez-Alles, Mariluz}, journal = {International Entrepreneurship and Management Journal}, volume = {17}, number = {2}, pages = {1007--1035}, year = {2021}, publisher = {Springer}}                                                        "
    }, {
    "id": 169,
    "url": "https://wanted2.github.io/bibliography/nystrom2021working/",
    "title": "Working for an entrepreneur: heaven or hell?",
    "body": "  Nyström, K. 2021. Working for an entrepreneur: heaven or hell? Small Business Economics. 56, 2 (2021), 919–931.                                                                                             @article{nystrom2021working, title = {Working for an entrepreneur: heaven or hell?}, author = {Nystr{\ o}m, Kristina}, journal = {Small Business Economics}, volume = {56}, number = {2}, pages = {919--931}, year = {2021}, publisher = {Springer}}                                                        "
    }, {
    "id": 170,
    "url": "https://wanted2.github.io/bibliography/andersson2009reaching/",
    "title": "Reaching for the stars: who pays for talent in innovative industries?",
    "body": "  Andersson, F. , Freedman, M. , Haltiwanger, J. , Lane, J. and Shaw, K. 2009. Reaching for the stars: who pays for talent in innovative industries? The Economic Journal. 119, 538 (2009), F308–F332.                                                                                             @article{andersson2009reaching, title = {Reaching for the stars: who pays for talent in innovative industries?}, author = {Andersson, Fredrik and Freedman, Matthew and Haltiwanger, John and Lane, Julia and Shaw, Kathryn}, journal = {The Economic Journal}, volume = {119}, number = {538}, pages = {F308--F332}, year = {2009}, publisher = {Oxford University Press Oxford, UK}}                                                        "
    }, {
    "id": 171,
    "url": "https://wanted2.github.io/bibliography/ilyas2018plastic/",
    "title": "Plastic waste as a significant threat to environment–a systematic literature review",
    "body": "  Ilyas, M. , Ahmad, W. , Khan, H. , Yousaf, S. , Khan, K. and Nazir, S. 2018. Plastic waste as a significant threat to environment–a systematic literature review. Reviews on environmental health. 33, 4 (2018), 383–406.                                                                                             @article{ilyas2018plastic, title = {Plastic waste as a significant threat to environment--a systematic literature review}, author = {Ilyas, Muhammad and Ahmad, Waqas and Khan, Hizbullah and Yousaf, Saeeda and Khan, Kifayatullah and Nazir, Shah}, journal = {Reviews on environmental health}, volume = {33}, number = {4}, pages = {383--406}, year = {2018}, publisher = {De Gruyter}}                                                        "
    }, {
    "id": 172,
    "url": "https://wanted2.github.io/bibliography/meredith2017projecu/",
    "title": "Project management: a strategic managerial approach",
    "body": "  Meredith, J. R. , Shafer, S. M. and Mantel Jr, S. J. 2017. Project management: a strategic managerial approach. John Wiley &amp; Sons.                                                                                             @book{meredith2017projecu, title = {Project management: a strategic managerial approach}, author = {Meredith, Jack R and Shafer, Scott M and Mantel Jr, Samuel J}, year = {2017}, publisher = {John Wiley \&amp; Sons}}                                                        "
    }, {
    "id": 173,
    "url": "https://wanted2.github.io/bibliography/meredith2017projecv/",
    "title": "Project management: a strategic managerial approach",
    "body": "  Meredith, J. R. , Shafer, S. M. and Mantel Jr, S. J. 2017. Project management: a strategic managerial approach. John Wiley &amp; Sons.                                                                                             @book{meredith2017projecv, title = {Project management: a strategic managerial approach}, author = {Meredith, Jack R and Shafer, Scott M and Mantel Jr, Samuel J}, year = {2017}, publisher = {John Wiley \&amp; Sons}}                                                        "
    }, {
    "id": 174,
    "url": "https://wanted2.github.io/bibliography/OracleCr38_online/",
    "title": "Oracle Crystal Ball Downloads",
    "body": "  Oracle Crystal Ball Downloads. https://www. oracle. com/middleware/technologies/crystalball/downloads. html.   (Accessed on 06/07/2021)                                                                                            @misc{OracleCr38:online, author = {}, title = {Oracle Crystal Ball Downloads}, howpublished = {https://www. oracle. com/middleware/technologies/crystalball/downloads. html}, month = {}, year = {}, note = {(Accessed on 06/07/2021)}}                                                        "
    }, {
    "id": 175,
    "url": "https://wanted2.github.io/bibliography/fisher1983getting/",
    "title": "Getting to Yes: Negotiating Agreement Without Giving In",
    "body": "  Fisher, R. and Ury, W. 1983. Getting to Yes: Negotiating Agreement Without Giving In. New York: Penguin Books.                                                                                             @misc{fisher1983getting, title = {Getting to Yes: Negotiating Agreement Without Giving In}, author = {Fisher, Roger and Ury, William}, year = {1983}, publisher = {New York: Penguin Books}}                                                        "
    }, {
    "id": 176,
    "url": "https://wanted2.github.io/bibliography/hamburger1986three/",
    "title": "Three perceptions of project cost",
    "body": "  Hamburger, D. H. 1986. Three perceptions of project cost. Project Management journal. (1986), 372–378.                                                                                             @article{hamburger1986three, title = {Three perceptions of project cost}, author = {Hamburger, DH}, journal = {Project Management journal}, pages = {372--378}, year = {1986}}                                                        "
    }, {
    "id": 177,
    "url": "https://wanted2.github.io/bibliography/GanttPro32_online/",
    "title": "GanttProject - Free Project Management Application",
    "body": "  GanttProject - Free Project Management Application. https://www. ganttproject. biz/.   (Accessed on 06/13/2021)                                                                                            @misc{GanttPro32:online, author = {}, title = {GanttProject - Free Project Management Application}, howpublished = {https://www. ganttproject. biz/}, month = {}, year = {}, note = {(Accessed on 06/13/2021)}}                                                        "
    }, {
    "id": 178,
    "url": "https://wanted2.github.io/bibliography/ProjectM44_online/",
    "title": "Project Management Software | Microsoft Project",
    "body": "  Project Management Software | Microsoft Project. https://www. microsoft. com/en-us/microsoft-365/project/project-management-software.   (Accessed on 06/13/2021)                                                                                            @misc{ProjectM44:online, author = {}, title = {Project Management Software | Microsoft Project}, howpublished = {https://www. microsoft. com/en-us/microsoft-365/project/project-management-software}, month = {}, year = {}, note = {(Accessed on 06/13/2021)}}                                                        "
    }, {
    "id": 179,
    "url": "https://wanted2.github.io/bibliography/PEP578Py66_online/",
    "title": "PEP 578 – Python Runtime Audit Hooks | Python.org",
    "body": "  PEP 578 – Python Runtime Audit Hooks | Python. org. https://www. python. org/dev/peps/pep-0578.   (Accessed on 07/17/2021)                                                                                            @misc{PEP578Py66:online, author = {}, title = {PEP 578 -- Python Runtime Audit Hooks | Python. org}, howpublished = {https://www. python. org/dev/peps/pep-0578}, month = {}, year = {}, note = {(Accessed on 07/17/2021)}}                                                        "
    }, {
    "id": 180,
    "url": "https://wanted2.github.io/bibliography/PEP551Se63_online/",
    "title": "PEP 551 - Security transparency in the Python runtime - Python.org",
    "body": "  PEP 551 - Security transparency in the Python runtime - Python. org. https://www. python. org/dev/peps/pep-0551/.   (Accessed on 07/17/2021)                                                                                            @misc{PEP551Se63:online, author = {}, title = {PEP 551 - Security transparency in the Python runtime - Python. org}, howpublished = {https://www. python. org/dev/peps/pep-0551/}, month = {}, year = {}, note = {(Accessed on 07/17/2021)}}                                                        "
    }, {
    "id": 181,
    "url": "https://wanted2.github.io/bibliography/sysSyst75_online/",
    "title": "sys - System-specific parameters and functions - Python 3.9.6 documentation",
    "body": "  sys - System-specific parameters and functions - Python 3. 9. 6 documentation. https://docs. python. org/3/library/sys. html.   (Accessed on 07/17/2021)                                                                                            @misc{sysSyst75:online, author = {}, title = {sys - System-specific parameters and functions - Python 3. 9. 6 documentation}, howpublished = {https://docs. python. org/3/library/sys. html}, month = {}, year = {}, note = {(Accessed on 07/17/2021)}}                                                        "
    }, {
    "id": 182,
    "url": "https://wanted2.github.io/bibliography/sysaudit76_online/",
    "title": "sysaudit – sysaudit documentation",
    "body": "  sysaudit – sysaudit documentation. https://sysaudit. readthedocs. io/en/latest/.   (Accessed on 07/17/2021)                                                                                            @misc{sysaudit76:online, author = {}, title = {sysaudit -- sysaudit documentation}, howpublished = {https://sysaudit. readthedocs. io/en/latest/}, month = {}, year = {}, note = {(Accessed on 07/17/2021)}}                                                        "
    }, {
    "id": 183,
    "url": "https://wanted2.github.io/bibliography/Auditeve66_online/",
    "title": "Audit events table - Python 3.9.6 documentation",
    "body": "  Audit events table - Python 3. 9. 6 documentation. https://docs. python. org/3/library/audit_events. html.   (Accessed on 07/17/2021)                                                                                            @misc{Auditeve66:online, author = {}, title = {Audit events table - Python 3. 9. 6 documentation}, howpublished = {https://docs. python. org/3/library/audit_events. html}, month = {}, year = {}, note = {(Accessed on 07/17/2021)}}                                                        "
    }, {
    "id": 184,
    "url": "https://wanted2.github.io/bibliography/Bypassin44_online/",
    "title": "Bypassing Python3.8 Audit Hooks [Part 1] · daddycocoaman",
    "body": "  Bypassing Python3. 8 Audit Hooks [Part 1] · daddycocoaman. https://daddycocoaman. dev/posts/bypassing-python38-audit-hooks-part-1/.   (Accessed on 07/17/2021)                                                                                            @misc{Bypassin44:online, author = {}, title = {Bypassing Python3. 8 Audit Hooks [Part 1] · daddycocoaman}, howpublished = {https://daddycocoaman. dev/posts/bypassing-python38-audit-hooks-part-1/}, month = {}, year = {}, note = {(Accessed on 07/17/2021)}}                                                        "
    }, {
    "id": 185,
    "url": "https://wanted2.github.io/bibliography/soumushou46online/",
    "title": "総務省｜報道資料｜「テレワークセキュリティガイドライン（第5版）」（案）に対する意見募集の結果及び当該ガイドラインの公表",
    "body": "  総務省｜報道資料｜「テレワークセキュリティガイドライン（第5版）」（案）に対する意見募集の結果及び当該ガイドラインの公表. https://www. soumu. go. jp/menu_news/s-news/01cyber01_02000001_00111. html.   (Accessed on 09/09/2021)                                                                                            @misc{soumushou46online, author = {}, title = {総務省｜報道資料｜「テレワークセキュリティガイドライン（第5版）」（案）に対する意見募集の結果及び当該ガイドラインの公表}, howpublished = {https://www. soumu. go. jp/menu_news/s-news/01cyber01_02000001_00111. html}, month = {}, year = {}, note = {(Accessed on 09/09/2021)}}                                                        "
    }, {
    "id": 186,
    "url": "https://wanted2.github.io/bibliography/avastsecurebrowser64online/",
    "title": "追跡なしのプライベート ブラウザ | アバスト セキュア ブラウザ",
    "body": "  追跡なしのプライベート ブラウザ | アバスト セキュア ブラウザ. https://www. avast. co. jp/secure-browser#pc.   (Accessed on 09/09/2021)                                                                                            @misc{avastsecurebrowser64online, author = {}, title = {追跡なしのプライベート ブラウザ | アバスト セキュア ブラウザ}, howpublished = {https://www. avast. co. jp/secure-browser#pc}, month = {}, year = {}, note = {(Accessed on 09/09/2021)}}                                                        "
    }, {
    "id": 187,
    "url": "https://wanted2.github.io/bibliography/bankmode1online/",
    "title": "アバスト セキュア ブラウザでバンク モードを開く方法 | アバスト",
    "body": "  アバスト セキュア ブラウザでバンク モードを開く方法 | アバスト. https://support. avast. com/ja-jp/article/Use-Bank-Mode/.   (Accessed on 09/09/2021)                                                                                            @misc{bankmode1online, author = {}, title = {アバスト セキュア ブラウザでバンク モードを開く方法 | アバスト}, howpublished = {https://support. avast. com/ja-jp/article/Use-Bank-Mode/}, month = {}, year = {}, note = {(Accessed on 09/09/2021)}}                                                        "
    }, {
    "id": 188,
    "url": "https://wanted2.github.io/bibliography/koehn2009statisticam/",
    "title": "Statistical machine translation",
    "body": "  Koehn, P. 2009. Statistical machine translation. Cambridge University Press.                                                                                             @book{koehn2009statisticam, title = {Statistical machine translation}, author = {Koehn, Philipp}, year = {2009}, publisher = {Cambridge University Press}}                                                        "
    }, {
    "id": 189,
    "url": "https://wanted2.github.io/bibliography/koehn2007moses/",
    "title": "Moses: Open source toolkit for statistical machine translation",
    "body": "  Koehn, P. , Hoang, H. , Birch, A. , Callison-Burch, C. , Federico, M. , Bertoldi, N. , Cowan, B. , Shen, W. , Moran, C. , Zens, R. and others 2007. Moses: Open source toolkit for statistical machine translation. Proceedings of the 45th annual meeting of the association for computational linguistics companion volume proceedings of the demo and poster sessions (2007), 177–180.                                                                                             @inproceedings{koehn2007moses, title = {Moses: Open source toolkit for statistical machine translation}, author = {Koehn, Philipp and Hoang, Hieu and Birch, Alexandra and Callison-Burch, Chris and Federico, Marcello and Bertoldi, Nicola and Cowan, Brooke and Shen, Wade and Moran, Christine and Zens, Richard and others}, booktitle = {Proceedings of the 45th annual meeting of the association for computational linguistics companion volume proceedings of the demo and poster sessions}, pages = {177--180}, year = {2007}}                                                        "
    }, {
    "id": 190,
    "url": "https://wanted2.github.io/bibliography/Artifici92_online/",
    "title": "Artificial intelligence isn’t very intelligent and won’t be any time soon",
    "body": "  Artificial intelligence isn’t very intelligent and won’t be any time soon. https://massivesci. com/articles/artificial-intelligence-deep-learning-self-driving-car/.   (Accessed on 05/29/2021)                                                                                            @misc{Artifici92:online, author = {}, title = {Artificial intelligence isn't very intelligent and won't be any time soon}, howpublished = {https://massivesci. com/articles/artificial-intelligence-deep-learning-self-driving-car/}, month = {}, year = {}, note = {(Accessed on 05/29/2021)}}                                                        "
    }, {
    "id": 191,
    "url": "https://wanted2.github.io/bibliography/Hackersu80_online/",
    "title": "Hackers used stickers to fool a Tesla, highlighting the risks of AI - Vox",
    "body": "  Hackers used stickers to fool a Tesla, highlighting the risks of AI - Vox. https://www. vox. com/future-perfect/2019/4/8/18297410/ai-tesla-self-driving-cars-adversarial-machine-learning.   (Accessed on 05/29/2021)                                                                                            @misc{Hackersu80:online, author = {}, title = {Hackers used stickers to fool a Tesla, highlighting the risks of AI - Vox}, howpublished = {https://www. vox. com/future-perfect/2019/4/8/18297410/ai-tesla-self-driving-cars-adversarial-machine-learning}, month = {}, year = {}, note = {(Accessed on 05/29/2021)}}                                                        "
    }, {
    "id": 192,
    "url": "https://wanted2.github.io/bibliography/UntoldHi12_online/",
    "title": "Untold History of AI: Why Alan Turing Wanted AI Agents to Make Mistakes - IEEE Spectrum",
    "body": "  Untold History of AI: Why Alan Turing Wanted AI Agents to Make Mistakes - IEEE Spectrum. https://spectrum. ieee. org/tech-talk/tech-history/dawn-of-electronics/untold-history-of-ai-why-alan-turing-wanted-ai-to-make-mistakes.   (Accessed on 05/29/2021)                                                                                            @misc{UntoldHi12:online, author = {}, title = {Untold History of AI: Why Alan Turing Wanted AI Agents to Make Mistakes - IEEE Spectrum}, howpublished = {https://spectrum. ieee. org/tech-talk/tech-history/dawn-of-electronics/untold-history-of-ai-why-alan-turing-wanted-ai-to-make-mistakes}, month = {}, year = {}, note = {(Accessed on 05/29/2021)}}                                                        "
    }, {
    "id": 193,
    "url": "https://wanted2.github.io/bibliography/machinery1950computing/",
    "title": "Computing machinery and intelligence",
    "body": "  Turing, A. 1950. Computing machinery and intelligence. Mind. 49, 236 (1950), 433.                                                                                             @article{machinery1950computing, title = {Computing machinery and intelligence}, author = {Turing, Alan}, journal = {Mind}, volume = {49}, number = {236}, pages = {433}, year = {1950}}                                                        "
    }, {
    "id": 194,
    "url": "https://wanted2.github.io/bibliography/Kh%C3%B4ngch%E1%BB%8946_online/",
    "title": "Không chỉ là video khiêu dâm bóng ma Deepfake đang khiến cả thế giới lo sợ vì ngày càng khó kiểm soát",
    "body": "  Không chỉ là video khiêu dâm bóng ma Deepfake đang khiến cả thế giới lo sợ vì ngày càng khó kiểm soát. https://vnexpress. net/deepfake-bong-ma-trong-the-gioi-internet-4034159. html.   (Accessed on 05/29/2021)                                                                                            @misc{Khôngchỉ46:online, author = {}, title = {Không chỉ là video khiêu dâm bóng ma Deepfake đang khiến cả thế giới lo sợ vì ngày càng khó kiểm soát}, howpublished = {https://vnexpress. net/deepfake-bong-ma-trong-the-gioi-internet-4034159. html}, month = {}, year = {}, note = {(Accessed on 05/29/2021)}}                                                        "
    }, {
    "id": 195,
    "url": "https://wanted2.github.io/bibliography/LogicEls13_online/",
    "title": "Logic / Else-if blocks • Svelte Tutorial",
    "body": "  Logic / Else-if blocks • Svelte Tutorial.   (Accessed on 12/18/2021)                                                                                            @misc{LogicEls13:online, author = {}, title = {Logic / Else-if blocks • Svelte Tutorial}, howpublished = {\url{https://svelte. dev/tutorial/else-if-blocks}}, month = {}, year = {}, note = {(Accessed on 12/18/2021)}}                                                        "
    }, {
    "id": 196,
    "url": "https://wanted2.github.io/bibliography/DocsSve0_online/",
    "title": "Docs • SvelteKit",
    "body": "  Docs • SvelteKit.   (Accessed on 12/18/2021)                                                                                            @misc{DocsSve0:online, author = {}, title = {Docs • SvelteKit}, howpublished = {\url{https://kit. svelte. dev/docs}}, month = {}, year = {}, note = {(Accessed on 12/18/2021)}}                                                        "
    }, {
    "id": 197,
    "url": "https://wanted2.github.io/bibliography/PMPCerti18_online/",
    "title": "PMP Certification Requirements | Project Management Certification & PMP Certification Eligibility",
    "body": "  PMA PMP Certification Requirements | Project Management Certification &amp; PMP Certification Eligibility.   (Accessed on 01/05/2022)                                                                                            @misc{PMPCerti18:online, author = {PMA}, title = {PMP Certification Requirements | Project Management Certification \&amp; PMP Certification Eligibility}, howpublished = {\url{https://projectmanagementacademy. net/pmp-certification-requirements}}, month = {}, year = {}, note = {(Accessed on 01/05/2022)}}                                                        "
    }, {
    "id": 198,
    "url": "https://wanted2.github.io/bibliography/jaffe1986technological/",
    "title": "Technological Opportunity and Spillovers of R&D: Evidence from Firms’ Patents, Profits, and Market Value",
    "body": "  Jaffe, A. B. 1986. Technological Opportunity and Spillovers of R&amp;D: Evidence from Firms’ Patents, Profits, and Market Value. The American Economic Review. 76, 5 (1986), 984–1001.                                                                                             @article{jaffe1986technological, title = {Technological Opportunity and Spillovers of R\&amp;D: Evidence from Firms' Patents, Profits, and Market Value}, author = {Jaffe, Adam B}, journal = {The American Economic Review}, volume = {76}, number = {5}, pages = {984--1001}, year = {1986}}                                                        "
    }, {
    "id": 199,
    "url": "https://wanted2.github.io/bibliography/jaffe1989real/",
    "title": "Real effects of academic research",
    "body": "  Jaffe, A. B. 1989. Real effects of academic research. The American economic review. (1989), 957–970.                                                                                             @article{jaffe1989real, title = {Real effects of academic research}, author = {Jaffe, Adam B}, journal = {The American economic review}, pages = {957--970}, year = {1989}, publisher = {JSTOR}}                                                        "
    }, {
    "id": 200,
    "url": "https://wanted2.github.io/bibliography/audretsch1996r/",
    "title": "R&D spillovers and the geography of innovation and production",
    "body": "  Audretsch, D. B. and Feldman, M. P. 1996. R&amp;D spillovers and the geography of innovation and production. The American economic review. 86, 3 (1996), 630–640.                                                                                             @article{audretsch1996r, title = {R\&amp;D spillovers and the geography of innovation and production}, author = {Audretsch, David B and Feldman, Maryann P}, journal = {The American economic review}, volume = {86}, number = {3}, pages = {630--640}, year = {1996}, publisher = {JSTOR}}                                                        "
    }, {
    "id": 201,
    "url": "https://wanted2.github.io/bibliography/david2000public/",
    "title": "Is public R&D a complement or substitute for private R&D? A review of the econometric evidence",
    "body": "  David, P. A. , Hall, B. H. and Toole, A. A. 2000. Is public R&amp;D a complement or substitute for private R&amp;D? A review of the econometric evidence. Research policy. 29, 4-5 (2000), 497–529.                                                                                             @article{david2000public, title = {Is public R\&amp;D a complement or substitute for private R\&amp;D? A review of the econometric evidence}, author = {David, Paul A and Hall, Bronwyn H and Toole, Andrew A}, journal = {Research policy}, volume = {29}, number = {4-5}, pages = {497--529}, year = {2000}, publisher = {Elsevier}}                                                        "
    }, {
    "id": 202,
    "url": "https://wanted2.github.io/bibliography/baptista1998firms/",
    "title": "Do firms in clusters innovate more?",
    "body": "  Baptista, R. and Swann, P. 1998. Do firms in clusters innovate more? Research policy. 27, 5 (1998), 525–540.                                                                                             @article{baptista1998firms, title = {Do firms in clusters innovate more?}, author = {Baptista, Rui and Swann, Peter}, journal = {Research policy}, volume = {27}, number = {5}, pages = {525--540}, year = {1998}, publisher = {Elsevier}}                                                        "
    }, {
    "id": 203,
    "url": "https://wanted2.github.io/bibliography/salter2001economic/",
    "title": "The economic benefits of publicly funded basic research: a critical review",
    "body": "  Salter, A. J. and Martin, B. R. 2001. The economic benefits of publicly funded basic research: a critical review. Research policy. 30, 3 (2001), 509–532.                                                                                             @article{salter2001economic, title = {The economic benefits of publicly funded basic research: a critical review}, author = {Salter, Ammon J and Martin, Ben R}, journal = {Research policy}, volume = {30}, number = {3}, pages = {509--532}, year = {2001}, publisher = {Elsevier}}                                                        "
    }, {
    "id": 204,
    "url": "https://wanted2.github.io/bibliography/perkmann2007university/",
    "title": "University–industry relationships and open innovation: Towards a research agenda",
    "body": "  Perkmann, M. and Walsh, K. 2007. University–industry relationships and open innovation: Towards a research agenda. International journal of management reviews. 9, 4 (2007), 259–280.                                                                                             @article{perkmann2007university, title = {University--industry relationships and open innovation: Towards a research agenda}, author = {Perkmann, Markus and Walsh, Kathryn}, journal = {International journal of management reviews}, volume = {9}, number = {4}, pages = {259--280}, year = {2007}, publisher = {Wiley Online Library}}                                                        "
    }, {
    "id": 205,
    "url": "https://wanted2.github.io/bibliography/sun2021energy/",
    "title": "Energy efficiency: The role of technological innovation and knowledge spillover",
    "body": "  Sun, H. , Edziah, B. K. , Kporsu, A. K. , Sarkodie, S. A. and Taghizadeh-Hesary, F. 2021. Energy efficiency: The role of technological innovation and knowledge spillover. Technological Forecasting and Social Change. 167, (2021), 120659.                                                                                             @article{sun2021energy, title = {Energy efficiency: The role of technological innovation and knowledge spillover}, author = {Sun, Huaping and Edziah, Bless Kofi and Kporsu, Anthony Kwaku and Sarkodie, Samuel Asumadu and Taghizadeh-Hesary, Farhad}, journal = {Technological Forecasting and Social Change}, volume = {167}, pages = {120659}, year = {2021}, publisher = {Elsevier}}                                                        "
    }, {
    "id": 206,
    "url": "https://wanted2.github.io/bibliography/fini2021attention/",
    "title": "Attention to exploration: The effect of academic entrepreneurship on the production of scientific knowledge",
    "body": "  Fini, R. , Perkmann, M. and Michael Ross, J. 2021. Attention to exploration: The effect of academic entrepreneurship on the production of scientific knowledge. Organization Science. (2021).                                                                                             @article{fini2021attention, title = {Attention to exploration: The effect of academic entrepreneurship on the production of scientific knowledge}, author = {Fini, Riccardo and Perkmann, Markus and Michael Ross, Jan}, journal = {Organization Science}, year = {2021}, publisher = {INFORMS}}                                                        "
    }, {
    "id": 207,
    "url": "https://wanted2.github.io/bibliography/akcigit2021back/",
    "title": "Back to basics: Basic research spillovers, innovation policy, and growth",
    "body": "  Akcigit, U. , Hanley, D. and Serrano-Velarde, N. 2021. Back to basics: Basic research spillovers, innovation policy, and growth. The Review of Economic Studies. 88, 1 (2021), 1–43.                                                                                             @article{akcigit2021back, title = {Back to basics: Basic research spillovers, innovation policy, and growth}, author = {Akcigit, Ufuk and Hanley, Douglas and Serrano-Velarde, Nicolas}, journal = {The Review of Economic Studies}, volume = {88}, number = {1}, pages = {1--43}, year = {2021}, publisher = {Oxford University Press}}                                                        "
    }, {
    "id": 208,
    "url": "https://wanted2.github.io/bibliography/hsu2021rich/",
    "title": "Rich on paper? Chinese firms’ academic publications, patents, and market value",
    "body": "  Hsu, D. H. , Hsu, P. -H. and Zhao, Q. 2021. Rich on paper? Chinese firms’ academic publications, patents, and market value. Research Policy. 50, 9 (2021), 104319.                                                                                             @article{hsu2021rich, title = {Rich on paper? Chinese firms’ academic publications, patents, and market value}, author = {Hsu, David H and Hsu, Po-Hsuan and Zhao, Qifeng}, journal = {Research Policy}, volume = {50}, number = {9}, pages = {104319}, year = {2021}, publisher = {Elsevier}}                                                        "
    }, {
    "id": 209,
    "url": "https://wanted2.github.io/bibliography/martinez2021knowledge/",
    "title": "The knowledge spillover effect of crowdfunding",
    "body": "  Martı́nez-Climent Carla, Mastrangelo, L. and Ribeiro-Soriano, D. 2021. The knowledge spillover effect of crowdfunding. Knowledge Management Research &amp; Practice. 19, 1 (2021), 106–116.                                                                                             @article{martinez2021knowledge, title = {The knowledge spillover effect of crowdfunding}, author = {Mart{\'\i}nez-Climent, Carla and Mastrangelo, Leonardo and Ribeiro-Soriano, Domingo}, journal = {Knowledge Management Research \&amp; Practice}, volume = {19}, number = {1}, pages = {106--116}, year = {2021}, publisher = {Taylor \&amp; Francis}}                                                        "
    }, {
    "id": 210,
    "url": "https://wanted2.github.io/bibliography/COCOtest31/",
    "title": "COCO test-dev Benchmark (Object Detection) | Papers With Code",
    "body": "  COCO test-dev Benchmark (Object Detection) | Papers With Code. https://paperswithcode. com/sota/object-detection-on-coco.   (Accessed on 04/24/2021)                                                                                            @misc{COCOtest31, author = {}, title = {COCO test-dev Benchmark (Object Detection) | Papers With Code}, howpublished = {https://paperswithcode. com/sota/object-detection-on-coco}, month = {}, year = {}, note = {(Accessed on 04/24/2021)}}                                                        "
    }, {
    "id": 211,
    "url": "https://wanted2.github.io/bibliography/conf/eccv/LiuAESRFB16/",
    "title": "SSD: Single Shot MultiBox Detector.",
    "body": "  Liu, W. , Anguelov, D. , Erhan, D. , Szegedy, C. , Reed, S. E. , Fu, C. -Y. and Berg, A. C. 2016. SSD: Single Shot MultiBox Detector. ECCV (1) (2016), 21–37.                                                                                             @inproceedings{conf/eccv/LiuAESRFB16, added-at = {2020-02-12T00:00:00. 000+0100}, author = {Liu, Wei and Anguelov, Dragomir and Erhan, Dumitru and Szegedy, Christian and Reed, Scott E. and Fu, Cheng-Yang and Berg, Alexander C. }, booktitle = {ECCV (1)}, crossref = {conf/eccv/2016-1}, editor = {Leibe, Bastian and Matas, Jiri and Sebe, Nicu and Welling, Max}, ee = {https://www. wikidata. org/entity/Q60638633}, interhash = {b446854aff4b39b071b4db6dd7babde3}, intrahash = {a2b481fd62137855241846b53fc5d4cd}, isbn = {978-3-319-46447-3}, keywords = {dblp}, pages = {21-37}, publisher = {Springer}, series = {Lecture Notes in Computer Science}, timestamp = {2020-02-13T12:33:05. 000+0100}, title = {SSD: Single Shot MultiBox Detector. }, volume = {9905}, year = {2016}}                                                        "
    }, {
    "id": 212,
    "url": "https://wanted2.github.io/bibliography/liu2021Swin/",
    "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows",
    "body": "  Liu, Z. , Lin, Y. , Cao, Y. , Hu, H. , Wei, Y. , Zhang, Z. , Lin, S. and Guo, B. 2021. Swin Transformer: Hierarchical Vision Transformer using Shifted Windows. arXiv preprint arXiv:2103. 14030. (2021).                                                                                             @article{liu2021Swin, title = {Swin Transformer: Hierarchical Vision Transformer using Shifted Windows}, author = {Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining}, journal = {arXiv preprint arXiv:2103. 14030}, year = {2021}}                                                        "
    }, {
    "id": 213,
    "url": "https://wanted2.github.io/bibliography/NECfacia36_online/",
    "title": "NEC facial recognition system offers 99.9% accuracy with mask on - Nikkei Asia",
    "body": "  NEC facial recognition system offers 99. 9% accuracy with mask on - Nikkei Asia. https://asia. nikkei. com/Spotlight/Coronavirus/NEC-facial-recognition-system-offers-99. 9-accuracy-with-mask-on.   (Accessed on 04/24/2021)                                                                                            @misc{NECfacia36:online, author = {}, title = {NEC facial recognition system offers 99. 9\% accuracy with mask on - Nikkei Asia}, howpublished = {https://asia. nikkei. com/Spotlight/Coronavirus/NEC-facial-recognition-system-offers-99. 9-accuracy-with-mask-on}, month = {}, year = {}, note = {(Accessed on 04/24/2021)}}                                                        "
    }, {
    "id": 214,
    "url": "https://wanted2.github.io/bibliography/FaceReco74_online/",
    "title": "Face Recognition Vendor Test (FRVT) | NIST",
    "body": "  Face Recognition Vendor Test (FRVT) | NIST. https://www. nist. gov/programs-projects/face-recognition-vendor-test-frvt.   (Accessed on 04/24/2021)                                                                                            @misc{FaceReco74:online, author = {}, title = {Face Recognition Vendor Test (FRVT) | NIST}, howpublished = {https://www. nist. gov/programs-projects/face-recognition-vendor-test-frvt}, month = {}, year = {}, note = {(Accessed on 04/24/2021)}}                                                        "
    }, {
    "id": 215,
    "url": "https://wanted2.github.io/bibliography/HowtoCho11_online/",
    "title": "How to Choose a PhD Research Topic | DiscoverPhDs",
    "body": "  How to Choose a PhD Research Topic | DiscoverPhDs. https://www. discoverphds. com/advice/finding/phd-research-topic.   (Accessed on 04/25/2021)                                                                                            @misc{HowtoCho11:online, author = {}, title = {How to Choose a PhD Research Topic | DiscoverPhDs}, howpublished = {https://www. discoverphds. com/advice/finding/phd-research-topic}, month = {}, year = {}, note = {(Accessed on 04/25/2021)}}                                                        "
    }, {
    "id": 216,
    "url": "https://wanted2.github.io/bibliography/FoolProo45_online/",
    "title": "Fool Proof Tips for Finding PhD Research Topics - PhDPortal.com",
    "body": "  Fool Proof Tips for Finding PhD Research Topics - PhDPortal. com. https://www. phdportal. com/articles/996/fool-proof-tips-for-finding-phd-research-topics. html.   (Accessed on 04/25/2021)                                                                                            @misc{FoolProo45:online, author = {}, title = {Fool Proof Tips for Finding PhD Research Topics - PhDPortal. com}, howpublished = {https://www. phdportal. com/articles/996/fool-proof-tips-for-finding-phd-research-topics. html}, month = {}, year = {}, note = {(Accessed on 04/25/2021)}}                                                        "
    }, {
    "id": 217,
    "url": "https://wanted2.github.io/bibliography/MOTChall87_online/",
    "title": "MOT Challenge - Results",
    "body": "  MOT Challenge - Results. https://motchallenge. net/results/MOT17/.   (Accessed on 04/25/2021)                                                                                            @misc{MOTChall87:online, author = {}, title = {MOT Challenge - Results}, howpublished = {https://motchallenge. net/results/MOT17/}, month = {}, year = {}, note = {(Accessed on 04/25/2021)}}                                                        "
    }, {
    "id": 218,
    "url": "https://wanted2.github.io/bibliography/MOTChall87_online2/",
    "title": "MOT Challenge",
    "body": "  MOT Challenge. https://motchallenge. net/method/MOT=2927&amp;chl=10.   (Accessed on 04/25/2021)                                                                                            @misc{MOTChall87:online2, author = {}, title = {MOT Challenge}, howpublished = {https://motchallenge. net/method/MOT=2927&amp;chl=10}, month = {}, year = {}, note = {(Accessed on 04/25/2021)}}                                                        "
    }, {
    "id": 219,
    "url": "https://wanted2.github.io/bibliography/xu2021transcenter/",
    "title": "TransCenter: Transformers with Dense Queries for Multiple-Object Tracking",
    "body": "  Xu, Y. , Ban, Y. , Delorme, G. , Gan, C. , Rus, D. and Alameda-Pineda, X. 2021. TransCenter: Transformers with Dense Queries for Multiple-Object Tracking.                                                                                             @misc{xu2021transcenter, title = {TransCenter: Transformers with Dense Queries for Multiple-Object Tracking}, author = {Xu, Yihong and Ban, Yutong and Delorme, Guillaume and Gan, Chuang and Rus, Daniela and Alameda-Pineda, Xavier}, year = {2021}, eprint = {2103. 15145}, archiveprefix = {arXiv}, primaryclass = {cs. CV}}                                                        "
    }, {
    "id": 220,
    "url": "https://wanted2.github.io/bibliography/%E1%BB%A8ngd%E1%BB%A5ngC61_online/",
    "title": "Ứng dụng Computer Vision trong thời đại COVID-19 (3): Quy trình tiêu chuẩn cho việc thu thập dữ liệu liên quan tới đối tượng là con người – NEOS VietNam AIoT",
    "body": "  Ứng dụng Computer Vision trong thời đại COVID-19 (3): Quy trình tiêu chuẩn cho việc thu thập dữ liệu liên quan tới đối tượng là con người – NEOS VietNam AIoT. https://neosaiiot. wordpress. com/2021/04/23/ung-dung-computer-vision-trong-thoi-dai-covid-19-3-quy-trinh-tieu-chuan-cho-viec-thu-thap-du-lieu-lien-quan-toi-doi-tuong-la-con-nguoi/.   (Accessed on 04/25/2021)                                                                                            @misc{ỨngdụngC61:online, author = {}, title = {Ứng dụng Computer Vision trong thời đại COVID-19 (3): Quy trình tiêu chuẩn cho việc thu thập dữ liệu liên quan tới đối tượng là con người – NEOS VietNam AIoT}, howpublished = {https://neosaiiot. wordpress. com/2021/04/23/ung-dung-computer-vision-trong-thoi-dai-covid-19-3-quy-trinh-tieu-chuan-cho-viec-thu-thap-du-lieu-lien-quan-toi-doi-tuong-la-con-nguoi/}, month = {}, year = {}, note = {(Accessed on 04/25/2021)}}                                                        "
    }, {
    "id": 221,
    "url": "https://wanted2.github.io/bibliography/AmazonFr13_online/",
    "title": "Amazon Fraud Detector – Amazon Web Services",
    "body": "  Amazon Fraud Detector – Amazon Web Services. https://aws. amazon. com/vi/fraud-detector/.   (Accessed on 04/25/2021)                                                                                            @misc{AmazonFr13:online, author = {}, title = {Amazon Fraud Detector – Amazon Web Services}, howpublished = {https://aws. amazon. com/vi/fraud-detector/}, month = {}, year = {}, note = {(Accessed on 04/25/2021)}}                                                        "
    }, {
    "id": 222,
    "url": "https://wanted2.github.io/bibliography/AmazonLo45_online/",
    "title": "Amazon Lookout for Equipment - Amazon Web Services",
    "body": "  Amazon Lookout for Equipment - Amazon Web Services. https://aws. amazon. com/lookout-for-equipment/.   (Accessed on 04/25/2021)                                                                                            @misc{AmazonLo45:online, author = {}, title = {Amazon Lookout for Equipment - Amazon Web Services}, howpublished = {https://aws. amazon. com/lookout-for-equipment/}, month = {}, year = {}, note = {(Accessed on 04/25/2021)}}                                                        "
    }, {
    "id": 223,
    "url": "https://wanted2.github.io/bibliography/vaswani2017attention/",
    "title": "Attention is all you need",
    "body": "  Vaswani, A. , Shazeer, N. , Parmar, N. , Uszkoreit, J. , Jones, L. , Gomez, A. N. , Kaiser, Ł. and Polosukhin, I. 2017. Attention is all you need. Advances in neural information processing systems (2017), 5998–6008.                                                                                             @inproceedings{vaswani2017attention, title = {Attention is all you need}, author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia}, booktitle = {Advances in neural information processing systems}, pages = {5998--6008}, year = {2017}}                                                        "
    }, {
    "id": 224,
    "url": "https://wanted2.github.io/bibliography/you2016image/",
    "title": "Image captioning with semantic attention",
    "body": "  You, Q. , Jin, H. , Wang, Z. , Fang, C. and Luo, J. 2016. Image captioning with semantic attention. Proceedings of the IEEE conference on computer vision and pattern recognition (2016), 4651–4659.                                                                                             @inproceedings{you2016image, title = {Image captioning with semantic attention}, author = {You, Quanzeng and Jin, Hailin and Wang, Zhaowen and Fang, Chen and Luo, Jiebo}, booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition}, pages = {4651--4659}, year = {2016}}                                                        "
    }, {
    "id": 225,
    "url": "https://wanted2.github.io/bibliography/johnson2016densecap/",
    "title": "Densecap: Fully convolutional localization networks for dense captioning",
    "body": "  Johnson, J. , Karpathy, A. and Fei-Fei, L. 2016. Densecap: Fully convolutional localization networks for dense captioning. Proceedings of the IEEE conference on computer vision and pattern recognition (2016), 4565–4574.                                                                                             @inproceedings{johnson2016densecap, title = {Densecap: Fully convolutional localization networks for dense captioning}, author = {Johnson, Justin and Karpathy, Andrej and Fei-Fei, Li}, booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition}, pages = {4565--4574}, year = {2016}}                                                        "
    }, {
    "id": 226,
    "url": "https://wanted2.github.io/bibliography/antol2015vqa/",
    "title": "Vqa: Visual question answering",
    "body": "  Antol, S. , Agrawal, A. , Lu, J. , Mitchell, M. , Batra, D. , Zitnick, C. L. and Parikh, D. 2015. Vqa: Visual question answering. Proceedings of the IEEE international conference on computer vision (2015), 2425–2433.                                                                                             @inproceedings{antol2015vqa, title = {Vqa: Visual question answering}, author = {Antol, Stanislaw and Agrawal, Aishwarya and Lu, Jiasen and Mitchell, Margaret and Batra, Dhruv and Zitnick, C Lawrence and Parikh, Devi}, booktitle = {Proceedings of the IEEE international conference on computer vision}, pages = {2425--2433}, year = {2015}}                                                        "
    }, {
    "id": 227,
    "url": "https://wanted2.github.io/bibliography/venugopalan2015sequence/",
    "title": "Sequence to sequence-video to text",
    "body": "  Venugopalan, S. , Rohrbach, M. , Donahue, J. , Mooney, R. , Darrell, T. and Saenko, K. 2015. Sequence to sequence-video to text. Proceedings of the IEEE international conference on computer vision (2015), 4534–4542.                                                                                             @inproceedings{venugopalan2015sequence, title = {Sequence to sequence-video to text}, author = {Venugopalan, Subhashini and Rohrbach, Marcus and Donahue, Jeffrey and Mooney, Raymond and Darrell, Trevor and Saenko, Kate}, booktitle = {Proceedings of the IEEE international conference on computer vision}, pages = {4534--4542}, year = {2015}}                                                        "
    }, {
    "id": 228,
    "url": "https://wanted2.github.io/bibliography/rajpurkar2016squad/",
    "title": "SQuAD: 100,000+ Questions for Machine Comprehension of Text",
    "body": "  Rajpurkar, P. , Zhang, J. , Lopyrev, K. and Liang, P. 2016. SQuAD: 100,000+ Questions for Machine Comprehension of Text. Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing (2016), 2383–2392.                                                                                             @inproceedings{rajpurkar2016squad, title = {SQuAD: 100,000+ Questions for Machine Comprehension of Text}, author = {Rajpurkar, Pranav and Zhang, Jian and Lopyrev, Konstantin and Liang, Percy}, booktitle = {Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing}, pages = {2383--2392}, year = {2016}}                                                        "
    }, {
    "id": 229,
    "url": "https://wanted2.github.io/bibliography/ranzato2015sequence/",
    "title": "Sequence level training with recurrent neural networks",
    "body": "  Ranzato, M. A. , Chopra, S. , Auli, M. and Zaremba, W. 2015. Sequence level training with recurrent neural networks. arXiv preprint arXiv:1511. 06732. (2015).                                                                                             @article{ranzato2015sequence, title = {Sequence level training with recurrent neural networks}, author = {Ranzato, Marc'Aurelio and Chopra, Sumit and Auli, Michael and Zaremba, Wojciech}, journal = {arXiv preprint arXiv:1511. 06732}, year = {2015}}                                                        "
    }, {
    "id": 230,
    "url": "https://wanted2.github.io/bibliography/hochreiter1997long/",
    "title": "Long short-term memory",
    "body": "  Hochreiter, S. and Schmidhuber, J. 1997. Long short-term memory. Neural computation. 9, 8 (1997), 1735–1780.                                                                                             @article{hochreiter1997long, title = {Long short-term memory}, author = {Hochreiter, Sepp and Schmidhuber, J{\ u}rgen}, journal = {Neural computation}, volume = {9}, number = {8}, pages = {1735--1780}, year = {1997}, publisher = {MIT Press}}                                                        "
    }, {
    "id": 231,
    "url": "https://wanted2.github.io/bibliography/gers2000learning/",
    "title": "Learning to forget: Continual prediction with LSTM",
    "body": "  Gers, F. A. , Schmidhuber, J. and Cummins, F. 2000. Learning to forget: Continual prediction with LSTM. Neural computation. 12, 10 (2000), 2451–2471.                                                                                             @article{gers2000learning, title = {Learning to forget: Continual prediction with LSTM}, author = {Gers, Felix A and Schmidhuber, J{\ u}rgen and Cummins, Fred}, journal = {Neural computation}, volume = {12}, number = {10}, pages = {2451--2471}, year = {2000}, publisher = {MIT Press}}                                                        "
    }, {
    "id": 232,
    "url": "https://wanted2.github.io/bibliography/rumelhart1986learning/",
    "title": "Learning representations by back-propagating errors",
    "body": "  Rumelhart, D. E. , Hinton, G. E. and Williams, R. J. 1986. Learning representations by back-propagating errors. nature. 323, 6088 (1986), 533–536.                                                                                             @article{rumelhart1986learning, title = {Learning representations by back-propagating errors}, author = {Rumelhart, David E and Hinton, Geoffrey E and Williams, Ronald J}, journal = {nature}, volume = {323}, number = {6088}, pages = {533--536}, year = {1986}, publisher = {Nature Publishing Group}}                                                        "
    }, {
    "id": 233,
    "url": "https://wanted2.github.io/bibliography/bottou2007tradeoffs/",
    "title": "The tradeoffs of large scale learning",
    "body": "  Bottou, L. and Bousquet, O. 2007. The tradeoffs of large scale learning. Advances in neural information processing systems. 20, (2007).                                                                                             @article{bottou2007tradeoffs, title = {The tradeoffs of large scale learning}, author = {Bottou, L{\'e}on and Bousquet, Olivier}, journal = {Advances in neural information processing systems}, volume = {20}, year = {2007}}                                                        "
    }, {
    "id": 234,
    "url": "https://wanted2.github.io/bibliography/devlin2019bert/",
    "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    "body": "  Devlin, J. , Chang, M. -W. , Lee, K. and Toutanova, K. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers) (2019), 4171–4186.                                                                                             @inproceedings{devlin2019bert, title = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}, author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina}, booktitle = {Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)}, pages = {4171--4186}, year = {2019}}                                                        "
    }, {
    "id": 235,
    "url": "https://wanted2.github.io/bibliography/vaswani2018tensor2tensor/",
    "title": "Tensor2tensor for neural machine translation",
    "body": "  Vaswani, A. , Bengio, S. , Brevdo, E. , Chollet, F. , Gomez, A. N. , Gouws, S. , Jones, L. , Kaiser, Ł. , Kalchbrenner, N. , Parmar, N. and others 2018. Tensor2tensor for neural machine translation. arXiv preprint arXiv:1803. 07416. (2018).                                                                                             @article{vaswani2018tensor2tensor, title = {Tensor2tensor for neural machine translation}, author = {Vaswani, Ashish and Bengio, Samy and Brevdo, Eugene and Chollet, Francois and Gomez, Aidan N and Gouws, Stephan and Jones, Llion and Kaiser, {\L}ukasz and Kalchbrenner, Nal and Parmar, Niki and others}, journal = {arXiv preprint arXiv:1803. 07416}, year = {2018}}                                                        "
    }, {
    "id": 236,
    "url": "https://wanted2.github.io/bibliography/wolf2020transformers/",
    "title": "Transformers: State-of-the-art natural language processing",
    "body": "  Wolf, T. , Chaumond, J. , Debut, L. , Sanh, V. , Delangue, C. , Moi, A. , Cistac, P. , Funtowicz, M. , Davison, J. , Shleifer, S. and others 2020. Transformers: State-of-the-art natural language processing. Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations (2020), 38–45.                                                                                             @inproceedings{wolf2020transformers, title = {Transformers: State-of-the-art natural language processing}, author = {Wolf, Thomas and Chaumond, Julien and Debut, Lysandre and Sanh, Victor and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Funtowicz, Morgan and Davison, Joe and Shleifer, Sam and others}, booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations}, pages = {38--45}, year = {2020}}                                                        "
    }, {
    "id": 237,
    "url": "https://wanted2.github.io/bibliography/liu2019roberta/",
    "title": "Roberta: A robustly optimized bert pretraining approach",
    "body": "  Liu, Y. , Ott, M. , Goyal, N. , Du, J. , Joshi, M. , Chen, D. , Levy, O. , Lewis, M. , Zettlemoyer, L. and Stoyanov, V. 2019. Roberta: A robustly optimized bert pretraining approach. arXiv preprint arXiv:1907. 11692. (2019).                                                                                             @article{liu2019roberta, title = {Roberta: A robustly optimized bert pretraining approach}, author = {Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin}, journal = {arXiv preprint arXiv:1907. 11692}, year = {2019}}                                                        "
    }, {
    "id": 238,
    "url": "https://wanted2.github.io/bibliography/lan2019albert/",
    "title": "Albert: A lite bert for self-supervised learning of language representations",
    "body": "  Lan, Z. , Chen, M. , Goodman, S. , Gimpel, K. , Sharma, P. and Soricut, R. 2019. Albert: A lite bert for self-supervised learning of language representations. arXiv preprint arXiv:1909. 11942. (2019).                                                                                             @article{lan2019albert, title = {Albert: A lite bert for self-supervised learning of language representations}, author = {Lan, Zhenzhong and Chen, Mingda and Goodman, Sebastian and Gimpel, Kevin and Sharma, Piyush and Soricut, Radu}, journal = {arXiv preprint arXiv:1909. 11942}, year = {2019}}                                                        "
    }, {
    "id": 239,
    "url": "https://wanted2.github.io/bibliography/clark2020electra/",
    "title": "Electra: Pre-training text encoders as discriminators rather than generators",
    "body": "  Clark, K. , Luong, M. -T. , Le, Q. V. and Manning, C. D. 2020. Electra: Pre-training text encoders as discriminators rather than generators. arXiv preprint arXiv:2003. 10555. (2020).                                                                                             @article{clark2020electra, title = {Electra: Pre-training text encoders as discriminators rather than generators}, author = {Clark, Kevin and Luong, Minh-Thang and Le, Quoc V and Manning, Christopher D}, journal = {arXiv preprint arXiv:2003. 10555}, year = {2020}}                                                        "
    }, {
    "id": 240,
    "url": "https://wanted2.github.io/bibliography/yang2019xlnet/",
    "title": "Xlnet: Generalized autoregressive pretraining for language understanding",
    "body": "  Yang, Z. , Dai, Z. , Yang, Y. , Carbonell, J. , Salakhutdinov, R. R. and Le, Q. V. 2019. Xlnet: Generalized autoregressive pretraining for language understanding. Advances in neural information processing systems. 32, (2019).                                                                                             @article{yang2019xlnet, title = {Xlnet: Generalized autoregressive pretraining for language understanding}, author = {Yang, Zhilin and Dai, Zihang and Yang, Yiming and Carbonell, Jaime and Salakhutdinov, Russ R and Le, Quoc V}, journal = {Advances in neural information processing systems}, volume = {32}, year = {2019}}                                                        "
    }, {
    "id": 241,
    "url": "https://wanted2.github.io/bibliography/lewis2020bart/",
    "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension",
    "body": "  Lewis, M. , Liu, Y. , Goyal, N. , Ghazvininejad, M. , Mohamed, A. , Levy, O. , Stoyanov, V. and Zettlemoyer, L. 2020. BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension. Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (2020), 7871–7880.                                                                                             @inproceedings{lewis2020bart, title = {BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension}, author = {Lewis, Mike and Liu, Yinhan and Goyal, Naman and Ghazvininejad, Marjan and Mohamed, Abdelrahman and Levy, Omer and Stoyanov, Veselin and Zettlemoyer, Luke}, booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics}, pages = {7871--7880}, year = {2020}}                                                        "
    }, {
    "id": 242,
    "url": "https://wanted2.github.io/bibliography/hinton2006fast/",
    "title": "A fast learning algorithm for deep belief nets",
    "body": "  Hinton, G. E. , Osindero, S. and Teh, Y. -W. 2006. A fast learning algorithm for deep belief nets. Neural computation. 18, 7 (2006), 1527–1554.                                                                                             @article{hinton2006fast, title = {A fast learning algorithm for deep belief nets}, author = {Hinton, Geoffrey E and Osindero, Simon and Teh, Yee-Whye}, journal = {Neural computation}, volume = {18}, number = {7}, pages = {1527--1554}, year = {2006}, publisher = {MIT Press}}                                                        "
    }, {
    "id": 243,
    "url": "https://wanted2.github.io/bibliography/conneau2019cross/",
    "title": "Cross-lingual language model pretraining",
    "body": "  Conneau, A. and Lample, G. 2019. Cross-lingual language model pretraining. Advances in Neural Information Processing Systems. 32, (2019), 7059–7069.                                                                                             @article{conneau2019cross, title = {Cross-lingual language model pretraining}, author = {Conneau, Alexis and Lample, Guillaume}, journal = {Advances in Neural Information Processing Systems}, volume = {32}, pages = {7059--7069}, year = {2019}}                                                        "
    }, {
    "id": 244,
    "url": "https://wanted2.github.io/bibliography/peters2018deep/",
    "title": "Deep Contextualized Word Representations",
    "body": "  Peters, M. E. , Neumann, M. , Iyyer, M. , Gardner, M. , Clark, C. , Lee, K. and Zettlemoyer, L. 2018. Deep Contextualized Word Representations. Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers) (New Orleans, Louisiana, Jun. 2018), 2227–2237.     DOI                                                                                            @inproceedings{peters2018deep, author = {Peters, Matthew E. and Neumann, Mark and Iyyer, Mohit and Gardner, Matt and Clark, Christopher and Lee, Kenton and Zettlemoyer, Luke}, title = {Deep Contextualized Word Representations}, booktitle = {Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)}, year = {2018}, pages = {2227--2237}, publisher = {Association for Computational Linguistics}, address = {New Orleans, Louisiana}, month = jun, url = {https://aclanthology. org/N18-1202}, doi = {10. 18653/v1/N18-1202}}                                                        "
    }, {
    "id": 245,
    "url": "https://wanted2.github.io/bibliography/radford2018improving/",
    "title": "Improving language understanding by generative pre-training",
    "body": "  Radford, A. , Narasimhan, K. , Salimans, T. and Sutskever, I. 2018. Improving language understanding by generative pre-training. OpenAI.                                                                                             @techreport{radford2018improving, author = {Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya}, title = {Improving language understanding by generative pre-training}, year = {2018}, institution = {OpenAI}}                                                        "
    }, {
    "id": 246,
    "url": "https://wanted2.github.io/bibliography/rajpurkar2018know/",
    "title": "Know What You Don’t Know: Unanswerable Questions for SQuAD",
    "body": "  Rajpurkar, P. , Jia, R. and Liang, P. 2018. Know What You Don’t Know: Unanswerable Questions for SQuAD. Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers) (2018), 784–789.                                                                                             @inproceedings{rajpurkar2018know, title = {Know What You Don’t Know: Unanswerable Questions for SQuAD}, author = {Rajpurkar, Pranav and Jia, Robin and Liang, Percy}, booktitle = {Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)}, pages = {784--789}, year = {2018}}                                                        "
    }, {
    "id": 247,
    "url": "https://wanted2.github.io/bibliography/bojar2014findings/",
    "title": "Findings of the 2014 workshop on statistical machine translation",
    "body": "  Bojar, O. , Buck, C. , Federmann, C. , Haddow, B. , Koehn, P. , Leveling, J. , Monz, C. , Pecina, P. , Post, M. , Saint-Amand, H. and others 2014. Findings of the 2014 workshop on statistical machine translation. Proceedings of the ninth workshop on statistical machine translation (2014), 12–58.                                                                                             @inproceedings{bojar2014findings, title = {Findings of the 2014 workshop on statistical machine translation}, author = {Bojar, Ond{\v{r}}ej and Buck, Christian and Federmann, Christian and Haddow, Barry and Koehn, Philipp and Leveling, Johannes and Monz, Christof and Pecina, Pavel and Post, Matt and Saint-Amand, Herve and others}, booktitle = {Proceedings of the ninth workshop on statistical machine translation}, pages = {12--58}, year = {2014}}                                                        "
    }, {
    "id": 248,
    "url": "https://wanted2.github.io/bibliography/bojar2017findings/",
    "title": "Findings of the 2017 conference on machine translation (wmt17)",
    "body": "  Bojar, O. , Chatterjee, R. , Federmann, C. , Graham, Y. , Haddow, B. , Huang, S. , Huck, M. , Koehn, P. , Liu, Q. , Logacheva, V. and others 2017. Findings of the 2017 conference on machine translation (wmt17). Proceedings of the Second Conference on Machine Translation (2017), 169–214.                                                                                             @inproceedings{bojar2017findings, title = {Findings of the 2017 conference on machine translation (wmt17)}, author = {Bojar, Ond{\v{r}}ej and Chatterjee, Rajen and Federmann, Christian and Graham, Yvette and Haddow, Barry and Huang, Shujian and Huck, Matthias and Koehn, Philipp and Liu, Qun and Logacheva, Varvara and others}, booktitle = {Proceedings of the Second Conference on Machine Translation}, pages = {169--214}, year = {2017}}                                                        "
    }, {
    "id": 249,
    "url": "https://wanted2.github.io/bibliography/paul2004introduc/",
    "title": "An Introduction to DUC-2004",
    "body": "  Over, P. and Yen, J. 2014. An Introduction to DUC-2004. https://duc. nist. gov/pubs/2004slides/duc2004. intro. pdf.                                                                                             @misc{paul2004introduc, title = {An Introduction to DUC-2004}, author = {Over, Paul and Yen, James}, howpublished = {https://duc. nist. gov/pubs/2004slides/duc2004. intro. pdf}, year = {2014}}                                                        "
    }, {
    "id": 250,
    "url": "https://wanted2.github.io/bibliography/metatext2022summary/",
    "title": "+64 Summarization Datasets - NLP Database",
    "body": "  +64 Summarization Datasets - NLP Database.   (Accessed on 02/06/2022)                                                                                            @misc{metatext2022summary, author = {}, title = {+64 Summarization Datasets - NLP Database}, howpublished = {\url{https://metatext. io/datasets-list/summarization-task}}, month = {}, year = {}, note = {(Accessed on 02/06/2022)}}                                                        "
    }, {
    "id": 251,
    "url": "https://wanted2.github.io/bibliography/koupaee2018wikihow/",
    "title": "Wikihow: A large scale text summarization dataset",
    "body": "  Koupaee, M. and Wang, W. Y. 2018. Wikihow: A large scale text summarization dataset. arXiv preprint arXiv:1810. 09305. (2018).                                                                                             @article{koupaee2018wikihow, title = {Wikihow: A large scale text summarization dataset}, author = {Koupaee, Mahnaz and Wang, William Yang}, journal = {arXiv preprint arXiv:1810. 09305}, year = {2018}}                                                        "
    }, {
    "id": 252,
    "url": "https://wanted2.github.io/bibliography/lin2004rouge/",
    "title": "Rouge: A package for automatic evaluation of summaries",
    "body": "  Lin, C. -Y. 2004. Rouge: A package for automatic evaluation of summaries. Text summarization branches out (2004), 74–81.                                                                                             @inproceedings{lin2004rouge, title = {Rouge: A package for automatic evaluation of summaries}, author = {Lin, Chin-Yew}, booktitle = {Text summarization branches out}, pages = {74--81}, year = {2004}}                                                        "
    }, {
    "id": 253,
    "url": "https://wanted2.github.io/bibliography/nallapati2016abstractive/",
    "title": "Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond",
    "body": "  Nallapati, R. , Zhou, B. , Santos, C. dos, Gu̇lçehre Çağlar and Xiang, B. 2016. Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond. Proceedings of The 20th SIGNLL Conference on Computational Natural Language Learning (2016), 280–290.                                                                                             @inproceedings{nallapati2016abstractive, title = {Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond}, author = {Nallapati, Ramesh and Zhou, Bowen and dos Santos, Cicero and Gu̇l{\c{c}}ehre, {\c{C}}a{\u{g}}lar and Xiang, Bing}, booktitle = {Proceedings of The 20th SIGNLL Conference on Computational Natural Language Learning}, pages = {280--290}, year = {2016}}                                                        "
    }, {
    "id": 254,
    "url": "https://wanted2.github.io/bibliography/xiong2019tweetqa/",
    "title": "TWEETQA: A Social Media Focused Question Answering Dataset",
    "body": "  Xiong, W. , Wu, J. , Wang, H. , Kulkarni, V. , Yu, M. , Chang, S. , Guo, X. and Wang, W. Y. 2019. TWEETQA: A Social Media Focused Question Answering Dataset. Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics (2019), 5020–5031.                                                                                             @inproceedings{xiong2019tweetqa, title = {TWEETQA: A Social Media Focused Question Answering Dataset}, author = {Xiong, Wenhan and Wu, Jiawei and Wang, Hong and Kulkarni, Vivek and Yu, Mo and Chang, Shiyu and Guo, Xiaoxiao and Wang, William Yang}, booktitle = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics}, pages = {5020--5031}, year = {2019}}                                                        "
    }, {
    "id": 255,
    "url": "https://wanted2.github.io/bibliography/goyal2017making/",
    "title": "Making the v in vqa matter: Elevating the role of image understanding in visual question answering",
    "body": "  Goyal, Y. , Khot, T. , Summers-Stay, D. , Batra, D. and Parikh, D. 2017. Making the v in vqa matter: Elevating the role of image understanding in visual question answering. Proceedings of the IEEE conference on computer vision and pattern recognition (2017), 6904–6913.                                                                                             @inproceedings{goyal2017making, title = {Making the v in vqa matter: Elevating the role of image understanding in visual question answering}, author = {Goyal, Yash and Khot, Tejas and Summers-Stay, Douglas and Batra, Dhruv and Parikh, Devi}, booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition}, pages = {6904--6913}, year = {2017}}                                                        "
    }, {
    "id": 256,
    "url": "https://wanted2.github.io/bibliography/zellers2019recognition/",
    "title": "From recognition to cognition: Visual commonsense reasoning",
    "body": "  Zellers, R. , Bisk, Y. , Farhadi, A. and Choi, Y. 2019. From recognition to cognition: Visual commonsense reasoning. Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (2019), 6720–6731.                                                                                             @inproceedings{zellers2019recognition, title = {From recognition to cognition: Visual commonsense reasoning}, author = {Zellers, Rowan and Bisk, Yonatan and Farhadi, Ali and Choi, Yejin}, booktitle = {Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages = {6720--6731}, year = {2019}}                                                        "
    }, {
    "id": 257,
    "url": "https://wanted2.github.io/bibliography/VCRdataset/",
    "title": "VCR: Visual Commonsense Reasoning",
    "body": "  VCR: Visual Commonsense Reasoning.   (Accessed on 02/07/2022)                                                                                            @misc{VCRdataset, author = {}, title = {VCR: Visual Commonsense Reasoning}, howpublished = {\url{http://visualcommonsense. com/explore/?im=2518}}, month = {}, year = {}, note = {(Accessed on 02/07/2022)}}                                                        "
    }, {
    "id": 258,
    "url": "https://wanted2.github.io/bibliography/Yakubovskiy_2019/",
    "title": "Segmentation Models Pytorch",
    "body": "  Yakubovskiy, P. 2020. Segmentation Models Pytorch. GitHub repository. GitHub.                                                                                             @misc{Yakubovskiy:2019, author = {Yakubovskiy, Pavel}, title = {Segmentation Models Pytorch}, year = {2020}, publisher = {GitHub}, journal = {GitHub repository}, howpublished = {\url{https://github. com/qubvel/segmentation_models. pytorch}}}                                                        "
    }, {
    "id": 259,
    "url": "https://wanted2.github.io/bibliography/wu2019detectron2/",
    "title": "Detectron2",
    "body": "  Wu, Y. , Kirillov, A. , Massa, F. , Lo, W. -Y. and Girshick, R. 2019. Detectron2.                                                                                             @misc{wu2019detectron2, author = {Wu, Yuxin and Kirillov, Alexander and Massa, Francisco and Lo, Wan-Yen and Girshick, Ross}, title = {Detectron2}, howpublished = {\url{https://github. com/facebookresearch/detectron2}}, year = {2019}}                                                        "
    }, {
    "id": 260,
    "url": "https://wanted2.github.io/bibliography/rw2019timm/",
    "title": "PyTorch Image Models",
    "body": "  Wightman, R. 2019. PyTorch Image Models. GitHub repository. GitHub.     DOI                                                                                            @misc{rw2019timm, author = {Wightman, Ross}, title = {PyTorch Image Models}, year = {2019}, publisher = {GitHub}, journal = {GitHub repository}, doi = {10. 5281/zenodo. 4414861}, howpublished = {\url{https://github. com/rwightman/pytorch-image-models}}}                                                        "
    }, {
    "id": 261,
    "url": "https://wanted2.github.io/bibliography/mmdetection/",
    "title": "MMDetection: Open MMLab Detection Toolbox and Benchmark",
    "body": "  Chen, K. et al. 2019. MMDetection: Open MMLab Detection Toolbox and Benchmark. arXiv preprint arXiv:1906. 07155. (2019).                                                                                             @article{mmdetection, title = {{MMDetection}: Open MMLab Detection Toolbox and Benchmark}, author = {Chen, Kai and Wang, Jiaqi and Pang, Jiangmiao and Cao, Yuhang and Xiong, Yu and Li, Xiaoxiao and Sun, Shuyang and Feng, Wansen and Liu, Ziwei and Xu, Jiarui and Zhang, Zheng and Cheng, Dazhi and Zhu, Chenchen and Cheng, Tianheng and Zhao, Qijie and Li, Buyu and Lu, Xin and Zhu, Rui and Wu, Yue and Dai, Jifeng and Wang, Jingdong and Shi, Jianping and Ouyang, Wanli and Loy, Chen Change and Lin, Dahua}, journal = {arXiv preprint arXiv:1906. 07155}, year = {2019}}                                                        "
    }, {
    "id": 262,
    "url": "https://wanted2.github.io/bibliography/krishna2017visual/",
    "title": "Visual genome: Connecting language and vision using crowdsourced dense image annotations",
    "body": "  Krishna, R. , Zhu, Y. , Groth, O. , Johnson, J. , Hata, K. , Kravitz, J. , Chen, S. , Kalantidis, Y. , Li, L. -J. , Shamma, D. A. and others 2017. Visual genome: Connecting language and vision using crowdsourced dense image annotations. International journal of computer vision. 123, 1 (2017), 32–73.                                                                                             @article{krishna2017visual, title = {Visual genome: Connecting language and vision using crowdsourced dense image annotations}, author = {Krishna, Ranjay and Zhu, Yuke and Groth, Oliver and Johnson, Justin and Hata, Kenji and Kravitz, Joshua and Chen, Stephanie and Kalantidis, Yannis and Li, Li-Jia and Shamma, David A and others}, journal = {International journal of computer vision}, volume = {123}, number = {1}, pages = {32--73}, year = {2017}, publisher = {Springer}}                                                        "
    }, {
    "id": 263,
    "url": "https://wanted2.github.io/bibliography/goyal2017accurate/",
    "title": "Accurate, large minibatch sgd: Training imagenet in 1 hour",
    "body": "  Goyal, P. , Dollár, P. , Girshick, R. , Noordhuis, P. , Wesolowski, L. , Kyrola, A. , Tulloch, A. , Jia, Y. and He, K. 2017. Accurate, large minibatch sgd: Training imagenet in 1 hour. arXiv preprint arXiv:1706. 02677. (2017).                                                                                             @article{goyal2017accurate, title = {Accurate, large minibatch sgd: Training imagenet in 1 hour}, author = {Goyal, Priya and Doll{\'a}r, Piotr and Girshick, Ross and Noordhuis, Pieter and Wesolowski, Lukasz and Kyrola, Aapo and Tulloch, Andrew and Jia, Yangqing and He, Kaiming}, journal = {arXiv preprint arXiv:1706. 02677}, year = {2017}}                                                        "
    }, {
    "id": 264,
    "url": "https://wanted2.github.io/bibliography/carreira2017quo/",
    "title": "Quo vadis, action recognition? a new model and the kinetics dataset",
    "body": "  Carreira, J. and Zisserman, A. 2017. Quo vadis, action recognition? a new model and the kinetics dataset. proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (2017), 6299–6308.                                                                                             @inproceedings{carreira2017quo, title = {Quo vadis, action recognition? a new model and the kinetics dataset}, author = {Carreira, Joao and Zisserman, Andrew}, booktitle = {proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}, pages = {6299--6308}, year = {2017}}                                                        "
    }, {
    "id": 265,
    "url": "https://wanted2.github.io/bibliography/smith1997scientist/",
    "title": "The scientist and engineer’s guide to digital signal processing",
    "body": "  Smith, S. W. and others 1997. The scientist and engineer’s guide to digital signal processing. California Technical Pub. San Diego, California.                                                                                             @book{smith1997scientist, author = {Smith, Steven W and others}, title = {The scientist and engineer's guide to digital signal processing}, year = {1997}, publisher = {California Technical Pub. San Diego, California}}                                                        "
    }, {
    "id": 266,
    "url": "https://wanted2.github.io/bibliography/zolzer2008digital/",
    "title": "Digital audio signal processing",
    "body": "  Zölzer, U. 2008. Digital audio signal processing. John Wiley &amp; Sons.                                                                                             @book{zolzer2008digital, title = {Digital audio signal processing}, author = {Z{\ o}lzer, Udo}, year = {2008}, publisher = {John Wiley \&amp; Sons}}                                                        "
    }, {
    "id": 267,
    "url": "https://wanted2.github.io/bibliography/gulati2020conformer/",
    "title": "Conformer: Convolution-augmented Transformer for Speech Recognition",
    "body": "  Gulati, A. , Qin, J. , Chiu, C. -C. , Parmar, N. , Zhang, Y. , Yu, J. , Han, W. , Wang, S. , Zhang, Z. , Wu, Y. and others 2020. Conformer: Convolution-augmented Transformer for Speech Recognition. Proc. Interspeech 2020. (2020), 5036–5040.                                                                                             @article{gulati2020conformer, title = {Conformer: Convolution-augmented Transformer for Speech Recognition}, author = {Gulati, Anmol and Qin, James and Chiu, Chung-Cheng and Parmar, Niki and Zhang, Yu and Yu, Jiahui and Han, Wei and Wang, Shibo and Zhang, Zhengdong and Wu, Yonghui and others}, journal = {Proc. Interspeech 2020}, pages = {5036--5040}, year = {2020}}                                                        "
    }, {
    "id": 268,
    "url": "https://wanted2.github.io/bibliography/zhang2020pushing/",
    "title": "Pushing the limits of semi-supervised learning for automatic speech recognition",
    "body": "  Zhang, Y. , Qin, J. , Park, D. S. , Han, W. , Chiu, C. -C. , Pang, R. , Le, Q. V. and Wu, Y. 2020. Pushing the limits of semi-supervised learning for automatic speech recognition. arXiv preprint arXiv:2010. 10504. (2020).                                                                                             @article{zhang2020pushing, title = {Pushing the limits of semi-supervised learning for automatic speech recognition}, author = {Zhang, Yu and Qin, James and Park, Daniel S and Han, Wei and Chiu, Chung-Cheng and Pang, Ruoming and Le, Quoc V and Wu, Yonghui}, journal = {arXiv preprint arXiv:2010. 10504}, year = {2020}}                                                        "
    }, {
    "id": 269,
    "url": "https://wanted2.github.io/bibliography/gulati2020conformes/",
    "title": "Conformer: Convolution-augmented Transformer for Speech Recognition",
    "body": "  Gulati, A. , Qin, J. , Chiu, C. -C. , Parmar, N. , Zhang, Y. , Yu, J. , Han, W. , Wang, S. , Zhang, Z. , Wu, Y. and others 2020. Conformer: Convolution-augmented Transformer for Speech Recognition. Proc. Interspeech 2020. (2020), 5036–5040.                                                                                             @article{gulati2020conformes, title = {Conformer: Convolution-augmented Transformer for Speech Recognition}, author = {Gulati, Anmol and Qin, James and Chiu, Chung-Cheng and Parmar, Niki and Zhang, Yu and Yu, Jiahui and Han, Wei and Wang, Shibo and Zhang, Zhengdong and Wu, Yonghui and others}, journal = {Proc. Interspeech 2020}, pages = {5036--5040}, year = {2020}}                                                        "
    }, {
    "id": 270,
    "url": "https://wanted2.github.io/bibliography/kenny2007joint/",
    "title": "Joint factor analysis versus eigenchannels in speaker recognition",
    "body": "  Kenny, P. , Boulianne, G. , Ouellet, P. and Dumouchel, P. 2007. Joint factor analysis versus eigenchannels in speaker recognition. IEEE Transactions on Audio, Speech, and Language Processing. 15, 4 (2007), 1435–1447.                                                                                             @article{kenny2007joint, title = {Joint factor analysis versus eigenchannels in speaker recognition}, author = {Kenny, Patrick and Boulianne, Gilles and Ouellet, Pierre and Dumouchel, Pierre}, journal = {IEEE Transactions on Audio, Speech, and Language Processing}, volume = {15}, number = {4}, pages = {1435--1447}, year = {2007}, publisher = {IEEE}}                                                        "
    }, {
    "id": 271,
    "url": "https://wanted2.github.io/bibliography/hsu2021hubert/",
    "title": "Hubert: Self-supervised speech representation learning by masked prediction of hidden units",
    "body": "  Hsu, W. -N. , Bolte, B. , Tsai, Y. -H. H. , Lakhotia, K. , Salakhutdinov, R. and Mohamed, A. 2021. Hubert: Self-supervised speech representation learning by masked prediction of hidden units. IEEE/ACM Transactions on Audio, Speech, and Language Processing. 29, (2021), 3451–3460.                                                                                             @article{hsu2021hubert, title = {Hubert: Self-supervised speech representation learning by masked prediction of hidden units}, author = {Hsu, Wei-Ning and Bolte, Benjamin and Tsai, Yao-Hung Hubert and Lakhotia, Kushal and Salakhutdinov, Ruslan and Mohamed, Abdelrahman}, journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing}, volume = {29}, pages = {3451--3460}, year = {2021}, publisher = {IEEE}}                                                        "
    }, {
    "id": 272,
    "url": "https://wanted2.github.io/bibliography/yu2016automatic/",
    "title": "Automatic speech recognition",
    "body": "  Yu, D. and Deng, L. 2016. Automatic speech recognition. Springer.                                                                                             @book{yu2016automatic, title = {Automatic speech recognition}, author = {Yu, Dong and Deng, Li}, volume = {1}, year = {2016}, publisher = {Springer}}                                                        "
    }, {
    "id": 273,
    "url": "https://wanted2.github.io/bibliography/reynolds1995robust/",
    "title": "Robust text-independent speaker identification using Gaussian mixture speaker models",
    "body": "  Reynolds, D. A. and Rose, R. C. 1995. Robust text-independent speaker identification using Gaussian mixture speaker models. IEEE transactions on speech and audio processing. 3, 1 (1995), 72–83.                                                                                             @article{reynolds1995robust, title = {Robust text-independent speaker identification using Gaussian mixture speaker models}, author = {Reynolds, Douglas A and Rose, Richard C}, journal = {IEEE transactions on speech and audio processing}, volume = {3}, number = {1}, pages = {72--83}, year = {1995}, publisher = {IEEE}}                                                        "
    }, {
    "id": 274,
    "url": "https://wanted2.github.io/bibliography/dehak2011frontend/",
    "title": "Front-End Factor Analysis for Speaker Verification",
    "body": "  Dehak, N. , Kenny, P. J. , Dehak, R. , Dumouchel, P. and Ouellet, P. 2011. Front-End Factor Analysis for Speaker Verification. IEEE Transactions on Audio, Speech, and Language Processing. 19, 4 (2011), 788–798. DOI:https://doi. org/10. 1109/TASL. 2010. 2064307.     DOI                                                                                            @article{dehak2011frontend, author = {Dehak, Najim and Kenny, Patrick J. and Dehak, R\'eda and Dumouchel, Pierre and Ouellet, Pierre}, title = {Front-End Factor Analysis for Speaker Verification}, journal = {IEEE Transactions on Audio, Speech, and Language Processing}, year = {2011}, volume = {19}, number = {4}, pages = {788-798}, doi = {10. 1109/TASL. 2010. 2064307}}                                                        "
    }, {
    "id": 275,
    "url": "https://wanted2.github.io/bibliography/snyder2018x/",
    "title": "X-vectors: Robust dnn embeddings for speaker recognition",
    "body": "  Snyder, D. , Garcia-Romero, D. , Sell, G. , Povey, D. and Khudanpur, S. 2018. X-vectors: Robust dnn embeddings for speaker recognition. 2018 IEEE international conference on acoustics, speech and signal processing (ICASSP) (2018), 5329–5333.                                                                                             @inproceedings{snyder2018x, title = {X-vectors: Robust dnn embeddings for speaker recognition}, author = {Snyder, David and Garcia-Romero, Daniel and Sell, Gregory and Povey, Daniel and Khudanpur, Sanjeev}, booktitle = {2018 IEEE international conference on acoustics, speech and signal processing (ICASSP)}, pages = {5329--5333}, year = {2018}, organization = {IEEE}}                                                        "
    }, {
    "id": 276,
    "url": "https://wanted2.github.io/bibliography/reynolds1995robusu/",
    "title": "Robust text-independent speaker identification using Gaussian mixture speaker models",
    "body": "  Reynolds, D. A. and Rose, R. C. 1995. Robust text-independent speaker identification using Gaussian mixture speaker models. IEEE transactions on speech and audio processing. 3, 1 (1995), 72–83.                                                                                             @article{reynolds1995robusu, title = {Robust text-independent speaker identification using Gaussian mixture speaker models}, author = {Reynolds, Douglas A and Rose, Richard C}, journal = {IEEE transactions on speech and audio processing}, volume = {3}, number = {1}, pages = {72--83}, year = {1995}, publisher = {IEEE}}                                                        "
    }, {
    "id": 277,
    "url": "https://wanted2.github.io/bibliography/reynolds2000speaker/",
    "title": "Speaker verification using adapted Gaussian mixture models",
    "body": "  Reynolds, D. A. , Quatieri, T. F. and Dunn, R. B. 2000. Speaker verification using adapted Gaussian mixture models. Digital signal processing. 10, 1 (2000), 19–41.                                                                                             @article{reynolds2000speaker, title = {Speaker verification using adapted Gaussian mixture models}, author = {Reynolds, Douglas A and Quatieri, Thomas F and Dunn, Robert B}, journal = {Digital signal processing}, volume = {10}, number = {1}, pages = {19--41}, year = {2000}, publisher = {Elsevier}}                                                        "
    }, {
    "id": 278,
    "url": "https://wanted2.github.io/bibliography/hinton2012deep/",
    "title": "Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups",
    "body": "  Hinton, G. , Deng, L. , Yu, D. , Dahl, G. E. , Mohamed, A. -rahman, Jaitly, N. , Senior, A. , Vanhoucke, V. , Nguyen, P. , Sainath, T. N. and others 2012. Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups. IEEE Signal processing magazine. 29, 6 (2012), 82–97.                                                                                             @article{hinton2012deep, title = {Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups}, author = {Hinton, Geoffrey and Deng, Li and Yu, Dong and Dahl, George E and Mohamed, Abdel-rahman and Jaitly, Navdeep and Senior, Andrew and Vanhoucke, Vincent and Nguyen, Patrick and Sainath, Tara N and others}, journal = {IEEE Signal processing magazine}, volume = {29}, number = {6}, pages = {82--97}, year = {2012}, publisher = {IEEE}}                                                        "
    }, {
    "id": 279,
    "url": "https://wanted2.github.io/bibliography/graves2013speech/",
    "title": "Speech recognition with deep recurrent neural networks",
    "body": "  Graves, A. , Mohamed, A. -rahman and Hinton, G. 2013. Speech recognition with deep recurrent neural networks. 2013 IEEE international conference on acoustics, speech and signal processing (2013), 6645–6649.                                                                                             @inproceedings{graves2013speech, title = {Speech recognition with deep recurrent neural networks}, author = {Graves, Alex and Mohamed, Abdel-rahman and Hinton, Geoffrey}, booktitle = {2013 IEEE international conference on acoustics, speech and signal processing}, pages = {6645--6649}, year = {2013}, organization = {IEEE}}                                                        "
    }, {
    "id": 280,
    "url": "https://wanted2.github.io/bibliography/graves2013hybrid/",
    "title": "Hybrid speech recognition with deep bidirectional LSTM",
    "body": "  Graves, A. , Jaitly, N. and Mohamed, A. -rahman 2013. Hybrid speech recognition with deep bidirectional LSTM. 2013 IEEE workshop on automatic speech recognition and understanding (2013), 273–278.                                                                                             @inproceedings{graves2013hybrid, title = {Hybrid speech recognition with deep bidirectional LSTM}, author = {Graves, Alex and Jaitly, Navdeep and Mohamed, Abdel-rahman}, booktitle = {2013 IEEE workshop on automatic speech recognition and understanding}, pages = {273--278}, year = {2013}, organization = {IEEE}}                                                        "
    }, {
    "id": 281,
    "url": "https://wanted2.github.io/bibliography/panayotov2015librispeech/",
    "title": "Librispeech: an asr corpus based on public domain audio books",
    "body": "  Panayotov, V. , Chen, G. , Povey, D. and Khudanpur, S. 2015. Librispeech: an asr corpus based on public domain audio books. 2015 IEEE international conference on acoustics, speech and signal processing (ICASSP) (2015), 5206–5210.                                                                                             @inproceedings{panayotov2015librispeech, title = {Librispeech: an asr corpus based on public domain audio books}, author = {Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev}, booktitle = {2015 IEEE international conference on acoustics, speech and signal processing (ICASSP)}, pages = {5206--5210}, year = {2015}, organization = {IEEE}}                                                        "
    }, {
    "id": 282,
    "url": "https://wanted2.github.io/bibliography/paul1992design/",
    "title": "The design for the Wall Street Journal-based CSR corpus",
    "body": "  Paul, D. B. and Baker, J. 1992. The design for the Wall Street Journal-based CSR corpus. Speech and Natural Language: Proceedings of a Workshop Held at Harriman, New York, February 23-26, 1992 (1992).                                                                                             @inproceedings{paul1992design, title = {The design for the Wall Street Journal-based CSR corpus}, author = {Paul, Douglas B and Baker, Janet}, booktitle = {Speech and Natural Language: Proceedings of a Workshop Held at Harriman, New York, February 23-26, 1992}, year = {1992}}                                                        "
    }, {
    "id": 283,
    "url": "https://wanted2.github.io/bibliography/garofolo1993darpa/",
    "title": "DARPA TIMIT acoustic-phonetic continous speech corpus CD-ROM. NIST speech disc 1-1.1",
    "body": "  Garofolo, J. S. , Lamel, L. F. , Fisher, W. M. , Fiscus, J. G. and Pallett, D. S. 1993. DARPA TIMIT acoustic-phonetic continous speech corpus CD-ROM. NIST speech disc 1-1. 1. NASA STI/Recon technical report n. 93, (1993), 27403.                                                                                             @article{garofolo1993darpa, title = {DARPA TIMIT acoustic-phonetic continous speech corpus CD-ROM. NIST speech disc 1-1. 1}, author = {Garofolo, John S and Lamel, Lori F and Fisher, William M and Fiscus, Jonathan G and Pallett, David S}, journal = {NASA STI/Recon technical report n}, volume = {93}, pages = {27403}, year = {1993}}                                                        "
    }, {
    "id": 284,
    "url": "https://wanted2.github.io/bibliography/warden2018speech/",
    "title": "Speech commands: A dataset for limited-vocabulary speech recognition",
    "body": "  Warden, P. 2018. Speech commands: A dataset for limited-vocabulary speech recognition. arXiv preprint arXiv:1804. 03209. (2018).                                                                                             @article{warden2018speech, title = {Speech commands: A dataset for limited-vocabulary speech recognition}, author = {Warden, Pete}, journal = {arXiv preprint arXiv:1804. 03209}, year = {2018}}                                                        "
    }, {
    "id": 285,
    "url": "https://wanted2.github.io/robots.txt",
    "title": "",
    "body": "      Sitemap: {{ “sitemap. xml”   absolute_url }}   "
    }, {
    "id": 286,
    "url": "https://wanted2.github.io/page2/",
    "title": "Home",
    "body": "{% if page. url == “/” %}       Featured:       {% for post in site. posts %}    {% if post. featured == true %}      {% include featuredbox. html %}    {% endif %}  {% endfor %}  {% endif %}       All Stories:         {% for post in paginator. posts %}    {% include postbox. html %}    {% endfor %}    {% include pagination. html %}"
    }, {
    "id": 287,
    "url": "https://wanted2.github.io/page3/",
    "title": "Home",
    "body": "{% if page. url == “/” %}       Featured:       {% for post in site. posts %}    {% if post. featured == true %}      {% include featuredbox. html %}    {% endif %}  {% endfor %}  {% endif %}       All Stories:         {% for post in paginator. posts %}    {% include postbox. html %}    {% endfor %}    {% include pagination. html %}"
    }, {
    "id": 288,
    "url": "https://wanted2.github.io/speech/",
    "title": "Speech and Sequence-to-sequence",
    "body": "2022/02/06 - Như trong bài viết trước thì chúng ta đã tìm hiểu và biết trong mảng NLP cũng như Vision-Language (VL) thì seq2seq đều đang làm chủ. Trong bài viết này chúng ta sẽ tìm hiểu 1 mảng khác mà seq2seq và các hậu duệ (thuộc dòng dõi Transformer [1] và BERT [2, 3]) cũng đang nắm thế chủ động. Khởi đầu bài viết, tôi định viết lại về i-vector [4, 5] và x-vector [6] là các biểu diễn nổi bật trong speaker identification (SI)/ automatic speech recognition (ASR), nhưng xem ra mảng speech recognition cũng bị seq2seq chiếm hết rồi nên chúng ta sẽ nói thêm về một số state-of-the-art thuộc dạng này như Conformer [7, 8] 12. Với bài toán SI thì cách làm cổ điển sẽ là dùng Gaussian Mixture Models (GMM, [9, 10, 4, 5]), còn với ASR thì dùng GMM để classify HMM states (GMM-HMM), tuy nhiên là như kết quả của nhiều nhóm nghiên cứu về SI/ASR thì Deep Neural Networks (DNN) với đạt kết quả tốt hơn hẳn cho cả SI (DNN embeddings, [6]) lẫn ASR (DNN-HMM, [11]). Do vậy về mặt lịch sử thì GMM/GMM-HMM là cách làm truyền thống, từ khoảng 2012 thì DNN/DNN-HMM chứng tỏ DNN tốt hơn hẳn HMM về mặt representations lẫn accuracy. Gần đây thì đến lượt những tiến bộ bắt nguồn từ seq2seq DNN-RNN, rồi đến những model end-to-end, transformers. Giới thiệu chung về ASR/SI và các bài toán liên quanAutomatic Speech Recognition: Automatic Speech Recognition (ASR, [12]) là nhiệm vụ chuyển một chuỗi âm thanh giọng nói (waveform) sang một chuỗi văn bản được chứa trong âm thanh đó. Cách làm truyền thống nhất là sử dụng Hidden Markov Model (HMM) để mô hình thông tin chuỗi, và dùng GMM để fit lượng thông tin của các states trong HMM vào 1 phân bố có sẵn và đưa ra nhận dạng cho âm thanh trong time window tương ứng. Tuy nhiên, GMM có nhược điểm là khó có thể mô hình được dữ liệu phi tuyến tính (non-linear manifold) dẫn đến nếu lượng dữ liệu ít có thể xảy ra tình trạng overfit hoặc model HMM không mô tả hết manifold dữ liệu (ếch ngồi đáy giếng). Do đó, thông qua kết quả thực nghiệm [11], thì nếu thay GMM bởi DNN để xuất ra xác suất của từng âm một từ states của HMM thì kết quả outperform GMM-HMM trong nhiều bộ dữ liệu lớn. Và quan trọng là càng train nhiều dữ liệu thì model DNN-HMM càng stable. Nhìn chung DNN-HMM thì cũng là một kiểu model seq2seq tức là chuyển chuỗi (audio) thành chuỗi (text hoặc phoneme [13, 14]). Vì vậy khá đơn giản để ứng dụng model seq2seq vào ASR. Chuỗi âm thanh (waveform) được chuyển thành chuỗi đặc trưng MFCC và rồi input vào seq2seq. Và việc này cũng giúp chúng ta loại bỏ luôn HMM để thực hiện training end-to-end. Khi decode output của end-to-end (E2E) network, với giả thiết chúng ta có input là chuỗi \(X=\left\{\mathbf{x}_t\right\}_{t=1}^T\subset\mathbb{R}^d\) và output của E2E network là vector xác suất \(\mathbf{p}_t=\left[p_{t,0},p_{t,2},\ldots,p_{t,N}\right]^\top\in [0,1]^N\) với \(p_{t,i}\) là xác suất của từ thứ \(i\) trong vocabulary ở bước thứ \(t\). Và hiển nhiên \(\sum_{i=1}^Np_{t,i}=1\). Ở đây ta có vocabulary \(V=\left\{\mathbf{w}_1, \mathbf{w}_2, \ldots, \mathbf{w}_N\right\}\) gồm \(N\) từ. Ta sẽ phải tính thêm những quãng ngừng trong output, nên ta thêm từ rỗng vào vocabulary \(\overline{V}=V\cup\phi\). Vậy xác suất của một chuỗi phoneme như \(W=\left[\mathbf{w}_{i_1},\mathbf{w}_{i_2},\ldots,\mathbf{w}_{i_M}\right], M\leq T, 1\leq i_j\leq N\) là bao nhiêu?Chúng ta cần hiểu là từ chuỗi \(P=\left[\mathbf{p}_1,\ldots,\mathbf{p}_T\right]\) để chuyển sang chuỗi \(W\) thì đã thêm từ rỗng \(\phi\) xen kẽ vào \(W\) để có độ dài \(T\). Ta định nghĩa một ánh xạ many-to-one \(f: V^T\rightarrow V^{\leq T}\) là một phép toán xóa bỏ tất cả các từ rỗng khỏi từ có độ dài \(T\). Vậy phép toán ngược one-to-many \(f^{-1}: V^{\leq T}\rightarrow 2^{V^T}\). Và \(f^{-1}(W)\) là tập các từ có độ dài \(T\) mà loại bỏ hết từ rỗng đi thì còn lại \(W\). Xác xuất của 1 từ \(\pi = \left[\mathbf{w}_{l_1},\mathbf{w}_{l_2},\ldots,\mathbf{w}_{l_T}\right]\in f^{-1}(W) \subset V^T\) là [p\left(\pi \mid \mathbf{\theta};X\right) = \sum_{t=1}^T p\left(\mathbf{w}{l_t}\mid \mathbf{\theta};\mathbf{x}_t\right)=\sum{t=1}^Tp_{t,l_t}] trong đó \(\mathbf{\theta}\) là parameters của model E2E. Vậy xác xuất để model output ra cụm từ \(W\) là [p\left(W\mid \mathbf{\theta};X\right)=\sum_{\pi\in f^{-1}(W)}p\left(\pi\mid \mathbf{\theta};X\right)] Vấn đề bây giờ rút gọn lại thành tìm ứng với model \(\mathbf{\theta}\) và chuỗi đầu vào \(X\) thì cần phải decode ra cụm output \(W\) có độ dài không quá \(T\) tức là tìm ra \(W\) thỏa mãn: [W=\mbox{argmax}{W\in V^{\leq T}}p\left(W\mid \mathbf{\theta};X\right)=\mbox{argmax}{W\in V^{\leq T}}\sum_{\pi\in f^{-1}(W)}p\left(\pi\mid \mathbf{\theta};X\right)] Bài toán đặt ra là số lượng khả năng cần phải tính toán là vô cùng nhiều, do đó cách làm hiệu quả rơi vào 1 trong hai cách:  Dùng dynamic programming để tìm ra alignment dựa theo công thức ở trên. Phương pháp này thi thoảng gọi là Connectionist Temporal Segmentation (CTC).  Dùng transducer: tạo ra một network để học alignment thông qua backpropagation và dựa vào phoneme ở step trước. Transducer thì nhanh hơn rất nhiều so với dynamic programming, và vì xác suất của từng chuỗi \(p\left(\pi\mid \mathbf{\theta};X\right)\) được mô hình bằng neural network nên tính toán có tính thích ứng cao hơn với dữ liệu. Nhìn chung, task ASR khá thuận lợi cho việc ứng dụng mô hình seq2seq như Transformer hay BERT. Dữ liệu thì cũng dồi dào nhất là tiếng Anh với hàng ngàn giờ đọc cuả đủ loại speech như audio books [15], báo chí Wall Street Journal [16], phát âm [17], . v. v…Thì những bộ dữ liệu trên thuộc nhóm task conversational speech recognition. Những task này đòi hỏi phải transcribe ngay khi âm thanh phát ra. Ngoài ra cũng có nhóm task command speech recognition tức là kiểu như người dùng nói vào loa Echo và câu lệnh được ghi nhận. Đó thường là các câu lệnh ngắn. Với tiếng Anh, có bộ dữ liệu Speech Commands [18]. Code kiếc, tool thiếc cũng nói chung sẵn có dồi dào: ESPNet (missing reference), Microsoft ASR (missing reference), DeepSpeech v1 &amp; v2 (missing reference) hay fairseq (missing reference). Mà những công việc chuẩn bị dữ liệu recipes các cái là có sẵn trong các framework trên rồi như là với ESPNet bạn có thể tham khảo tại:  https://github. com/espnet/espnet/tree/master/egs2Nên nói chung là cũng chả cần code mấy đâu, chủ yếu là code vài dòng thể hiện ý tưởng. Nếu bạn thích ăn sẵn hơn nữa thì đấy lại có cái Amazon Lex v22. Sound classification và Speaker Identification: Voice Conversion, Text-To-Speech và Speech Synthesis: Công nghệ chínhi-vector và x-vector cho bài toán Speaker Identification: seq2seq và các Transformers cho bài toán ASR: Lưu ý khi train model ASR/SIGiá thành khi train model State-of-the-art (SOTA): Quay lại với mảng ASR, nhìn đi nhìn lại cũng lại hậu duệ của seq2seq nên chắc mẩm là giá sẽ không mềm rồi. Như hình dưới tôi đưa ra ví dụ dựa trên mô tả của một nhóm làm về ASR trong Google Brain [8]. Giá cả của TPU thì v3 mà trên 32 cores thì chỉ mới hỗ trợ tài Hà Lan nên các bạn chú ý nhé. Kết luận chung là để mà train vài ngày trên bộ Librispeech thôi chả hạn là cũng tốn vài chục ngàn Mỹ kim rồi. Tóm lại là cuộc chơi của người giàu các bạn ạ! Tài liệu tham khảoVaswani, A. , Shazeer, N. , Parmar, N. , Uszkoreit, J. , Jones, L. , Gomez, A. N. , Kaiser, Ł. and Polosukhin, I. 2017. Attention is all you need. Advances in neural information processing systems (2017), 5998–6008. DetailsDevlin, J. , Chang, M. -W. , Lee, K. and Toutanova, K. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers) (2019), 4171–4186. DetailsHsu, W. -N. , Bolte, B. , Tsai, Y. -H. H. , Lakhotia, K. , Salakhutdinov, R. and Mohamed, A. 2021. Hubert: Self-supervised speech representation learning by masked prediction of hidden units. IEEE/ACM Transactions on Audio, Speech, and Language Processing. 29, (2021), 3451–3460. DetailsKenny, P. , Boulianne, G. , Ouellet, P. and Dumouchel, P. 2007. Joint factor analysis versus eigenchannels in speaker recognition. IEEE Transactions on Audio, Speech, and Language Processing. 15, 4 (2007), 1435–1447. DetailsDehak, N. , Kenny, P. J. , Dehak, R. , Dumouchel, P. and Ouellet, P. 2011. Front-End Factor Analysis for Speaker Verification. IEEE Transactions on Audio, Speech, and Language Processing. 19, 4 (2011), 788–798. DOI:https://doi. org/10. 1109/TASL. 2010. 2064307. DetailsSnyder, D. , Garcia-Romero, D. , Sell, G. , Povey, D. and Khudanpur, S. 2018. X-vectors: Robust dnn embeddings for speaker recognition. 2018 IEEE international conference on acoustics, speech and signal processing (ICASSP) (2018), 5329–5333. DetailsGulati, A. , Qin, J. , Chiu, C. -C. , Parmar, N. , Zhang, Y. , Yu, J. , Han, W. , Wang, S. , Zhang, Z. , Wu, Y. and others 2020. Conformer: Convolution-augmented Transformer for Speech Recognition. Proc. Interspeech 2020. (2020), 5036–5040. DetailsZhang, Y. , Qin, J. , Park, D. S. , Han, W. , Chiu, C. -C. , Pang, R. , Le, Q. V. and Wu, Y. 2020. Pushing the limits of semi-supervised learning for automatic speech recognition. arXiv preprint arXiv:2010. 10504. (2020). DetailsReynolds, D. A. and Rose, R. C. 1995. Robust text-independent speaker identification using Gaussian mixture speaker models. IEEE transactions on speech and audio processing. 3, 1 (1995), 72–83. DetailsReynolds, D. A. , Quatieri, T. F. and Dunn, R. B. 2000. Speaker verification using adapted Gaussian mixture models. Digital signal processing. 10, 1 (2000), 19–41. DetailsHinton, G. , Deng, L. , Yu, D. , Dahl, G. E. , Mohamed, A. -rahman, Jaitly, N. , Senior, A. , Vanhoucke, V. , Nguyen, P. , Sainath, T. N. and others 2012. Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups. IEEE Signal processing magazine. 29, 6 (2012), 82–97. DetailsYu, D. and Deng, L. 2016. Automatic speech recognition. Springer. DetailsGraves, A. , Mohamed, A. -rahman and Hinton, G. 2013. Speech recognition with deep recurrent neural networks. 2013 IEEE international conference on acoustics, speech and signal processing (2013), 6645–6649. DetailsGraves, A. , Jaitly, N. and Mohamed, A. -rahman 2013. Hybrid speech recognition with deep bidirectional LSTM. 2013 IEEE workshop on automatic speech recognition and understanding (2013), 273–278. DetailsPanayotov, V. , Chen, G. , Povey, D. and Khudanpur, S. 2015. Librispeech: an asr corpus based on public domain audio books. 2015 IEEE international conference on acoustics, speech and signal processing (ICASSP) (2015), 5206–5210. DetailsPaul, D. B. and Baker, J. 1992. The design for the Wall Street Journal-based CSR corpus. Speech and Natural Language: Proceedings of a Workshop Held at Harriman, New York, February 23-26, 1992 (1992). DetailsGarofolo, J. S. , Lamel, L. F. , Fisher, W. M. , Fiscus, J. G. and Pallett, D. S. 1993. DARPA TIMIT acoustic-phonetic continous speech corpus CD-ROM. NIST speech disc 1-1. 1. NASA STI/Recon technical report n. 93, (1993), 27403. DetailsWarden, P. 2018. Speech commands: A dataset for limited-vocabulary speech recognition. arXiv preprint arXiv:1804. 03209. (2018). Details      Nguyên tắc vẫn như cũ, chọn những bài top nhiều citations và có độ tăng trưởng tốt thôi nhé.  &#8617;        Bài viết này chủ yếu là giới thiệu công nghệ thôi. Chứ còn đồ ăn sẵn thì các bạn có thể tham khảo Amazon Lex.  &#8617; &#8617;2    "
    }, {
    "id": 289,
    "url": "https://wanted2.github.io/seq2seq/",
    "title": "Seq2Seq và kiến trúc Encoder-Decoder",
    "body": "2022/02/01 - Seq2Seq [1, 2, 3] là một giải pháp kiến trúc được dùng khá nhiều trong các bài toán NLP và vision như Neural Machine Translation (NMT, [2]), Question-Answering (QA, [4]), Visual Question Answering (VQA, [5, 6]), Text Summarization (TS, [7, 8]) và Video-To-Text (VTT, [9]). Bài toán Image Captioning thì cũng có thể ứng dụng seq2seq nếu thông minh hơn một tí, sử dụng object detector để detect attributes và coi attribute sequence đó thành input vào seq2seq như trong bài Semantic Attention (SA) [10] hay Densecap [11]. Nên nhìn chung là seq2seq là 1 technique mà có thể dùng vào nhiều nhiệm vụ và rất hữu dụng [12]. 1 Giới thiệu model Seq2SeqNỗi lòng người làm thày mà hướng dẫn sinh viên thì tùy level mà kỳ vọng thì nó cũng khác nhau, và với những level cao như postdoc là luôn có sự mong muốn nhất định. Đó là phải vượt qua thử thách (challenges) của thày. Thì cái challenge đây có hai nghĩa là cuộc thi và thử thách, thì nói thực là cuộc thi không cần đâu, chỉ cần vượt qua thử thách tối thiểu của thày trong cái kỹ năng làm nghiên cứu thôi là ok em rồi. Trong thực tế kinh nghiệm thì tôi thấy mấy cái thử thách cũng không phức tạp lắm đâu, đặc biệt là trong lĩnh vực NLP+Vision này thì tôi thấy cũng chỉ có vài bài như Image Captioning, Video-to-Text hay VQA. Code thì nhan nhản trong cộng đồng nghiên cứu (đặc thù của ngạch nghiên cứu là kế thừa, vì người ta công bố mà mình không dùng thì phí), rồi tài liệu thì mảng NLP với Vision các ông cũng publish trên ArXiV với mấy hội nghị open, chứ nào có giấu giếm gì nhau?Thế mà không hiểu vì sao vẫn không vượt qua được cho thày?Xem lại rốt cuộc là tôi nghĩ thì có lẽ nên thêm câu hỏi sau vào bộ dữ liệu QA:  Q: Không làm muốn có ăn thì ăn gì bây giờ?A: ??? (câu hỏi tự luận nha)Context: Hãy xem video của Prof. Huan Rose Thì nhìn chung là seq2seq là một model thử thách như vậy. Với những bài đặc biệt chỉ của NLP như NMT, Text Summarization hay QA thì seq2seq đã mở ra hẳn cả một mảng riêng mà về sau còn có thêm mấy cái pretraining encoder/decoder như BERT, AlBERT, RoBERT, BART, … mà chủ yếu là representation learning.  Mô hình seq2seq đơn giản chỉ gồm một chuỗi input $\mathbb{x}_1, \mathbb{x}_2, \ldots, \mathbb{x}_m$. Chuỗi này đương nhiên là biểu diễn vector (embedding) sau khi đã preprocessing qua tokenizer và thay thế từ không có trong vocabulảy bởi UNK. Sau đó là encoder với các trạng thái $\mathbb{h}_1, \mathbb{h}_2, \ldots, \mathbb{h}_m$ cũng như biểu diễn đầu ra của encoder là $\mathbb{z}_1, \mathbb{z}_2, \ldots, \mathbb{z}_m$. Encoder chính là một mạng trí tuệ nhân tạo dạng Long-Short Term Memory (LSTM) mà chúng ta sẽ nói sau. Bây giờ thì chúng ta cần aggregate chuỗi biểu diễn đầu ra của encoder thành biến vector \(\mathbb{c}_t=\sum_{i=1}^m\alpha_i^t\mathbb{z}_i\). Ở mỗi bước \(t\) thì decoder LSTM sẽ nhận input là output của bước \(t-1\) là \(\mathbb{g}_{t-1}\) và biến context \(\mathbb{c}_t\) để đưa ra output \(\mathbb{g}_t\). \[\mathbb{g}_t=\mbox{LSTM}\left(\mathbb{g}_{t-1},\mathbb{c}_t\right)\] ứng với mỗi \(\mathbb{g}_t\) sẽ được giải mã thành một ký tự trong ngôn ngữ đầu ra. Quá trình này kết thúc khi ký tự EOS được giải mã ra. Chuỗi đầu vào \(\mathbb{x}_i\) và chuỗi đầu ra của decoder \(\mathbb{g}_j\) có thể có độ dài khác nhau. Trong bài toán NMT, thì chuỗi đầu vào có thể là tiếng Anh và chuỗi đầu ra là tiếng Nhật. Nhưng ngược lại thì sẽ cần tokenizer bằng tiếng Nhật. Trong bài toán Text Summarization (TS), thì cả đầu ra và đầu vào đều sẽ cùng ngôn ngữ, nhưng đầu ra sẽ là một chuỗi ngắn gọn xúc tích hơn. Cái gọi là ngắn gọn, xúc tích hơn sẽ được định nghĩa và học thông qua dữ liệu. Thì NMT có bộ WMT2014 [14], WMT2017 [15], còn TS thì có bộ DUC [16]. Còn bài toán QA thì chuỗi đầu vào là một câu hỏi còn đầu ra là 1 câu trả lời. Cái hay của QA là đôi khi có thêm chuỗi context (hay gọi là gợi ý), ví dụ như hỏi Bạn sống ở đâu? thì có thêm context là Tôi sống ở Nhật thì máy sẽ trả lời luôn là Nhật. QA thì có bộ SQuAD v1 [4] và v2 [17] với hơn trăm ngàn bộ câu hỏi (nghe như luyện thì TOEIC). Metrics đánh giá thì có cái BLUE-4 score, CIDEr, ROGUE [18] là có thể dùng để đánh giá chuỗi đầu ra có phù hợp không. Chúng ta sẽ đi sâu thêm vào từng chi tiết sau. Các task trong NLP thì là như vậy, dữ liệu, code và metrics hầu như có sẵn. Thì cũng là kết nối với Vision là khoảng CVPR tầm 2015-2016 gì đó có mấy cái Workshops nói về làm sao để có thể tích hợp nhiều modal (multi-modal) để đưa ra những giải pháp tốt hơn. Mọc ra trước mắt lúc đó thì có 3 tasks nằm trong định hướng: Image Captioning, Video-to-Text và VQA. Nói chung nghe lúc đó có vẻ mới, nhưng chỉ có task là mới thôi chứ còn những cái để thực thi những task ấy các sếp promote các task ấy lên họ đã chuẩn bị hết rồi. Technique thì có sẵn seq2seq, CNN, RNN, LSTM, Faster R-CNN để extract attributes dưới dạng object detections, …Metrics thì vì output vẫn là chuỗi text nên lại xài lại BLUE-4, CIDEr rồi ROGUE thôi. Nên coi như nền tảng rất sẵn rồi, chỉ nhảy vào làm thí nghiệm và viết paper rồi … ăn! Vậy tại sao vẫn cứ không đến nơi đến chốn được?  Tôi nghĩ vấn đề đầu tiên lúc làm Image Captioning là thiếu alignment.  Lúc làm cái Video-to-Text thì cái visual semantic embedding (VSE) là không có. Mà nói thẳng ra thì cái ấy chính mình chủ động nghĩ ra mà làm chứ? CÒn cái VQA thì lúc ấy nói thật là hai cái captioning với VTT nó đã bết bát sẵn rồi thì sẽ rất khó vì bản thân VQA tuy chỉ thay cái context là text bởi hình ảnh, nhưng chất lượng detector, rồi alignment mà hai bước trên chưa làm tốt thì sang đến VQA coi như … vỡ trận. Tuy nhiên, nếu ở vào vai trò anh Postdoc mà làm cái mảng này tôi vẫn sẽ đề xuất luồng làm việc Image Captioning --&gt; Video-to-Text --&gt; VQA. Bởi luồng làm việc này nó theo chiều hướng tích lùy dần know-how để làm việc ngày càng tốt hơn. Thứ hai, là vì nó có một vài điểm trigger giữa chừng nên nếu làm postdoc các bạn có thể submit bài báo tại các thời điểm ấy như là làm Image Captioning xong thì 1 bài, …Nhưng rốt cuộc cái quan trọng nhất vẫn là phải có làm có ăn. Còn không muốn làm thì hỏi giáo sư Huấn để biết phải làm gì. Recurrent Neural Nets, Long-Short Term Memory và Gated Recurrent Units: Thôi nói chung là cái trường hợp postdoc ở trên là một ví dụ điển hình thôi, mà trường hợp ấy tôi nghĩ đã được giáo sư Huấn chỉ bảo tận tình rồi nên không cần lo lắng nữa. Chúng ta quay lại với chủ để chính của hôm nay là giới thiệu về seq2seq. Để implement được seq2seq thì chúng ta cần 1 mô hình nhận chuỗi và output đầu ra cũng là một chuỗi khác, và quan trọng hơn là có thể huấn luyện bằng thuật toán Gradient Descent, cụ thể hơn là Stochastic Gradient Descent (SGD, [19]). Thì cái học củ SGD là mình chỉ random sample một phần của dữ liệu học để tính được gradient và update weight của model. Chúng ta sẽ có learning rate mà nhỏ thì chậm, còn cao quá thì mô hình sẽ khó hội tụ. Lời giải thì đơn giản nhất là có mô hình Recurrent Neural Nets (RNN, [20], [21]) mà mô hình và công thức forward pass như bên dưới: Công thức rất rõ ràng nên có thể sử dụng Numpy để implement forward pass khá đơn giản với vài dòng code chơi thôi. Cái khó khăn là khi đã tính xong kết quả các biến \(u_t, o_t, h_t, x_t\) và hàm loss \(\mathcal{L}\) thì làm sao update được các weight \(\mathbf{V}, \mathbf{W}, \mathbf{b}, \mathbf{c}\)? Thì có hệ thống các công thức phía dưới: Tuy hệ thống công thức này phức tạp hơn, nhưng vẫn có thể implement bằng Numpy và thực hiện train với SGD (tầm khoảng vài chục dòng code nữa). Nhìn lại thì công thức và cả phương thức implement RNN là cũng rất rõ ràng rồi, vì vậy, nếu không thể implement được thì … thày cũng chịu không thể giải thích tại sao được? Nhược điểm của RNN là vấn đề ghi nhớ long-term dependencies: ví dụ chúng ta có 1 gradient \(\mathbf{g}\) và giả sử là RNN không có non-linear activations nào thì chúng ta có thể giả sử thêm là cứ sau mỗi time step thì Jacobian matrix là \(\mathbf{J}\), vậy sau \(n\) bước thì gradient của chúng ta sẽ biến thành \(\mathbf{J}^n\mathbf{g}\) và nếu nó có một giá trị riêng \(\lambda\) mà giá trị khác \(\pm 1\), thì sẽ dẫn đến vấn đề là gradient triệt tiêu hoặc tiến ra vô cùng sau hữu hạn bước tính. Để khắc phục nhược điểm này thì một giải pháp được đưa ra là đưa self-loop vào cùng các non-linear gates như forget gate, output/input gates để control giá trị. Một kiến trúc đã làm được việc đó là Long-Short Term Memory (LSTM, [22, 23]). Mỗi cổng đều chứa sigmoid activation để đưa giá trị về khoảng \((0,1)\) dẫn đến các giá trị output ở các cổng có thể bị shut-off.  Việc thêm gates và non-linear activation (sigmoid) để control giá trị là hợp lý với LSTM. Tuy nhiên, nếu nhìn vào cái đám công thức thì trong LSTM khi update và forget của \(\mathbf{h}_{t+1}\) là đồng thời thực hiện song song việc forget và quyết định có update hay không. Gated Recurrent Unit (GRU, [24]) thực hiện chia ra, tức là thay vì 1 cổng là làm luôn cả hai chức năng, thì tạo 2 cổng update và reset cho từng mục đích ấy.  Nhìn chung, công thức toán của các kiến trúc RNN/LSTM/GRU đều không phức tạp. Nếu có thời gian, các bạn có thể tự thực hiện implement các kiến trúc trên bằng numpy. Forward pass thì chắc là đơn giản hơn, tuy nhiên backward pass với SGD thì sẽ đòi hỏi một chút công sức (vài chục dòng code nữa). Nói một chút về hàm loss \(\mathcal{L}\) khi train NMT chẳng hạn, vì chúng ta biết chuỗi đúng \(\mathbf{y}=(y_1,y_2,\ldots,y_n)\) nên ở mỗi step \(0\leq t\leq n-1\), ta sẽ xem xét vector output \(\mathbf{u}_t\) (là softmax) và lấy xác suất của vị trí thứ \(y_t\), và tất nhiên lấy log nghịch đảo như mọi khi: [\mathcal{L}=\sum_t-\log u_{y_t}] Khi testing, chúng ta sẽ sử dụng beam search để tìm ra các chuỗi phù hợp (sẽ giải thích thêm ở phần sau). Kiến trúc Seq2Seq (S2S): Training seq2seq đòi hỏi cần có GPU phù hợp và tận dụng xử lý song song. 1 đặc điểm không thể tránh khỏi của bộ dữ liệu là độ dài các chuỗi không đồng bộ, nên có thể tạo ra giải pháp là fill thêm ký tự trống vào để cho tất cả các chuỗi cùng độ dài. Việc này sẽ đòi hỏi thêm khá nhiều memory, vì vậy, một giải pháp khá phù hợp là chia ra thành các maxi-batches rồi trong từng maxi-batch thì lại chia tiếp thành các mini-batch. Trong mỗi mini-batch như hình dưới thì mới thực hiện fill ký tự trống.  Training seq2seq thường mất 5-15 epochs (1 lượt qua toàn bộ corpus). Bạn cũng nên thiết lập một tiêu chí dừng lại khi validation error rate không cải tiến thêm. Training lâu thêm không những không tạo thêm cải tiến mà có thể dẫn tới overfitting. Testing seq2seq. Giả sử chúng ta có một corpus 50,000 từ. Vậy trong vector \(\mathbf{u}_t\in\mathbb{R}^{50,000}\), ta sẽ chọn phần tử có xác suất cao nhất (dựa trên embedding logits) để output ra ở bước thứ \(t\). Giải pháp này tức là chỉ chọn cái tốt nhất ở mỗi bước. Vấn đề ở đây là nếu chỉ chọn cái tốt nhất độc lập ở từng bước thì khi đến một thời điểm \(t'\), câu dịch trở lên không đúng thì không thể quay lại sửa từ đầu được. Do đó, cách tốt hơn là dùng Beam Search:  Ở bước \(t=0\) chúng ta chọn một beam gồm \(n\) top words \(p(w_0^1), p(w_0^2), \ldots, p(w_0^n)\).  Ở thời điểm tiếp theo \(t=1\), ta lại chọn tiếp \(n\) top words \(p(w_1^1), p(w_1^2), \ldots, p(w_1^n)\) và làm tiếp:     nhân xác xuất của cụm 2 từ liên tiếp \(p(w_0^{i_0})p(w_1^{i_1}), 1\leq i_0, i_1\leq n\).    Chọn top \(n\) cặp từ \((i_0,i_1)\) giữ lại.     Ở thời điểm \(t=2\), ta lại chọn tiếp top \(n\) words \(p(w_2^1), p(w_2^2), \ldots, p(w_2^n)\), và lại nhân xác suất để tìm ra top \(n\) triplets \((i_0, i_1, i_2)\) để giữ lại trong beam.  Cứ tiếp tục như vậy đến khi gặp EOS thì bỏ câu dịch đó ra khỏi beam và giảm size của beam đi 1.  Khi kích thước của beam giảm xuống còn 0 thì dừng beam search. Một đoạn code demo của beam search: 400: Invalid requestNgoài ra, nếu có thời gian các bạn có thể tìm hiểu thêm các thủ thuật để tăng hiệu suất khi inference như fusion (ensembling), reranking, hoặc khi train như tăng kích thước vocabularies, training data, back translation, round-trip training, guided alignment training, . v. v… ([25]).  Tất nhiên, cũng cần chú ý là implement những cái này ở local cũng chỉ để học hỏi thôi nhé. Chứ còn triển khai vận hành thực sự thì nó có những solutions có sẵn chạy ầm ầm trên AWS/Azure/GCP rồi. Mà có khi nó còn thành dịch vụ đem bán khắp nơi rồi ấy chứ (có cả tiếng Việt luôn nhé). Transformers và BERT: Transformer [13]: Deep Networks nhưng không có RNNs hay CNNs gì cả!Transformer cũng có thể coi là một dạng seq2seq nhưng không chỉ gồm các tầng FC, embedding, …Điểm khác biệt là context (hay là attention) đã được chuyển thành tầng đề xuất self-attention. Nhìn chung, Transformer hay cả các kiến trúc BERT về sau cũng kế thừa tương đối nhiều tính chất của seq2seq. Bản thân Transformer cũng là seq2seq nhưng bỏ đi RNN/CNN. Trong kiến trúc thì ngoài residual connection chỉ có điểm đáng chú ý là multi-head attention. Như hình vẽ bên trái, có 3 vector mới được đưa ra là \(K, V, Q\), tương ứng cho keys, values, queries. Thì công thức attention (không có mask) sẽ như sau: [\mbox{Attention}\left(Q,K,V\right)=\mbox{softmax}\left(\frac{QK^\top}{\sqrt{d_k}}\right)V] trong đó, \(d_k\) là số chiều của vector query \(Q\) và key \(K\). Trong trường hợp dùng mask (ở decoder chả hạn) thì chủ yếu là để kết hợp với position embedding để hạn chế ảnh hưởng của các token trước thời điểm $t$ chả hạn. Nói chung lý thuyết của Transformer cũng không có gì quá phức tạp. Bản thân Transformer cũng đã được implement chi tiết trong thư viện tensor2tensor [26] nên như tôi đã nói, cái mảng này thực ra tài liệu tài nguyên thì vô cùng dồi dào. Ngoài ra một thư viện nữa là HuggingFace [27] với model zoo dồi dào cũng rất đáng xem. Thế là lại nói lại câu chuyện postdoc ở trên: không hiểu tại sao lại không làm được?  Thì tôi nghĩ là ngoài 3 yếu tố đã nói ở mục đầu, thì quá tập trung vào competition! Từ challenge mà người thày nói cũng có nghĩa là cuộc thi (competition) nhưng cũng có nghĩa là thử thách. Mà vấn đề là cái nghĩa sau nó sẽ quan trọng hơn. Bởi mảng nghiên cứu là giao thoa giữa Vision và NLP, nên là nếu chỉ tập trung vào 1 competition nhất định của vision mà không cập nhật bên NLP thì có vẻ là tầng nghĩa sau (thử thách) là sẽ bị lose track. Đấy thế nên là cũng nhắc lại lời người thày: “Thực ra nhiệm vụ của người làm thày là giảm bớt số lượng những con bò trên thế giới xuống”. Tôi nghĩ đúng là để biến một con bò thành người cũng khá vất vả, mà thất bại mãi mới thành công một phát cũng là chuyện thường!  Chốt là cuộc thi, competition là không quan trọng đâu. Cái quan trọng với postdoc là rèn luyện được một cái tác phong nghiên cứu tốt để có thể hướng tới lâu dài. Chứ mất công giành được vị trí trong 1 competition trước mắt, nhưng lại mất vị trí tenure cả đời thì luận về TRÍ là thua rồi!Đã xác định gắn bó lâu dài thì không cần thi cử gì cho mất thời gian ra, lo mà tìm ra cống hiến để đời và gắn bó lâu dài thì hơn. Mà nhìn lại tôi nghĩ nguyên nhân sâu xa dẫn tới sự vụ hậu quả postdoc kể trên là thiếu kỹ năng quản lý dự án (Project Management). Triệu chứng bệnh rõ ràng nhất ở đây là  Việc không quản lý được các tri thức về thử thách, dẫn đến bị đánh lạc hướng, sa đà vào các competition. Đây chính là triệu chứng bệnh thiếu kỹ năng quản lý scope dự án.  Việc không control được những lời khuyên từ bên NLP chứng tỏ có dấu hiệu yếu về quản lý stakeholder.  Việc ưu tiên competition trước việc nhận ra thách thức thực sự của mình chính là yếu về quản lý action plan, time và schedule. Nhìn chung việc thiếu kỹ năng quản lý dự án sẽ không bao giờ đưa người postdoc gia nhập nhóm (dưới) 5% thành công được. Mà ví dụ khoảng làm postdoc được 2-3 năm mà người thày nhìn vào thấy đủ thứ bệnh, chỗ nào cũng yếu thế này thì rất là khó để không cho … bật bãi!Ở Mỹ chả hạn, làm nghiên cứu muốn tồn tại lâu dài phải có kỹ năng quản lý dự án nghiên cứu. Thế mà chạy postdoc 2 năm mà không ngộ ra chân lý, không thể hiện tiềm năng làm quản lý lãnh đạo, thì không bật bãi chắc chỉ có ở thiên đường thôi! BERT: Bidirectional Encoder Representations from Transformers (BERT, [28]) lại là 1 kiến trúc mới gần đây (từ 2018?). Pretraining kiến trúc trên 1 task unsupervised (kiểu tự học), rồi dùng lại kiến trúc đó trong 1 task supervised khác là tư tưởng chính của BERT. Các phiên bản cải tiến của BERT có thể kể đến AlBERT [29], RoBERTa [30], BART [31], XlNet [32], XLM [33] hay gần đây là ELECTRA [34] đều kế thừa tinh thần này. Trong quá khứ thì việc sử dụng pretraining để tạo ra một xuất phát điểm tốt hơn cho model là ý tưởng đã được khai thác [35]. Ví dụ như Hinton thì đã pretrain deep belief nets và gọi là greedy layer-wise unsupervised pretraining. Thủ thuật này là cần thiết khi train các model lớn:  to train the first layer in isolation, then extract all features from the first layer only once, then train the second layer in isolation given those features, and so on. [21]. Ý tưởng của kiểu pretraining này là ta có một model rất lớn \(A\), việc train \(A\) từ đầu (random weights) sẽ rất khó. Do vậy, chúng ta sẽ tìm một task unsupervised \(u\) (vì vậy không cần labels), để train \(A\) trước. Sau đó, khi vào train cho task chính \(T\) (có labels) thì weights của \(A\) đã được khởi tạo bởi việc học \(u\) sẽ khiến training \(A\) cho \(T\) trở nên nhanh chóng hơn. Trên thực tế có khá nhiều task bên computer vision đã sử dụng ý tưởng này và đưa ra khá nhiều kết quả thuyết phục. Với bên NLP, thì BERT lựa chọn task pretraining (gọi là pretext) là masked language modeling (MLM). Ví dụ như trong câu 12Original: I have a pen &lt;EOS&gt;Masked: I &lt;MASK&gt; a pen &lt;EOS&gt;thì từ câu Masked, nhiệm vụ của pretext là phải phục hồi lại các từ bị &lt;MASK&gt;. Nguyên tắc pretext này nhìn chung giống với denoising auto-encoders [21]. Vì việc tạo bộ dữ liệu masking là dễ dàng và có thể tự làm được (viết script để ngẫu nhiên thay 1 token bởi &lt;MASK&gt;) nên task này có thể xếp vào hạng mục unsupervised learning hoặc self-supervised learning (SSL). Lợi thế là người train có thể tạo ra bộ dữ liệu lớn tự động để máy học pretext mà không cần gắn nhãn!Một pretext khác là đoán câu tiếp theo (Next Sentence Prediction, NSP). Ví dụ: 12I told the principal that I would like to revolutionize this university if he give me something to do. Next Sentence: He sent me to the Psychology department. Trong kết quả của BERT thì có vẻ pretext NSP giúp cải thiện độ chính xác của task QA. Tất nhiên, ngoài dùng pretext thì còn những kiểu pretraining khác như sử dụng feature đã pretrain (ELMo, [36]) hoặc fine-tune toàn bộ pretrain parameters (OpenAI GPT, [37]). Gần đây có model BART [31] tích hợp cả BERT và GPT để tạo ra một cơ chế pretext có thể mô phỏng hàm noise bất kỳ. Hầu hết những phương pháp kể trên đều có thể tìm thấy tại thư viện model HuggingFace [27]. Ứng dụngCách tiếp cận: Các nguồn tài nguyên: Như đã nói ở trên, mảng này thì code kiếc, tài liệu, tài nguyên thì vô cùng sẵn có và dồi dào. Thế nên thôi mình cứ ăn “sẵn” đi cho nó nhanh chứ nấu làm gì mất thời gian.  Nó cũng kiểu như đồ ăn Tết ấy mà: Hì hục nấu mất cả buổi mà ăn thì chắc được mấy miếng là chán. Thế nên tôi mới bảo rồi, những cái này mà mở khóa học truyền bá tri thức phổ cập thì liệu có khách không? ai học cho mà dạy?  Tôi nghĩ chả ai học đâu, giờ người ta ăn sẵn hết. Có dạy “nấu” thì cũng phải cái gì mà nó kiểu sẵn sẵn mà nấu nhanh ăn luôn. Thì tại sao nói mảng này đồ ăn sẵn nhiều thì dưới đây là một số nguồn mà các bạn có thể tận dụng:  Code thì HuggingFace, tensorflow, Github Model Zoo thì HuggingFace thôi.      https://huggingface. co/   Cứ tải về mà hì hục “nấu”.    Nấu xong chắc cũng chỉ chạm đũa vài miếng là ngấy thôi nhưng nếu thích nấu thì nấu thôi.     Tài liệu tutorials thì cứ search YouTube là ra hết mà.      Kênh hướng dẫn của HuggingFace   The Future of Natural Language Processing    Nguồn tài nguyên tính toán:     Đầu tiên cũng chả cần mua GPU/TPU riêng đâu.    Để làm demo bạn cứ xài tạm Colab ấy.          https://colab. research. google. com/     Một playlist hướng dẫn dùng Colab với Tensorflow          Đôi lời về Google Colab:  FAQ What is Colabotory?  Colaboratory, or “Colab” for short, is a product from Google Research. Colab allows anybody to write and execute arbitrary python code through the browser, and is especially well suited to machine learning, data analysis and education. More technically, Colab is a hosted Jupyter notebook service that requires no setup to use, while providing free access to computing resources including GPUs. Google Colab nhìn chung là 1 dịch vụ Notebook cung cấp sẵn môi trường để chạy các tác vụ liên quan tới machine learning. Với Colab, bạn có thể định nghĩa form các biến chương trình như hình bên dưới, rồi tạo lập mạng trí tuệ nhân tạo, thiết lập môi trường GPU/TPU để training hoặc inference.  Sau khi đã làm quen với môi trường Google Colab thì bạn đã all-set to go! Chú ý về train song song: Một chú ý nhỏ mang tính hô trợ trong quản lý time thôi là nếu bạn chọn Colab Free plan thì GPU/TPU tốc độ khá thấp. Ngoài ra, bộ dữ liệu hạng vừa như WMT 2014 thì cũng có 4,468,840 cặp câu dịch (bộ training set). Mà Colab Free thì tốc độ training sẽ rơi vào tầm 18-20 FPS với model AlBERT, như vậy để train hết 1 epoch với WMT sẽ mất tầm 62-70 (h), tức là khoảng 3 ngày/epoch (liên tục). Mà để train model NMT thì sẽ mất 5-15 epochs nên sẽ phải mất tầm 15-45 ngày train liên tục. Tuy nhiên, Colab Free có giới hạn là 1 session chỉ được 12h liên tục, nên bạn sẽ phải break ra tầm 30-90 sessions. Ngoài ra đóng browser là mất luôn đấy chứ nó lại không chạy ở background đâu. Bài viết này chỉ sử dụng có sẵn với viết script để demo inference hoặc show training vài step nó như thế nào thôi, nên chúng tôi cũng chỉ cần Colab Free là đủ. Tuy nhiên, nếu mà các bạn định làm nghiêm túc kiểu hì hục nấu cả buổi thì tôi nghĩ là nếu dùng GPU thì dưới 8 GPUs là hì hục lâu phết đấy!Có mấy giải pháp:  Nâng cấp nên Colab Pro (10USD/tháng) và Pro Plus (50USD/tháng). Tuy nhiên, dù lên Pro Plus thì 1 session cũng chỉ được 24h liên tục. Được cái là cho phép chạy background nên sẽ dễ thở hơn. Có điều là 24h thì lại phải save ra Google Drive, rồi khởi động lại training bằng tay. GPU/TPU sẽ nhanh hơn tầm vài lần nên có thể sẽ chỉ mất vài tuần để train thôi. Hì hục nó là thế đấy! Tự chế ra 1 hệ thống multi-GPU: kiếm kinh phí mua tầm 24 cái GPUs P100 thì có khi 1 epoch mất 1h thôi, thì train trong ngày sẽ xong. Giá cả thì Tesla P100 SXM2 16GB tầm 10,000 USD/cái, 24 cái thì tầm 240,000 USD thôi! Muốn làm big data mà chỉ code thôi là không ăn thua đâu! Bởi vận hành triển khai mỗi tháng hóa đơn đã vài chục ngàn đô, tiền upfront mua GPU cũng đã 240,000 USD thì code hầu như là phần ít giá trị nhất! Code nói chung … rẻ mạt! Thuê EC2: thì có vài lựa chọn là on-demand và reserved.      reserved thì 1 tháng 30 ngày 720 h là mình phải trả hết 720 h. Thì rẻ nhất là g5. xlarge cũng mỗi giờ 0. 63 đô. Như vậy là mỗi tháng \(0. 63 \times 720 = 453. 6\) USD/tháng. Tuy nhiên, g5. xlarge chỉ có 1 GPU và tính năng thì xấp xỉ Colab Free, nên giả sử train 15 epochs mất 45 ngày liên tục, thì sẽ tốn là \(0. 63 \times 45 \times 24 = 680. 4\) USD cho lượt train này.          Nếu thuê GPU tốt hẳn đi là g5. 48xlarge coi như 8 GPUs thì nhanh hơn tầm 8 lần thì giá reserved sẽ là \(10. 26 \times 45 \times 24 /8 = 1385. 1\) USD cho lượt train. Tuy nhiên, vì reserved nên mình thuê theo tháng thì ngoài lượt train này, hàng tháng mình tổng phải trả là \(10. 26 \times 720 = 7387. 2\) USD/tháng. Tức là train được tầm 6 lượt WMT 2014.           Thuê on-demand thì mình không trả hàng tháng, dùng phát nào xong trả phát ấy thôi. Thì ví dụ, g5. 48xlarge thì sẽ mất \(16. 29\times 45 \times 24 /8 = 2199. 5\) USD cho mỗi lượt train này kéo dài tầm gần 1 tuần.    Thuê Spot thì có thể thuê loại g5g. 16xlarge thì có 2 Tensor core và mất 1. 1112 USD/h. Nhìn chung Spot giá sẽ mềm hơn on-demand và cùng hạng với reserved. Tuy nhiên, vì là spot nên lúc nào mà tự dưng bị interupt là phải có kế hoạch ứng phó trước:         Spot Instances are a cost-effective choice if you can be flexible about when your applications run and if your applications can be interrupted           Như các bạn đã thấy ở trên: cùng mức GPU g5. xlarge thì Colab Free còn thuê EC2 mất 453. 6 USD. Vậy sự khác biệt là gì? Điểm khác chính yếu là thuê EC2 thì bạn không phải lo cái session 12 h (sau 12h phải khởi động lại bằng tay và save dữ liệu vào Google Drive). Tức là chỉ mỗi cái limit 12h ấy thôi đã trị giá 453. 6 USD rồi. Một điểm đáng lưu ý thứ 2 là giới R&amp;D cạnh tranh khá khốc liệt, nên trên thứ vô thưởng vô phạt kiểu này thì kéo dài 45 ngày và free cũng được. Nhưng cái gì mà có giá trị kinh tế một chút là cạnh tranh ác liệt: train là phải xong trong ngày, chứ đợi cả tháng sau có đứa nó publish mất thì sao?Thế nên tôi nghĩ nếu thực sự phải cạnh tranh thì chắc lại 240,000 USD hoặc g5. 48xlarge thôi. Và nếu chọn con đường cạnh tranh này thì các tập đoàn lớn, có sẵn hàng chục cái GPU server trong tay muốn huy động lúc nào cũng ok em thì chắc chắn là thắng thế. Nên cạnh tranh vào cái con đường kiểu đọ thông số GPU này có lẽ là chỉ dành cho tập đoàn lớn thôi. Thứ 3 nữa là tự chế 240,000 USD thì mới là DIY và self-supervised chứ còn thuê với Colab thì đâu còn là self nữa nên rốt cuộc là chắc cũng quay lại 240,000 USD nếu thực sự là self. Neural Machine Translation (NMT): NMT là 1 bài toán NLP khá điển hình. Lần này chúng ta sẽ chạy thử 1 vài mô hình trên HuggingFace để dịch tiếng Đức sang tiếng Anh. Đầu tiên, là với mớ lý thuyết phía trên, chúng ta sẽ xem thử cách thức fine-tune model AlBERT cho task NMT. Tôi dùng bộ dữ liệu WMT 2014 để show: 400: Invalid requestNhìn chung, cứ setup đúng các thông số, tokenizer, hàm loss, optimizer, . v. v… thì hầu như quá trình fine-tune mô hình kiểu BERT diễn ra rất trôi chảy. Vấn đề tài nguyên để kết thúc quá trình train thì như thảo luận ở trên, các bạn có thể tự lựa chọn giải pháp phù hợp túi tiền. Nói chung nấu cả buổi nhưng ăn thì nhanh thôi. Để demo chức năng dịch Đức-Anh thì tôi xài luôn model có sẵn google/bert2bert_L-24_wmt_de_en. 400: Invalid requestTôi cũng sử dụng sacrebleu để show được điểm số BLEU của vài câu dịch. Text Summarization: Bài toán Text Summarization (TS), yêu cầu đưa ra một đoạn tóm tắt ngắn gọn của 1 văn bản dài. Có khá nhiều bộ dữ liệu hỗ trợ việc training một model như vậy [38]. Trong bài này, tôi chọn 1 bộ nhỏ vừa là bộ WikiHow [39] với tầm 240,000 cặp bài báo-tóm tắt. Về mặt model, thì có khá nhiều hệ thống state-of-the-art và là seq2seq cho abstractive TS như NAM [7], Encoder-Decoder RNN [40] hay BART [31]. 400: Invalid requestNhìn chung, tuy WikiHow số lượng cặp dữ liệu ít hơn WMT14 (240,000 vs. 4,500,000) nhưng mỗi cặp dữ liệu lại là hẳn 1 bài dài, nên kết cục là cùng 1 GPU Colab Free thì thời gian train vẫn mất 49h/epoch. Tức là cứ 1 epoch 2 ngày, và train khoảng 15 epochs thì mất tầm 30 ngày (hay 1 tháng, tính cả nghỉ lễ, T7/CN).  QA và VQA: Nếu bạn đã làm bài thi TOEIC reading and listening thì cũng dễ giải thích bài QA và VQA thôi. Task QA là 1 bộ phận trong task lớn Reading Comprehension (RC): cho 1 bài báo (có thể kèm hình ảnh), người/máy sẽ đọc rồi trả lời 1 câu hỏi liên quan tới bài viết đó. Bài báo làm reference được gọi là context, một ví dụ điển hình:  Context: I live in Japan. Question: Where do I live?Answer: Japan. Dạng đơn giản nhất là như vậy chỉ cần đọc kỹ và paraphrasing lại cụm từ có sẵn trong context thôi. Đây là dạng extractive QA tức là chỉ đơn giản skim bài viết và quote lại thôi. Bộ dữ liệu đại diện cho kiểu extractive QA này là SQuAD v1 [4] và v2 [17]. Tuy nhiên, nếu bạn làm bài thi TOEIC bạn sẽ hiểu là có cả những câu hỏi mà không chỉ paraphrasing mà phải suy luận. Đây gọi là abstractive QA, điển hình cho dạng này là bộ TweetQA [41]. Như ở ví dụ bên tay trái, bạn có thể thấy cần phải để ý chi tiết và suy luận thì mới trả lời được. Ví dụ bên dưới là 1 model Abstractive QA dựa trên AlBERT: 400: Invalid requestĐể đánh giá, có thể dùng các metric như ROUGE-L hoặc METEOR. Visual Question Answering (VQA, [5, 6]) thay context bởi 1 hình ảnh hoặc video. Tức là giống câu hỏi bài nghe thứ nhất trong thi TOEIC (nhưng TOEIC thì không có xem video). Thì nói chung cũng đa dạng đấy!Vì câu hỏi thì cũng tùy vào mức độ hình ảnh mà đánh đố hay không đánh đố. Thì làm sao để thấy được sự khác biệt với QA của bên NLP thì chắc là các bạn xem hình ảnh bên trái (lấy từ [42, 43]) thì sẽ hiểu ngay. Mà tôi nghĩ cũng chỉ nhìn vào mỗi cái hình này là cũng hiểu được là how and why như thế nào rồi đấy. Dưới đây là bức tranh lớn trong mảng VQA (tập hợp qua các bài trên 300 citations). Tuy chỉ là một mảng nhỏ, nhưng cái scene này nhìn cũng là 1 graph phức tạp phết! Cũng không nên quên là cách tiếp cận của nhân vật chính postdoc trong bài này là seq2seq, mà nói chung là mảng giao giữa với vision và language nên tôi nghĩ là tiếp cận theo cách nào cũng sẽ đi đến cái chỗ nó như vậy thôi. Vậy chúng ta lại cứ bám sát vào seq2seq nhé (mà hậu duệ là Transformers, BERT là những cái tôi thấy có vẻ cũng bắt đầu lấn sân sang Vision gần đây rồi).  Điểm khác biệt lớn nhất giữa vision và language chính là ORDER. Nếu như đơn vị trong language là words được sắp xếp theo order thành phrase và sentence, words được extract từ documents nhờ tokenizer. Trong hình ảnh, có một sự mapping với language, và cái hướng này cũng có mấy nhóm cũng rất mạnh đang làm chủ công nghệ này. Ví dụ, word, phrase &lt;-&gt; visual conceptscòn tokenizer &lt;-&gt; classifier, object detectors, visual relation detectors, . v. v…Nói chung, bên vision cũng có đủ những “vũ khí” tương xứng để extract tokens và feed vào seq2seq models. Tuy nhiên, vấn đề chính là order: cùng trong một hình ảnh, có thể extract ra 2 vật thể, nhưng khi xếp vào 1 câu văn thì thứ tự nào cũng có khả năng cả. Nó khác language là ORDER đã được input sẵn, còn vision thì không. Vấn đề order cũng không phải mới mà được xem xét ngay từ 2015 (seq2seq for sets, [44]). Tuy nhiên, họ cũng chỉ dừng ở mức chọn 1 thứ tự nhất định để bắt đầu và optimize thứ tự đó trong quá trình training. Đó cũng là tinh thần của hầu hết các ứng dụng vision-language về sau có dùng seq2seq và attention như image captioning, Video-To-Text (VTT) và VQA. Một cách giải quyết khác chính là tìm một representation tốt hơn cho set. Vì set trong vision không phải sequence trong NLP nên vấn đề sẽ xảy ra khi dùng representation mới là seq2seq sẽ phải thay đổi để phù hợp với representation mới. Trong những publication gần đây, một set representation phù hợp là graph. Vấn đề là graph không phải sequence nên seq2seq cũng thay thế bằng graph neural networks (GNN).  Là người thày, có thể không trực tiếp bắt tay vào làm, nhưng phải định hướng. Vì vậy không thể định hướng một hướng đi “cụt”, chỉ làm 1 đời postdoc là hết. Định hướng, đôi khi dù 10 đời postdoc không làm gì thì cũng không thể hết việc được, mới là định hướng tốt. Thậm chí, nếu postdoc mà chịu khó làm thì còn sinh sôi nảy nở ra làm mãi không hết. Vision-Language (VL) nhìn chung là 1 định hướng lâu dài như vậy.  Làm người trò, thì khi bắt đầu dự án không nên quá thụ động. Việc representation có thể phải thay đổi giữa chừng (từ sequence sang graph) là chuyện nếu không nhìn ra ngay từ đầu,có thể dẫn đến dự án bị đình chỉ giữa chừng. Làm postdoc như vậy là yếu về quản lý rủi ro. Nhìn chung vẫn là nghiệp vụ quản lý dự án (Project Management) vẫn còn chưa mạnh. Nhìn chung, mảng Vision-Language (VL) này tôi thấy còn nhiều dư địa cả về lý thuyết lẫn ứng dụng:  Về lý thuyết, cái representation vẫn còn chỗ làm. Ứng với mỗi representation có thể sẽ phải thu thập dataset và gắn nhãn riêng. Xây dựng model mới hẳn cho graph và seq2seq.  Về ứng dụng, VQA hiện tại vẫn chỉ là closed form: xem 1 hình ảnh và extract concepts rồi dùng kỹ thuật QA để trả lời nội dung trong ảnh, tức là chưa phải dạng suy luận nhiều. VQA ở dạng open hơn sẽ thay context không chỉ bởi 1 hình ảnh hay 1 video, mà bởi 1 multimedia database, cũng như trong trò chơi tỷ phú, mỗi câu hỏi không chỉ đòi hỏi phải xem 1 context nhất định mà phải search trong 1 database knowledge mới có thể trả lời được.      Một bước đơn giản hơn chỉ là thay context hình ảnh bởi context video, và câu hỏi là về 1 details nào đó: ví dụ show cho máy một video nấu ăn, và hỏi Tại sao lại cho hành vào phi trước?.    Thay vì giới hạn luật chơi rằng máy chỉ được xem context là 1 bài báo, 1 hình ảnh, 1 video cụ thể, thì nhưu IBM Watson hay Siri, cho phép máy kết nối Internet và có thể query trong cả 1 multimedia database lớn, thì QA sẽ như thế nào?   Tuy vậy, với công nghệ hiện tại cũng đủ để làm 1 demo nho nhỏ dạng: cho máy xem 1 hình ảnh, và đặt 1 vài câu hỏi xung quanh nội dung hình ảnh và không cho máy kết nối Internet, thì máy cũng có thể trả lời ở mức độ nhất định. Tức là có thể lấy điểm bài nghe số 1 của TOEIC! Đánh giá về tiềm năng bài toán VQA, thì tôi thấy cái mảng này nó cũng dồi dào, code kiếc cũng thừa mứa trên Github, kiểu như HuggingFace ý: classifier thì có TIMM [45], detector thì có Detectron2 [46] hay MMDetection [47], segmentations thì có [48], visual relationship detector (VRD) thì cũng tràn lan vì các tác giả cũng công bố hết lên Github. Thế nên là những cái low-level detector kiểu visual tokenizer là sẵn có, mà người ta công bố mà mình không dùng thì cũng phí. Mà vấn đề là của người ta chất lượng nó cao. Dữ liệu thì cũng công bố sẵn có hết, bộ dữ liệu VQA hay commonsense hay Visual Genome [49] thì nhìn chung cũng tầm triệu câu hỏi, với vài trăm ngàn hình ảnh. Đấy vấn đề với quy mô dữ liệu này thì lại quay về bài toán 240,000 USD thoai!Đấy, mấy cái mảng này nó toàn kiểu code kiếc, dữ liệu thì bằng cho không trên Github rồi, nhưng vấn đề là để chạy được thì hàng trăm ngàn đô. Các bạn thấy có những nhóm nó chịu khó train để ra model công bố thì toàn 8 GPUs mà cũng hì hục train 1 tuần. Có cái train ImageNet trong 1 giờ [50] thì lại là họ dùng những 256 GPUs mà họ có được nguồn tài nguyên ấy là nhóm của … Facebook!Nên tôi nghĩ khi làm postdoc mà không kiểu có estimate trước thời gian train là lại … giữa chừng đứt gánh vì … không có tiền!Mà không có tiền thì đấy như ví dụ postdoc của chúng ta là lặng lẽ giải tán rồi!  Chứ không có tiền thì thày cũng không có, trò cũng không có thì nhìn nhau … cười à?  Mà vì tài nguyên cái mảng này nó tràn lan trên Github nên có bảo tôi code thì lấy code làm công cũng không được vì cùng cái code trên mạng Internet nó nhan nhản ra, code nói chung là rẻ mạt!Cái quan trọng là vượt qua cái khó khăn như 240,000 USD và ra được sản phẩm thoai! Video-to-Text và Image Captioning:  Training on videos used standard SGD with momentum set to 0. 9 in all cases, with synchronous parallelization across 32 GPUs for all models except the 3D ConvNets which receive a large number of input frames and hence require more GPUs to form large batches – we used 64 GPUs for these. We trained models on on Kinetics for 110k steps, with a 10x reduction of learning rate when validation loss saturated. We tuned the learning rate hyperparameter on the validation set of Kinetics. Models were trained for up to 5k steps on UCF-101 and HMDB-51 using a similar learning rate adaptation procedure as for Kinetics but using just 16 GPUs. (trích dẫn [51]) Vấn đề gì trong đoạn văn trên?  Thứ nhất, UCF-101 và HMDB-51 là những bộ dữ liệu nhỏ nhưng họ cũng phải dùng tới 16 GPUs để train. Thì gọi cho 16 GPUs sẽ nhanh lên tầm 1s/iteration thì train 5k steps mất tầm 1h-2h. Thì với bộ dữ liệu nhỏ như vậy là ổn.  Tuy nhiên, với bộ dữ liệu lớn như Kinetics thì họ phải inputs hàng triệu frames, và để nhanh thì bắt buộc dùng tới 32, thậm chí 64 GPUs để train. Gọi cho là dùng 64 GPUs thì sẽ train nhanh đi thì 1s/iteration thì 110k steps cũng mất 1-2 ngày.  Nhưng nên nhớ họ có 64 GPUs nhé, chứ còn chỉ có 1-2 GPUs thì xác định mất 1-2 ngày x 30 lần tức là train mất 1-2 tháng (không ngủ nghỉ gì cả, T7/CN nghỉ lễ cũng train). Bài toán Video-To-Text hay Video Captioning, Video-Text Retrieval đòi hỏi cần có những biểu diễn phù hợp cho cả vision lẫn language. Về mặt vision thì có mấy cái hệ biểu diễn C3D/I3D như trên. Nhìn chung có thể dùng seq2seq hoặc BERT để learn được những biểu diễn như vậy và input vào seq2seq để xuất ra captions.  Nhưng nhìn chung, độ khả thi của đề xuất này vẫn phụ thuộc con số 16-32-64 GPUs ở trên. Thày nghèo với thày giàu là có phân biệt đấy. Nói chung làm hình ảnh thì dưới 8 GPUs không nên theo. Nhưng video thì dưới 16 GPUs thì cũng không nên train triếc mất thời gian. Mà thày nào dưới 16 GPUs thì cũng không nên theo nếu bạn định train. Các bạn cũng cần hiểu, đó là nguồn tài nguyên trong một lab nghiên cứu luôn là mua chung cho cả lab, chứ không phải cho 1 anh postdoc cụ thể nào. Ví dụ postdoc muốn xin dùng hệ thống 8 GPUs của thày tầm 1 ngày 2 ngày thì còn ổn. Chứ postdoc mà muốn chiếm hẳn 1 tuần để train model video captioning thì tự dưng nó nảy sinh ra rất nhiều vấn đề khác. Nên là nếu bạn chọn vào chỗ nghèo quá ấy, thì liệu cơm gắp mắm, nhưng tốt nhất đừng có train gì cả. Bây giờ làm việc bên mảng vision này, đặc biệt là video, thì tự dưng lại phải ngồi build cả 1 hệ thống GPU server 16-32-64-128-256 GPUs để cho đệ tử nó dùng. Nên là trước khi bắt đầu dự án, việc lên kế hoạch mua sắm, build server các cái là phải chuẩn bị từ trước hết.  Chứ không chạy đến giữa chừng lại ngậm ngùi giải tán vì … không có GPUs (mà thực ra là không có tiền) để chạy thì còn ra cái thể thống cống rãnh gì nữa? Image Captioning thì cũng dùng RNN/LSTM và Attention từ lâu rồi. Nhìn chung, cái mảng này vẫn là cuộc chơi của người giàu. Mà độ giàu của ông thày là số lượng GPUs mà lab thày sở hữu. Bây giờ, postdoc có ý tưởng, postdoc có đề tài, postdoc lên kế hoạch, postdoc tính toán tỷ mỷ số lượng tài nguyên cần thiết. Thế bây giờ, postdoc là người chọn thày chứ không phải thày chọn postdoc. Thì quay lại trường hợp postdoc của chúng ta:  Tại sao lại chọn chỗ nghèo như vậy? Chưa đi ra đến chợ mà đã hết tiền như thế thì làm thế nào cạnh tranh nổi trong giới postdoc?Mà đã thấy không có tiền thì đổi đề tài cho nó phù hợp, làm cái task khác nó không cần tiền đi. Tất nhiên là người nghèo lại làm task không có tiền thì lại thành … nghèo bền vững thôi!Nói chung là ngay từ bước quản lý tài nguyên, một phần trong nghiệp vụ quản lý dự án là đã có vấn đề. Kết luậnVề seq2seq trong NLP: Nhìn chung về mấy task bên NLP, thì tất nhiên bài viết này cũng chỉ là 1 phần (bao gồm task NMT/TS/QA với mấy cái tự học) còn nhiều task khác như POS Tagging, semantic roles, …Tuy nhiên, nhìn chung những tiến bộ trong mảng NLP đã được tóm tắt, và có vẻ cũng không khó khăn lắm đâu.  Có làm thì sẽ có ăn thôi, còn không làm mà đòi có ăn thì … Cũng xoáy kha khá cái trường hợp postdoc, nhưng tôi nghĩ là cứ chuyển hết cho Prof. Huan Rose chỉ bảo là ok thôi. Nói chung phần kỹ thuật thì không có nhiều điểm khó, nhưng cái khó nhất chắc vẫn là cái 240,000 USD thôi. Mà cái đó thì chắc chắn không phải là cái anh em kỹ thuật có thể giải quyết nổi.  Nên nếu không có tiền thì … giải tán thôi, chứ biết làm thế nào bây giờ?Cái này có đố cũng chịu!Như bình thường thì có thể đổi sang làm những cái bài toán mà nó train phát xong luôn, dùng luôn, những bài toán mà nó có thể chạy chỉ cần CPU, thậm chí chỉ mấy cái device nhỏ nhỏ cũng chạy được ấy. Nên tôi nghĩ cũng không cần xoáy nhiều vào cái đám big data nữa:    Xin vô mấy cái tập đoàn lớn đùng ấy mà làm, nó có nhiều người dùng nó sẵn sàng chi tiền tấn ra mà mua. Ví dụ, các anh em thử nghĩ xem mấy cái papers nhiều citation của cái mảng này làm thí nghiệm toàn hàng trăm GPU, TPU thì tác giả toàn nhóm của những công ty như thế nào? phải Google, Facebook, … chứ như anh em chân đất mắt toét thì chờ nó ra model rồi dùng lại, chứ mất công hì hục nấu nướng làm gì cho mất thời gian.   Chuyển sang làm mấy cái thiết bị nhỏ nhỏ mà làm. Mà chấm dứt suy nghĩ về GPU với mấy cái model to đùng, nấu thì lâu mà ăn thì chóng đi.  Về chuyện tài nguyên training: Các bạn có thể thấy điển tích 240,000 USD xuất hiện khá nhiều trong bài viết. Nói chung mảng này lúc bắt đầu làm postdoc hay dự án nghiên cứu mà không nhìn trước được những khó khăn điển tích này thì kỹ năng quản lý dự án là kém. Chứ chạy đến giữa postdoc lại ngậm ngùi giải tán vì … không có tiền thì còn ra thể thống gì? Thứ hai là nếu bạn đã xác định đi con đường train triếc mất thời gian này thì điều tra kỹ về lab hoặc nhóm mình vào:  Nếu thày có ít hơn 8 GPUs (mà phải là GPU xịn khỏe nhé chứ GPU đểu thì cũng nhiều mà) thì đừng vào lab ấy làm gì, vì cơ sở hạ tầng của lab không có và lúc làm bạn phải tự lo tự chạy đấy. Trong trường hợp thuê thì thày phải có ngân sách và chịu chi. Thứ ba là tốt nhất là nên chọn mấy cái đề tài không cần train, hoặc có train thì cũng tí là xong. Đấy mấy cái Random Forest, mấy cái model nhẹ nhàng train vèo phát xong. Rồi mình làm mấy cái deploy lên thiết bị nhỏ nhẹ, vừa khỏe vừa có tiền, cả nhà đều vui :))  Cách đây ít lâu, tôi có làm phỏng vấn tuyển dụng, có bạn trẻ “thị uy” với tôi là từng làm việc với hệ thống 24 GPUs. Tôi cũng thú nhận là chỗ chúng tôi không train gì hết, chỉ vào làm luôn inference nhỏ nhẹ, vừa khỏe vừa vui thôi. Nên nếu bạn mà định kiểu dành hàng tuần ngồi train thì chúng tôi không đáp ứng được. Thế nên chốt lại là tốt nhất là nên chọn hướng đi ít train thôi. Còn nếu chọn con đường train nhiều tốn kém thì PHẢI CÓ TIỀN vì đây là cuộc chơi của người giàu! Về các task vision-language: Thật thú vị là cùng thời điểm khoảng 2015-2016, bên vision cũng xuất hiện 1 loạt task kế thừa seq2seq và đến bây giờ vẫn phát triển song song và lấy những công nghệ tiên tiến nhất của bên NLP như Transformers hay BERT về để ứng dụng. Thì họ cũng làm lên một nhánh vision-language learning (VL learning), với những task thú vị như VQA, VTT, image captioning, video/image-text retrieval. Nhìn chung là thú vị, nhưng có một số vấn đề như representation, thì đặc điểm của set nên có những biểu diễn mới như graph hay 3D (C3D/I3D). Nếu làm một kế hoạch nghiêm chỉnh cũng có thể làm ra một cái postdoc tốt nhưng không hiểu sao ngày ấy lại không đi đến đâu cả. Mà cuối cùng ấy, tôi nghĩ có nhiều nguyên nhân như phân tích ở trên, nhưng một nguyên nhân tuy nói ra hơi phô nhưng mà thật:  Không có GPUs! Cái này cũng thể hiện sự yếu kém về mặt nghiệp vụ quản lý dự án (liên quan tới quản lý scope, tài nguyên và kế hoạch). Nhìn chung cũng là một bài học kinh nghiệm quý báu. Tôi nghĩ vẫn có nhiều điều đáng lưu ý để thế hệ sau không vấp phải. Tài liệu tham khảoKalchbrenner, N. and Blunsom, P. 2013. Recurrent continuous translation models. Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing (EMNLP), Seattle, USA. Association for Computational Linguistics (2013). DetailsSutskever, I. , Vinyals, O. and Le, Q. V. V. 2014. Sequence to sequence learning with neural networks. Advances in Neural Information Processing Systems (2014), 3104–3112. DetailsCho, K. , Merrienboer, B. van, Gulcehre, C. , Bougares, F. , Schwenk, H. and Bengio, Y. 2014. Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation. arXiv preprint arXiv:1406. 1078. (2014). DetailsRajpurkar, P. , Zhang, J. , Lopyrev, K. and Liang, P. 2016. SQuAD: 100,000+ Questions for Machine Comprehension of Text. Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing (2016), 2383–2392. DetailsAntol, S. , Agrawal, A. , Lu, J. , Mitchell, M. , Batra, D. , Zitnick, C. L. and Parikh, D. 2015. Vqa: Visual question answering. Proceedings of the IEEE international conference on computer vision (2015), 2425–2433. DetailsGoyal, Y. , Khot, T. , Summers-Stay, D. , Batra, D. and Parikh, D. 2017. Making the v in vqa matter: Elevating the role of image understanding in visual question answering. Proceedings of the IEEE conference on computer vision and pattern recognition (2017), 6904–6913. DetailsRush, A. M. , Chopra, S. and Weston, J. 2015. A Neural Attention Model for Abstractive Sentence Summarization. Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (2015), 379–389. DetailsRanzato, M. A. , Chopra, S. , Auli, M. and Zaremba, W. 2015. Sequence level training with recurrent neural networks. arXiv preprint arXiv:1511. 06732. (2015). DetailsVenugopalan, S. , Rohrbach, M. , Donahue, J. , Mooney, R. , Darrell, T. and Saenko, K. 2015. Sequence to sequence-video to text. Proceedings of the IEEE international conference on computer vision (2015), 4534–4542. DetailsYou, Q. , Jin, H. , Wang, Z. , Fang, C. and Luo, J. 2016. Image captioning with semantic attention. Proceedings of the IEEE conference on computer vision and pattern recognition (2016), 4651–4659. DetailsJohnson, J. , Karpathy, A. and Fei-Fei, L. 2016. Densecap: Fully convolutional localization networks for dense captioning. Proceedings of the IEEE conference on computer vision and pattern recognition (2016), 4565–4574. DetailsLuong, M. -T. , Le, Q. V. , Sutskever, I. , Vinyals, O. and Kaiser, L. 2015. Multi-task sequence to sequence learning. arXiv preprint arXiv:1511. 06114. (2015). DetailsVaswani, A. , Shazeer, N. , Parmar, N. , Uszkoreit, J. , Jones, L. , Gomez, A. N. , Kaiser, Ł. and Polosukhin, I. 2017. Attention is all you need. Advances in neural information processing systems (2017), 5998–6008. DetailsBojar, O. , Buck, C. , Federmann, C. , Haddow, B. , Koehn, P. , Leveling, J. , Monz, C. , Pecina, P. , Post, M. , Saint-Amand, H. and others 2014. Findings of the 2014 workshop on statistical machine translation. Proceedings of the ninth workshop on statistical machine translation (2014), 12–58. DetailsBojar, O. , Chatterjee, R. , Federmann, C. , Graham, Y. , Haddow, B. , Huang, S. , Huck, M. , Koehn, P. , Liu, Q. , Logacheva, V. and others 2017. Findings of the 2017 conference on machine translation (wmt17). Proceedings of the Second Conference on Machine Translation (2017), 169–214. DetailsOver, P. and Yen, J. 2014. An Introduction to DUC-2004. https://duc. nist. gov/pubs/2004slides/duc2004. intro. pdf. DetailsRajpurkar, P. , Jia, R. and Liang, P. 2018. Know What You Don’t Know: Unanswerable Questions for SQuAD. Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers) (2018), 784–789. DetailsLin, C. -Y. 2004. Rouge: A package for automatic evaluation of summaries. Text summarization branches out (2004), 74–81. DetailsBottou, L. and Bousquet, O. 2007. The tradeoffs of large scale learning. Advances in neural information processing systems. 20, (2007). DetailsRumelhart, D. E. , Hinton, G. E. and Williams, R. J. 1986. Learning representations by back-propagating errors. nature. 323, 6088 (1986), 533–536. DetailsGoodfellow, I. , Bengio, Y. and Courville, A. 2016. Deep learning. MIT press. DetailsHochreiter, S. and Schmidhuber, J. 1997. Long short-term memory. Neural computation. 9, 8 (1997), 1735–1780. DetailsGers, F. A. , Schmidhuber, J. and Cummins, F. 2000. Learning to forget: Continual prediction with LSTM. Neural computation. 12, 10 (2000), 2451–2471. DetailsCho, K. , Merrienboer, B. van, Bahdanau, D. and Bengio, Y. 2014. On the properties of neural machine translation: Encoder-decoder approaches. Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation (SSST-8), 2014 (2014). DetailsKoehn, P. 2009. Neural Machine Translation. Statistical Machine Translation. Cambridge University Press. DetailsVaswani, A. , Bengio, S. , Brevdo, E. , Chollet, F. , Gomez, A. N. , Gouws, S. , Jones, L. , Kaiser, Ł. , Kalchbrenner, N. , Parmar, N. and others 2018. Tensor2tensor for neural machine translation. arXiv preprint arXiv:1803. 07416. (2018). DetailsWolf, T. , Chaumond, J. , Debut, L. , Sanh, V. , Delangue, C. , Moi, A. , Cistac, P. , Funtowicz, M. , Davison, J. , Shleifer, S. and others 2020. Transformers: State-of-the-art natural language processing. Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations (2020), 38–45. DetailsDevlin, J. , Chang, M. -W. , Lee, K. and Toutanova, K. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers) (2019), 4171–4186. DetailsLan, Z. , Chen, M. , Goodman, S. , Gimpel, K. , Sharma, P. and Soricut, R. 2019. Albert: A lite bert for self-supervised learning of language representations. arXiv preprint arXiv:1909. 11942. (2019). DetailsLiu, Y. , Ott, M. , Goyal, N. , Du, J. , Joshi, M. , Chen, D. , Levy, O. , Lewis, M. , Zettlemoyer, L. and Stoyanov, V. 2019. Roberta: A robustly optimized bert pretraining approach. arXiv preprint arXiv:1907. 11692. (2019). DetailsLewis, M. , Liu, Y. , Goyal, N. , Ghazvininejad, M. , Mohamed, A. , Levy, O. , Stoyanov, V. and Zettlemoyer, L. 2020. BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension. Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (2020), 7871–7880. DetailsYang, Z. , Dai, Z. , Yang, Y. , Carbonell, J. , Salakhutdinov, R. R. and Le, Q. V. 2019. Xlnet: Generalized autoregressive pretraining for language understanding. Advances in neural information processing systems. 32, (2019). DetailsConneau, A. and Lample, G. 2019. Cross-lingual language model pretraining. Advances in Neural Information Processing Systems. 32, (2019), 7059–7069. DetailsClark, K. , Luong, M. -T. , Le, Q. V. and Manning, C. D. 2020. Electra: Pre-training text encoders as discriminators rather than generators. arXiv preprint arXiv:2003. 10555. (2020). DetailsHinton, G. E. , Osindero, S. and Teh, Y. -W. 2006. A fast learning algorithm for deep belief nets. Neural computation. 18, 7 (2006), 1527–1554. DetailsPeters, M. E. , Neumann, M. , Iyyer, M. , Gardner, M. , Clark, C. , Lee, K. and Zettlemoyer, L. 2018. Deep Contextualized Word Representations. Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers) (New Orleans, Louisiana, Jun. 2018), 2227–2237. DetailsRadford, A. , Narasimhan, K. , Salimans, T. and Sutskever, I. 2018. Improving language understanding by generative pre-training. OpenAI. Details+64 Summarization Datasets - NLP Database. DetailsKoupaee, M. and Wang, W. Y. 2018. Wikihow: A large scale text summarization dataset. arXiv preprint arXiv:1810. 09305. (2018). DetailsNallapati, R. , Zhou, B. , Santos, C. dos, Gu̇lçehre Çağlar and Xiang, B. 2016. Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond. Proceedings of The 20th SIGNLL Conference on Computational Natural Language Learning (2016), 280–290. DetailsXiong, W. , Wu, J. , Wang, H. , Kulkarni, V. , Yu, M. , Chang, S. , Guo, X. and Wang, W. Y. 2019. TWEETQA: A Social Media Focused Question Answering Dataset. Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics (2019), 5020–5031. DetailsVCR: Visual Commonsense Reasoning. DetailsZellers, R. , Bisk, Y. , Farhadi, A. and Choi, Y. 2019. From recognition to cognition: Visual commonsense reasoning. Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (2019), 6720–6731. DetailsVinyals, O. , Bengio, S. and Kudlur, M. 2015. Order matters: Sequence to sequence for sets. arXiv preprint arXiv:1511. 06391. (2015). DetailsWightman, R. 2019. PyTorch Image Models. GitHub repository. GitHub. DetailsWu, Y. , Kirillov, A. , Massa, F. , Lo, W. -Y. and Girshick, R. 2019. Detectron2. DetailsChen, K. et al. 2019. MMDetection: Open MMLab Detection Toolbox and Benchmark. arXiv preprint arXiv:1906. 07155. (2019). DetailsYakubovskiy, P. 2020. Segmentation Models Pytorch. GitHub repository. GitHub. DetailsKrishna, R. , Zhu, Y. , Groth, O. , Johnson, J. , Hata, K. , Kravitz, J. , Chen, S. , Kalantidis, Y. , Li, L. -J. , Shamma, D. A. and others 2017. Visual genome: Connecting language and vision using crowdsourced dense image annotations. International journal of computer vision. 123, 1 (2017), 32–73. DetailsGoyal, P. , Dollár, P. , Girshick, R. , Noordhuis, P. , Wesolowski, L. , Kyrola, A. , Tulloch, A. , Jia, Y. and He, K. 2017. Accurate, large minibatch sgd: Training imagenet in 1 hour. arXiv preprint arXiv:1706. 02677. (2017). DetailsCarreira, J. and Zisserman, A. 2017. Quo vadis, action recognition? a new model and the kinetics dataset. proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (2017), 6299–6308. Details      Hôm trước ngồi đọc về GAN thấy nhiều bài trên vài ngàn tới 20,000 trích dẫn, hôm nay đọc tiếp cái sequence-to-sequence (Seq2Seq) cũng thấy có cả 30k-40k cũng có. Thế nên là cái Seq2Seq này cũng phải theo bài cũ: chỉ đọc những cái có trung bình trên 300 citations/năm (GAN thì ngưỡng threshold là 200 citations/năm, nhưng sang cái Seq2Seq này là chỉ cần tìm hiểu những bài có độ tăng trưởng trên 300 trích dẫn/năm). Chứ đọc làm sao mà hết được? Ví dụ mấy bài từ năm 2018 mà tính đến nay 2022 là 4 năm mà dưới 1200 trích dẫn là nhìn chung độ tăng trưởng thấp. Tập hợp lại những papers có độ tăng trưởng mạnh từ tầm 2013 trở lại thì liên quan tới chủ để này tầm hơn trăm tấm, nói chung thượng vàng hạ cám. Có bài như bài gốc Transformer (Attention is all you need, [13]) mới ra đời từ 2017 mà đã hơn 35k trích dẫn! &#8617;    "
    }, {
    "id": 290,
    "url": "https://wanted2.github.io/ml-ids/",
    "title": "Machine Learning for Network Intrusion Detection: From Local to Production",
    "body": "2022/01/29 - Network Intrusion Detection System  Network intrusion detection system (NIDS) is an independent platform that examines network traffic patterns to identify intrusions for an entire network. It needs to be placed at a choke point where all traffic traverses. A good location for this is in the DMZ. An IDS is reactive in nature: it only monitors and sends alerts to a group of specific people like administrators. The above figure shows a common NIDS architecture, where a DMZ is placed in between external firewall and internal firewall (to an internal network). Here, in the DMZ, a NIDS can be set up to monitor the traffic of the whole corporation and identify the anomalies. A NIDS can have the following architecture:  A streaming engine which ingests packet stream into the NIDS A package decoder which turns packet content into visibility A detection engine which identify intrusions A policy engine which decide and suggest what to do with an intrusion Finally, the intrusion details are collected and logged. Alerts will be sent to admins and optionally, scripted actions can be performed in according to policies. Two typical examples of NIDS are Snort IDS and Bro IDS. A nicer example that can be integrated into network monitoring can be Zabbix’s Problem Detection Engine. Machine Learning at scale: some solutions in AWSOverview: The theory about NIDS perhaps is a huge bundle of knowledge!Corporations have set up their own NIDS (in most cases in DMZ) for years. We will not talk about such solutions anymore. The most interesting part is in the cloud platforms like AWS.  While companies are moving their resources to the cloud, where is the NIDS? In the Shared Responsibility Model (SRM). The responsibility of protecting cloud resources like computing instances (EC2) and networking is of AWS. Users have the responsibility to tune the best configurations of firewall, instances, load balancers, and other resources in AWS. So a platform IDS is already managed at AWS, and the at the users (application developers), the remaining task is to implement a best Network/HIDS (endpoint protection). There are several choices for a HIDS in the AWS Marketplace like TrendMicro’s Deep Security. For a custom NIDS, users can implement a Transit DMZ Gateway. An examplar implementation can be as follows: Challenges in NIDS operations: A standard DMZ with NIDS can be implemented at the cloud or data center. However, the hurdle only comes when we operate our solution: this is the hard part!  When it comes to operations (運用保守), it often require an enormous amount of manual work! We need a large number of low-paid workers who will sit in front of the monitoring screen and then manually mark each access as legal or not. It is the real-world hurdle!  However, the technical issues start when we want automation: how to reduce false alarms and misses? Good automated solutions will reduce manual work a lot. But it is not straightforward!Rule-based systems can have many misses or false alarms.  A weak rule misses many, but a strong rule alerts too much! (So both strong and weak ones are useless!) Machine Learning at localYou have a dataset and perform some analytics at your local or edge PC. You don’t use any server or cloud solution at all.  You should ask us why do you need to care about these works while cloud platforms already prepare so many ready-to-use solutions for you? Agree! Machine learning engineers behind the platforms already do such works (model engineering). Then when you do these works, that means you are:  A student who is learning ML at an educational place (like university); A researcher (or engineer) who perform a project for NGO, government, or a big company (who is building a platform solution); and The worst luck: you’re only an ML enthusiast who is looking into ML when you have free time. Not so many people do model engineering on their own laptop (or desktop), so in my experience, they fall into one of these three categories. For the second category, people in that category is ML engineer/scientist who will make the model for thousands to million application developers over the world (who uses the platforms). Such category is quite a few, and to be in, you need qualification!The most common cases are in the first. The third category is possible but is rare and complex: while the first and second category have their own goals with ML (for studying and for works), the third category has no particular purpose. They only do it in their free time and for fun (like doing a hobby)!The first and second ones will have outcomes (successes and non-successes), but the third one is only for fun!  No one can ban the hobby of a man, and we only do the hobby: we start when we want and stop when we don’t like it anymore!That’s why I call it (the third category) the worst luck! Actually, people in the third category already have another job (but that job does not relate to ML or even AI). They do ML as hobbies but don’t complete anything (because ML is not their business, even more, ML does not give them bread and butter)!  It is said, but in practice, if a thing doesn’t give any benefit, it won’t be done properly! Nevertheless, whatever your category is, when you do these things in your local computing environment, ML matters with you in some ways!We will see what a local IDS model would look like. And, in a synthetic way! A Kaggle synthetic dataset: We start with a synthetic dataset from Kaggle.  The dataset to be audited was provided that consists of a wide variety of intrusions simulated in a military network environment. It created an environment to acquire raw TCP/IP dump data for a network by simulating a typical US Air Force LAN. The LAN was focused like a real environment and blasted with multiple attacks. A connection is a sequence of TCP packets starting and ending at some time duration between which data flows to and from a source IP address to a target IP address under some well-defined protocol. Also, each connection is labeled as either normal or as an attack with exactly one specific attack type. Each connection record consists of about 100 bytes.  For each TCP/IP connection, 41 quantitative and qualitative features are obtained from normal and attack data (3 qualitative and 38 quantitative features). The class variable has two categories:    Normal  Anomalous Explorative analysis: We notice that not all features are useful. Some features like is_Host_login have only a constant value. Our dataset is big enough (25K entries) and contains both categorical and numerical features: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748RangeIndex: 25192 entries, 0 to 25191Data columns (total 42 columns): #  Column            Non-Null Count Dtype --- ------            -------------- -----  0  duration           25192 non-null int64  1  protocol_type        25192 non-null object 2  service           25192 non-null object 3  flag             25192 non-null object 4  src_bytes          25192 non-null int64  5  dst_bytes          25192 non-null int64  6  land             25192 non-null int64  7  wrong_fragment        25192 non-null int64  8  urgent            25192 non-null int64  9  hot             25192 non-null int64  10 num_failed_logins      25192 non-null int64  11 logged_in          25192 non-null int64  12 num_compromised       25192 non-null int64  13 root_shell          25192 non-null int64  14 su_attempted         25192 non-null int64  15 num_root           25192 non-null int64  16 num_file_creations      25192 non-null int64  17 num_shells          25192 non-null int64  18 num_access_files       25192 non-null int64  19 num_outbound_cmds      25192 non-null int64  20 is_Host_login        25192 non-null int64  21 is_guest_login        25192 non-null int64  22 count            25192 non-null int64  23 srv_count          25192 non-null int64  24 serror_rate         25192 non-null float64 25 srv_serror_rate       25192 non-null float64 26 rerror_rate         25192 non-null float64 27 srv_rerror_rate       25192 non-null float64 28 same_srv_rate        25192 non-null float64 29 diff_srv_rate        25192 non-null float64 30 srv_diff_Host_rate      25192 non-null float64 31 dst_Host_count        25192 non-null int64  32 dst_Host_srv_count      25192 non-null int64  33 dst_Host_same_srv_rate    25192 non-null float64 34 dst_Host_diff_srv_rate    25192 non-null float64 35 dst_Host_same_src_port_rate 25192 non-null float64 36 dst_Host_srv_diff_Host_rate 25192 non-null float64 37 dst_Host_serror_rate     25192 non-null float64 38 dst_Host_srv_serror_rate   25192 non-null float64 39 dst_Host_rerror_rate     25192 non-null float64 40 dst_Host_srv_rerror_rate   25192 non-null float64 41 class            25192 non-null object dtypes: float64(15), int64(23), object(4)memory usage: 8. 1+ MBAnyway, this is a synthetic dataset with some characteristics based on simulation. However, it is close to real-world examples enough. Next, we will try some machine learning models for predicting anomalies. With a visualization technique, like T-SNE, we have a diagram of data distribution. A green point is a normal data point, and a red one is an anomaly. We can see that it would be hard to draw a linear boundary between normal points and anomalies. Play with some machine learners: In this section, we will try two different ML models with two different training/inference strategies:  Generative model with a reconstruction strategy: the Auto-Encoder12345678910# creating the autoencoder modeli = Input(shape=(X_train_normal. shape[1],))encoder = Dense(64, activation='relu')(i)encoder = Dense(32, activation='relu')(encoder)code = Dense(16, activation='relu')(encoder)decoder = Dense(32, activation='relu')(code)decoder = Dense(64, activation='relu')(decoder)decoder = Dense(X_train_normal. shape[1], activation='sigmoid')(decoder)model = Model(i,decoder) Discriminative model with a classification strategy: the quite classical Random Forest!12from sklearn. ensemble import RandomForestClassifierrf = RandomForestClassifier(n_estimators=100, criterion='gini')Training and validation: We need to transform the data a little bit. It is usual to use MinMaxScaler to perform data transformation. 1234from sklearn. preprocessing import MinMaxScalerscaler = MinMaxScaler()X_train_normal[to_norm] = scaler. fit_transform(X_train_normal[to_norm])X_val_normal[to_norm] = scaler. transform(X_val_normal[to_norm])The Auto-Encoder is trained in a reconstruction manner, i. e. , it learns to reconstruct the input: 1r = model. fit(X_train_normal, X_train_normal, validation_data=(X_val_normal, X_val_normal), epochs=5)But the Random Forest learns to classify data as usual: 1rf. fit(X=X_train, y=y_train_num)Results of Auto-Encoder: Since the prediction of AE relies on how good it can reconstruct the input:  If the reconstruction error is over a threshold, then the reconstruction fails, and the input is anomaly.  Otherwise, the input is normal. Then we must define a threshold to separate anomalies and normal inputs. To find such threshold, we can compute from the training dataset: 1234# reconstructing the train setpred = model. predict(X_train_normal)# finding the mean reconstruction errornp. mean(np. mean(np. power(pred - X_train_normal, 2), axis=1))Since the mean of construction error is 0. 0018520295581492838, we can choose the threshold thres = 0. 0018. Validation in validation set: 1234567X_val[to_norm] = scaler. transform(X_val[to_norm])pred = model. predict(X_val)mse = np. mean(np. power(pred - X_val, 2), axis=1)# classifying the samples based on thresholdpred_class = ['anomaly' if val &gt; thres else 'normal' for val in mse]print(confusion_matrix(y_val, pred_class))print(f Acc. = {accuracy_score(y_val, pred_class)*100}[%], F1 = {f1_score(y_val, pred_class, pos_label='anomaly')*100}[% )Results: 123[[2901  69] [ 563 2765]]Acc. = 89. 96506827564306[%], F1 = 90. 17718371153248[%]~90% of F1 score. Hmm, not so bad! Results of Random Forest: Let’s see the results with Random Forest: 123[[3321  7] [ 14 2956]]Acc. = 99. 66656081295649[%], F1 = 99. 64604753076016[%]99. 6%, it is quite good! Some methods for Machine Learning based IDS: There are many ways to identify anomalous access (i. e. , intrusion) in the network. Rule-based methods tend to find a “good” heuristic that can be generalized to a global policy for all feature space. The same policy can be applied to every input. For example, every connection which lasted for more than 7 minutes are anomalies is a policy to identify intrusions. The problem with this approach is that many false negatives (misses) can be raised. Because the rule is clear, counterfactuals try to make themselves legal (try to connect faster) and overcome the 7-minute rule. So a fixed rule is not enough.  The attacks become more and more advanced, but the rules cannot be changed so fast, making an Achilles' heel in the defense system. Machine Learning-based methods try to define a soft boundary that can be learned and improved over time. The main advantage of the Machine Learning approach is that since the boundary is soft and there is no clear rule, the intruders cannot know the rule exactly (how many minutes should they make for a successful intrusion?). Another important aspect is that since the soft rule is not fixed, it can evolve with the intrusions: the more advanced the intrusion is, the more advanced the defender is. When this sounds ambiguous, but for the security systems, it becomes exactly a common strategy to overcome incidents. The Machine Learning methods can be generative or discriminative, but they must be somewhat non-linear and ambiguous enough to hide details of the system to hackers. ConclusionWe have reviewed several views of NIDS: at a corporation network view, cloud solutions, and machine learning models. On the synthetic examples, we observed that a quite classical model like Random Forest can outperform neural nets. It is not a new thing: we already empirically knew that Random Forest is good at this problem, especially when it is in synthetic environments. Somebody can argue that there is a chance for overfitting with Random Forest: hmm, I don’t think so.  And even if it overfits, this is quite good, because that’s what we want: We want our model to overfit to this dataset.  Anonymous Source code for this article can be found at:  AIFI-INC’s ML-based IDS"
    }, {
    "id": 291,
    "url": "https://wanted2.github.io/pm-sekininsha/",
    "title": "責任者",
    "body": "2022/01/16 - ベトナムに帰ってからベトナムの職場文化になってからはもはや2年間になっております．ベトナム職場でいうと，恥ずかしいけど，楽しい経験もあるし，悲しい経験もありました．仕事の責任者として働いた経験もあり，悲しい時で，部下に怒られて，そろそろ殴られる経験もありました．なぜなら，背景から考えると，文化の違いかなと思います．ベトナム職場では上下関係は社会的に存在するけど，きちんと働かないとね，上下関係なく殴られるそうです．「殴られる」は厳しい言葉ですが，主にいうと，ベトナム職場で下記の三大原則はあります．  原則1：Có làm thì mới có ăn. You must work to be fed. 職あり食ある．  原則2：Có lỗi thì sửa là được. Don’t be panic, just fix bugs, then it’s OK. 問題にダラダラしないで，修正すれば問題なし．（ただ何もしないなら，↑の原則１をみてください）．  原則3：Làm thì làm cho nghiêm chỉnh. You should do the work thoroughly. 徹底的にやりましょう． ベトナム職場の約2年間の経験をまとめて，一度整理したいと思っております． 第一原則：「職」と「食」我々は職場で「仕事」を大事にしております．仕事が順調であれば，食感もよくなるという発想です．仕事をしなければ，食えるもんがなく，大変ですね．ですが，仕事（職）があって，就いたけど何もしないことで組織には不満が引き起こされたことが多いようです． ですので，組織全体で皆は統一して，職務をしてから食べるということを理解したらよかったです．もちろん，海外から来る要員だと，現地の文化がわからず，仕事とは何か現地の人の考え方は最初でわからないこともあります．しかし，時間が経過すると，その意義を理解すれば，原則を守る姿勢を整い，結局「労働」は第一だという考え方に帰着しました．組織全体といえば，作業人だけではなく，管理職でもきちんと働き姿勢を見せればよいと思います． ここで，一番気になることは，この原則にはもう一つの意味の層があります．仕事をやるといっても，何をやっても認められるのではないです．「すごいことをやる」のも間違いです．ある「職」に就く時，自分の役割と権限は決まっております．ある場合，期待もあります．しかし，開発の現場では，ほとんどの場合，役割と権限と責任範囲・仕事内容はすでに決まっております．（※申し訳ないが，それぐらい曖昧に契約してしまえば，ちょっとそれがまずい職になるかもしれません）．ですので，「自分の役割と権限・責任範囲の中に行動し，仕事を仕上げる」ことで職を行っているねといいます．まあ，「職あり食ある」という句です． ※曖昧に定めてしまった職に入った場合，もちろん仕事をしたから食べることがあるけど，ちょっと食べ物は美味しくないかもしれないです．おいしい食をどうやって作るか山ほど研究がありますので，それらをGoogleして参考にすればと思います． 第二原則：チームは障害にだらだらしないで，乗り越えることは大事！チーム運営の中に，一緒に働くので，楽しい時も，悲しい時も一緒に乗り越えています．楽しい時はいいんだけど，悲しい時はどんな時かな？自分の経験では，パニック状態になるときです．多くの場合，急に障害が起きるときとかですね． 確かに，パニック状態のハンドルをうまく取り込めているチームはすごいねとおもいます．パニック状態になった場合，よいチームは取り込むけど，悪いチームは責任追及ゲームを遊びます．なぜ責任追及ゲームは悪いのかというと，緊急対応なのに，問題対応をせずに，ゲームをしているからです．よいチームは問題を見極めて，対処法を第一優先し対応を取り込むのです． ※ちなみに，チームで開発する場合には，運営中で時間がかかってしまう状態があります．それが，パニック状態と，会議状態です．なぜなら，この2つだけは，一人の時間を取るだけではなく，チーム皆の時間を取っているからです．だらだらして，仕事が進まない罠に落ちやすいのです．チームのパフォーマンスを上げたい場合に，責任者として，回避と対応策を計画しなければなりません． ベトナム職場では，なぜこの原則が取り込まれているかというと，チームがどこかにだらだらすると，めっちゃ時間がかかっているから，まずは乗り越えることを第一優先したいからです．人がミスをすることは人間の根性ですので，それよりももっと悪いことは，「なにもしないこと」です．直さないことや修正しないことなどはまた，原則1で処分されると思います．いつもチームを前向きに進行させることができればと思います． 第三原則：自分の仕事へのこだわりも重視！完成したら，もう一度見直そう！2年間ベトナム職場で感じたもう一つの原則です．第一原則と第二原則を相互に働かせているため，「作成」と「修正」を交互に行っています．しかし，これらを交互に働かせると，永遠に修正のループに入る可能性はまだ残っています．ですので，途中でもっと修正してもあまり報われないと感じるときとか，早く止めた方がよいと感じるときとか，もう一つのコントローラーが必要でしょうか．それは第三原則です．必ず，（再）作成と（再）修正が完成したら，もう一度客観的にレビューしましょう．狭い視野で詳細をレビューするだけではなく，広い視野で，この作成と修正は長期的によいか悪いか一回考えるべきというステップがあれば，なおよいです．ここで，責任者として，技術部分だけではなく，スコープ管理とか要望管理とかスケジュール管理とかうまく併せてやる必要があります． 結論これが，おそらく私が2年間で観測したベトナム職場で支配されている三大原則かと思います．これらは，なぜか職場をコントロールして，各PJを進行させることが多いそうです． "
    }, {
    "id": 292,
    "url": "https://wanted2.github.io/aws-account/",
    "title": "4 điều nên làm để quản lý tài khoản AWS",
    "body": "2022/01/16 -  Những tri thức cơ bản như làm thế nào quản lý mật khẩu với đặt mật khẩu như thế nào thì có lẽ các em tự chủ động thiết lập nhé. Trong bài viết này chúng ta sẽ tập trung vào 4 chức năng mang tính nâng cao (advanced) của bảo mật tài khoản AWS. Thiết lập và quản lý tài khoản AWS không chỉ đơn giản là vấn đề bảo mật dữ liệu mà còn sâu xa hơn là quản lý toàn bộ account trong tổ chức một cách đồng bộ, tập trung và hiệu quả nhất. Việc này rất quan trọng bởi account chính là cửa ngõ vào của mọi luồng dữ liệu, mọi truy cập, do đó nếu việc quản lý account bị lơi là sẽ dẫn đến việc những truy cập bất hợp pháp có thể xâm nhập vào “hệ miễn dịch” của tổ chức và gây hại. 4 chức năng chúng ta nói đến hôm nay bao gồm:  Bảo mật nhiều lớp cho tài khoản root; Quản lý và thiết lập phân quyền cùng AWS Organizations; AWS Single-Sign On (SSO); và Giám sát hành vi tài khoản trên AWS. Giới thiệuNhư trong tiếng Nhật thì chữ tài khoản (tiếng Anh, account) được viết là 口座, bắt đầu bằng bộ “khẩu (miệng)”. Các bạn đều biết cửa sổ đi vào hệ tiêu hóa mà mọi thứ đồ ăn thức uống phải đi qua đều bắt đầu từ miệng. Cái miệng chính là nơi mọi thức ăn xâm nhập vào cơ thể con người. Thức ăn có thể hàm chứa dinh dưỡng, nhưng cũng có thể hàm chứa chất độc, bệnh dịch. Có thể ngon mà cũng có thể dở. Việc bảo vệ “bộ nhá” là cực kỳ quan trọng với con người nói chung! Trong bài viết này song song với việc thao tác trên AWS chúng ta cũng sẽ nói thêm về các nguyên lý đằng sau các thiết lập tài khoản, các dịch vụ bảo mật đa lớp, single sign-on, . v. v…Với nguyên tắc là mọi thứ qua miệng đều phải rõ nguồn gốc (cũng không cần chi tiết quá, nhưng ở mức có thể track được). Bảo mật nhiều lớpĐiểm qua những tiến bộ của mảng bảo mật nhiều lớp: Những tri thức nền tảng cho bảo mật nhiều lớp xuất hiện lần đầu từ bài báo của Mitchell Trauring [1], [2] năm 1963. Trong bài viết về cách thức nhận dạng vân tay tự động bằng Ridge patterns, ông viết:  It is the purpose of this article to present, together with some evidence of its feasibility, a method by which decentralized automatic identity verification, such as might be desired for credit, banking or security purposes, can be accomplished through automatic comparison of the minutiae in finger-ridge patterns.  Mitchell Trauring, Nature, March 1963 Như hình vẽ bên các bạn có thể thấy, bình thường bảo mật 1 lớp thì chỉ cần có mật khẩu (something you know). Tuy nhiên, để tăng độ bảo mật, ví dụ như khi mật khẩu bị đánh cắp thì nên có nhiều phương pháp bảo mật đi kèm như token [3], vân tay [2], khuôn mặt [4], PIN/key [5], mống mắt, …. Cái quan trọng là phải kết hợp thêm những cái gì user có (something you have) và những gì của user (something you are). Trích dẫn: [1] mô hình vân tay và cách matching local points. Tuy nhiên, một vấn đề lớn của các phương pháp bảo mật đi kèm là độ chính xác. Ví dụ như với vân tay [6] thì xác suất false matching probability vẫn có thể đạt $6. 10\times 10^{-8}$ với mẫu vân tay có 36 điểm minutiae. Do đó việc sử dụng đơn thuần 1 đặc trưng anatomical hoặc behavior có thể tạo ra nhiều false non-matching cũng như false matching. Cũng vì đó mà cần phải dùng nhiều đặc trưng, và khi dùng nhiều đặc trưng thì có đặc trưng quan trọng, có đặc trưng không, phải có weight cho từng đặc trưng. Và đó chính là ý tưởng feature fusion hay là multimodal cho mảng biometrics. Nói chung, cũng toàn mấy cái ý tưởng của các fellows từ thời 1990s-2000s, thời các sếp ấy thì cũng đã 20-30 năm về trước, nên mấy cái ý tưởng này tôi nghĩ mới cũng không mới và trong mảng biometrics cũng đã implement gần hết, thậm chí vào sản phẩm thị trường rồi. Cái mảng bảo mật nhiều lớp [7] và biometrics [2] nhìn chung là cũng liên đới rộng phết, từ bảo mật cloud đến tận thiết bị IoT [8] cũng liên quan. Nhưng nhìn chung cái mô hình thực thi thì khá giống nhau:  Về mặt hệ thống thì anh em nào làm nhiều về cloud, web app thì sẽ hiểu ngay là trong framework sẽ có một bộ phận middleware có những function kiểu như preLogin(), postAuthentication(), . . . là sẽ là nơi implement thêm các lớp bảo mật. Ở trong middleware [8] thì chúng ta sẽ call thêm các lớp bảo mật khác để đưa ra kết quả.      Ngoài ra, việc fusion của các đặc trưng có thể thực hiện tại biometrics sensor, tức là early fusion. Hoặc tại module decision, tức là late fusion và chủ yếu là fuse kết quả nhận dạng của từng modal.     Về mặt module, thì module bảo mật của từng lớp thì sẽ như hình vẽ bên phải. Sẽ có enrollment (đăng ký) và verification (đăng nhập/nhận dạng). Nói chung mảng bảo mật nhiều lớp cũng có khá nhiều dư địa, tuy nhiên nếu so với những mảng như GAN hay deep learning thì số lượng papers mỗi năm trong academics có vẻ không nhiều. Mà số lượng papers có nhiều trích dẫn thì cũng ít hơn. Vì đơn giản như paper về GAN của Goodfellow năm 2014, đến nay là 7 năm mà đã có gần 40k trích dẫn, mà cái mảng đó hầu như top-2% về nhiều trích dẫn thì cũng toàn những paper vài ngàn citations trở nên. Nói chung lựa chọn trích dẫn bài nào cũng tuỳ mảng, vì mảng biometrics, tôi thấy những papers của các fellow cũng chỉ vài trăm citations trong 10 năm. Nhưng cái mảng deep learning với GAN thấy năm nào cũng hàng ngàn papers mà những papers top thì toàn hàng ngàn citations. Nên đôi khi hỏi là có cần đọc hết các papers trong mảng không?, thì tôi nghĩ là nếu những mảng ít ít như biometrics thì đọc cũng được, nhưng mấy cái mảng liên quan tới deep với GAN, thì tôi nghĩ cũng chả cần đọc đâu. Chỉ cần filter ra top 2% mà chủ yếu những bài có tốc độ tăng trưởng mạnh (mỗi năm trên 200 citations) thì đọc thôi, chứ nó nhiều thế này mà toàn na ná nhau, thì papers mà ít citations chắc chắn là không phải trend, đọc không hết được mà đọc cũng chả để làm gì. Tất nhiên, cũng phải ưu tiên những papers mới xuất bản năm nay thì mình nên đọc. Tức là ví dụ năm nay là 2022 thì những bài từ 2021 thì mình ưu tiên đọc (nhưng vẫn chỉ nên đọc top tầm 30%), còn từ 2020 về trước thì chỉ chọn bài có độ tăng trưởng trung bình trên 200 citations/năm, và trong đó cũng chỉ nên chọn top. Cuối cùng, là về mảng biometrics này thì có một ứng dụng thú vị là face recognition mà bên computer vision hay deep learning cũng nổi lên (gọi là deep face recognition). Mảng này thì quả là cũng không nhiều papers lắm, cũng giống biometrics, nhưng lại có một số papers có trích dẫn hàng ngàn mặc dù xuất bản sau 2015 như FaceNet hay RetinaFace, ArcFace, CosFace. Tuy nhiên, nếu nói về thực tiễn sử dụng thì tôi nghĩ tốt nhất là nên tham khảo các con số trong benchmark lớn của chính phủ Mý [4]. Lý do là bởi vì đó là các ứng dụng thực tiễn, cũng như bộ dữ liệu lớn tới vài chục triệu người, và quan trọng là mọi team trên thế giới đều có thể tham gia. Dưới đây là bảng kết quả hạng mục Verification, tức là cho sẵn một pair hai khuôn mặt, đưa ra kết quả xem đó có cùng 1 identity không?Kết quả là đường cong thể hiện tỷ lệ false non-matching rate (FNMR) vs false matching rate (FMR). Chúng ta hãy để ý đến tỷ lệ FNMR@FMR=$10^{-5}$ thì tên tuổi đứng nhất là InsightFace (là nhóm tác giả của RetinaFace, ArcFace, …). Họ chính là tác giả của framework insightface để nhận dạng khuôn mặt 2D/3D. Thành tích đứng nhất là $FNMR=0. 0006$ khi $FMR=10^{-5}$, tức là 10 vạn người thì chỉ sai 1 người và miss 60 người, tổng là 61 người bị sai hoặc miss.  Trên đây chỉ là kết quả của dataset VISA, ngoài ra NIST còn có những task khác cùng với những dataset khác. Từ VN thì cũng có team của một số đội như VNPT hay VIN AI/VIN Bigdata cũng tham gia và có được thứ hạng (tức là đã nộp bài). Bật tính năng MFA của AWS: Với tài khoản root: Với người dùng có tài khoản root thì chắc thi thoảng bạn cũng sẽ login vào để làm một số việc như:  Quản lý IAM users Quản lý bill service Quản lý dịch vụ sử dụng …Vậy tài khoản root là chứa tất cả của bạn (hoặc tổ chức), vậy nên không thể không nâng độ bảo mật lên được. Và nên bật MFA lên. Mặc dù chúng ta đã tìm hiểu về MFA khá nhiều bên trên, thì AWS hỗ trợ một số biện pháp MFA như sau thôi:  Virtual MFA devices hay MFA thông qua phần mềm. Bạn có thể cài đặt Microsoft Authenticator vào điện thoại cho mục đích này.  U2F security key tức là 1 cái USB key để bạn cắm vào máy và nó sẽ dùng thông tin của USB này để nhận dạng bạn khi bạn đăng nhập.  Hardware MFA device. Một thiết bị được đăng ký sẽ tạo 1 code 6 chữ số để cho thuật toán time-synchronized one-time password (OTP). Nhìn chung, có thể vân tay hay khuôn mặt thì sẽ cần dùng một kênh khác, còn tài khoản AWS hiện chỉ support những kênh MFA thêm code. Ngoài ra MFA thông qua SMS cũng không được hỗ trợ. Sau khi khởi động phương thức MFA phù hợp, từ lần đăng nhập tiếp theo, người dùng sẽ phải nhập thêm code được sinh ra từ phần mềm hoặc thiết bị đã đăng ký. Với tài khoản IAM: Bạn có thể cấp tài khoản IAM cho người dùng trong tổ chức của bạn (định nghĩa Roles/Permissions tương ứng với nhiệm vụ của nhân viên). Nếu bạn muốn bảo mật hơn, bạn có thể bắt buộc nhân viên dùng IAM phải dùng MFA. Bạn truy cập vào trang cấu hình của IAM user đó và yêu cầu assign MFA devices. Xem thêm hướng dẫn kích hoạt MFA cho tài khoản IAM. Nhìn chung, MFA là một chức năng đơn giản để cấu hình và nên được áp dụng. Trong những best practices của AWS cũng có hướng dẫn nên cấu hình MFA cho việc xóa object khỏi S3 chẳng hạn. Và tại sao AWS chỉ áp dụng MFA dạng code 6 chữ số, chứ không hỗ trợ biometrics như vân tay hay khuôn mặt/mống mắt, thậm chí SMS cũng không được?Có lẽ là do vân tay hay mống mặt và đặc biệt khuôn mặt vẫn có tỷ lệ sai nhất định (chúng phù hợp cho nhiệm vụ điều tra của cảnh sát hơn), còn SMS thì có khá nhiều lỗ hổng bảo mật liên quan rồi nên lựa chọn code theo device có lẽ hợp lý hơn. Quản lý và thiết lập quyền với AWS OrganizationsGiới thiệu AWS Organizations: Trong nghiệp vụ quản lý tổ chức, có một mảng khá quan trọng là quản lý tài sản (asset management). Thì không đơn giản là lên danh sách tài sản và quản lý chúng, cái đó thì chỉ 1 file Excel là làm được. Cái quan trọng hơn với trọng trách này là quản lý và giám sát mọi tài sản trong tổ chức bao gồm cả tài sản, tài nguyên máy móc. Với AWS thì là quản lý tất cả các tài khoản nhân viên, máy ảo, dịch vụ được dùng một cách tập trung và hiệu quả.  Tại sao phải tập trung lại 1 chỗ? Là bởi vì nếu phân tán sẽ khó kiểm soát và nhà quản lý sẽ rơi vào trạng thái bị động với mọi thay đổi trong tổ chức.  Tại sao phải hiệu quả? Vì khi lên thành tổ chức, tài nguyên sẽ tăng lên rất nhiều, mà quản lý không hiệu quả thì cũng như người mù ngồi trên đống vàng. Người quản lý sẽ cần một công cụ để có thể ra policy và áp dụng policy đó một cách đồng bộ trong toàn tổ chức. Lời giải hợp lý ở đây chính là sử dụng AWS Organizations.       #   Tên   Chức năng         1   Manage your AWS accounts   Tài khoản AWS trong tổ chức là nơi cần tổ chức quản lý quyền, bảo mật, tài nguyên và costs. Để dễ dàng tổ chức quản lý việc nâng cấp lên môi trường đa tài khoản (multi-account enviroment) là cần thiết. AWS hỗ trợ việc quản lý tập trung tài khoản qua CLI, SDKs, APIs và thậm chí là Infrastructure as code như AWS Cloudformation.        2   Define and manage your organization   Ngay khi khởi tạo các tài khoản, người quản lý có thể tạo nhòm tài khoản (OUs) phục vụ cho từ ứng dụng hoặc dịch vụ. Người quản lý có thể sử dụng tags để phân loại và track tài nguyên. Ngoài ra người quản lý có thể truyền lại quyền (delegate) cho nhân viên, khi đó nhân viên có thể coi là đại diện cho tổ chức để thực thi quyền.        3   Secure and monitor your accounts   Người quản lý có thể quản lý bảo mật tập trung và cho phép đội bảo mật truy cập cho tổ chức. AWS Organizations cung cấp dịch vụ bảo mật như AWS GuardDuty để phát hiện và xử lý sự cố/nguy cơ bảo mật, IAM Access Analyzer để review những truy cập không mong muốn, và dùng Amazon Macie để quản lsy dữ liệu nhạy cảm (kiểu như review code xem có sót thông tin mật nào không?).        4   Control access and permissions   Set up Amazon Single Sign-On (SSO) để cung cấp cho tài khoản người dùng AWS quyền truy cập tài khoản thông qua active directory và tối ưu quyền dựa trên roles. Người quản lý còn có thể cho phép người dùng hoặc OUs sử dụng SCPs để quản lý quyền truy cập vào tài nguyên, dịch vụ, và regions trong tổ chức.        5   Share resources across accounts   Quản lý tài nguyên tập trung với AWS Resource Allocation Management (RAM). Kể cả license cũng có thể được quản lý tập trung với AWS License Manager, và chia sẻ dịch vụ trong cả tổ chức với AWS Service Catalog.        6   Audit your environment for compliance   Người quản lý có thể kích hoạt AWS CloudTrail để log mọi hành vi trong môi trường tổ chức, mà nhân viên không thể tắt đi được. Người quản lý có thể cấu hình AWS Backup để backup mọi tài nguyên, và dùng AWS Config để đồng bộ cấu hình tài nguyên dịch vụ trong cả tổ chức bất cháp tài khoản và regions.        7   Centrally manage billing and costs   Quản lý costs tập trung với AWS Cost Explorer, và sử dụng AWS Compute Optimizer để tối ưu giá thành.    Usecase: AWS GovCloud: Trên trang chủ của AWS Organizations có thể tìm thấy khá nhiều usecases có sẵn. Trong bài này chúng ta xem lại 1 usecase của AWS GovCloud [9]. Usecase này được đưa ra bởi MITRE. Họ đưa ra 9 lời khuyên trong việc quản lý AWS Organizations:  Reserved Instances: nên thuê dài hạn để nhận discount.  Spot Instances: nên thuê những instances dạng spot để có thể bid giá và chạy khi giá thực vượt quá giá bid.  Auto Scaling and Automating Elasticity: auto-scaling instances là chuyện nên làm và policy để scale nên dựa trên volume demand.  S3 Object Lifecycle Management: storage type nên được chọn dựa theo object lifecycle và tần suất truy cập.  Instance States and Stopping Instances: hãy cấu hình chỉ bill với những cái gì đang chạy. Không nên thuê kiểu phải trả cho thời gian không chạy.  Tagging: để giám sát giá thành nên dùng labels.  AWS Config: đồng bộ cấu hình tài nguyên trên toàn tổ chức và mọi regions.  AWS Organizations: quản lý quyền và tài khoản trong tổ chức một tập trung và hiệu quả.  EC2 Right Sizing: nếu dùng EC2 thì phải lựa chọn size phù hợp nhu cầu, không nên dùng lớn hơn nhu cầu dẫn tới lãng phí. Nói chung là nếu quản lý tài nguyên một cách tập trung và hiệu quả thì giá thành của tổ chức sẽ rẻ hơn nhiều so với dùng tài khoản cá nhân. AWS Single Sing-On (SSO) Giới thiệu về Federated learning với AWS: Federated Authentication. Vậy là chúng ta đã cấu hình xong AWS Organizations. Bây giờ chúng ta đã tạo 1 tài khoản user, và chúng ta muốn user đó sẽ login và sử dụng AWS account với quyền giới hạn. Tất nhiên là login bằng tài khoản root thì sẽ có mọi quyền rồi, nhưng vấn đề là việc đó cần phải giới hạn để tránh những sự cố không đáng có. Việc cấp quyền này chính là hình thức federated mà chúng ta muốn học hỏi hôm nay. Nhìn chung là nếu cứ tất cả dồn hết vào tài khoản root, thì chuyện quản lý phân quyền sẽ vô cùng mệt mỏi. Do vậy, cần có fedareted learning để nhượng quyền cũng như chia quyền cho thích hợp. Cấu hình Federated account để người dùng có thể truy cập AWS: Về phía người quản lý. Một lời giải cho việc này chính là sử dụng AWS Single Sign-On (SSO), mà khởi đầu chỉ cần vào danh sách dịch vụ của AWS Organizations và bật SSO lên. Sau đó người quản lý vào danh sách user và ấn check tên user account muốn cấp quyền và nhấn Assign user. Người quản lý sẽ được đưa đến màn hình Assign Users như sau. Tại đây, người quản lý có thể tạo một permission set mới cho user account đã cho, hoặc cấp ngay một permission set có sẵn. Trong ví dụ này tôi chọn luôn permission set DataScientist có sẵn để cho user account đã tạo nhé. Cần chú ý ở đây là bộ quyền DataScientist thì chỉ cho phép user truy cập các dịch vụ Analytics như database, DataLake Formation, RedShift, . v. v… chứ những dịch vụ như CLoudFront, Lambda, … là cần thêm quyền. Tùy vào nhu cầu sử dụng mà người quản lý có thể tạo những bộ quyền có sẵn để tiện cho việc quản lý. Sau khi nhấn thêm vài nút bấm OK em nữa thì bộ quyền đã được assign cho user nhá.  Về phía federated user. Thì họ cần truy cập vào link SSO do người quản lý cung cấp. Trong lần truy cập đầu, họ sẽ cần thay đổi mật khẩu mặc định và đăng nhập. Như bạn thấy ở hình bên, người dùng sẽ truy cập được vào AWS Account với quyền truy cập giới hạn. Người dùng cũng có thể cấu hình MFA devices để tăng bảo mật theo yêu cầu của người quản lý. Chú ý là không chỉ AWS Account mà cả các SAML service nếu có thì người dùng có thể truy cập thông qua cổng này. Giám sát hành vi với AWS CloudTrailNếu application logs có thể được lưu trữ và quản lý với CloudWatch thì CloudTrail có thể quản lý mọi hành vi diễn ra trên tài khoản AWS Accounts của cả cá nhân lẫn organization.  Với CloudTrail, người quản lý của tổ chức có thể làm rất nhiều việc:  Auditting: theo dõi, giám sát tự động mọi hoạt động diễn ra với tài khoản AWS Organizations. Người quản lý có thể truy vết lại log hành vi trên tài khoản tối đa 90 ngày quá khứ. Nếu muốn mở rộng trên 90 ngày thì có thể liên hệ với AWS để cấu hình thêm. CloudTrail cũng có thể tích hợp vào EventBridge để tăng cường theo dõi và lên cảnh báo. Log file của CloudTrail được mã hóa và được bảo vệ khỏi mất mát. Dữ liệu log trên nhiều vùng có thể được aggregate lại. ClouTrail Insight và CloudTrail Lake là các dịch vụ tăng cường hỗ trợ việc quản lý log hành vi dễ hơn.  Phát hiện và xử lý vi phạm bảo mật Đối ứng sự cố: phát hiện bất thường và tìm hiểu root cause. Giá cả của CloudTrail và CloudTrail Lake có thể tìm ở đây. Nói chung là nên ước tính trước số lượng sự kiện hành vi trên account để có kế hoạch chọn gói sử dụng thích hợp. Một mẫu log của CloudTrail cho sự kiện start-instances sẽ như sau: 1234567891011121314151617181920212223242526272829{ Records : [{   eventVersion :  1. 0 ,   userIdentity : {     type :  IAMUser ,     principalId :  EX_PRINCIPAL_ID ,     arn :  arn:aws:iam::123456789012:user/Alice ,     accessKeyId :  EXAMPLE_KEY_ID ,     accountId :  123456789012 ,     userName :  Alice   },   eventTime :  2014-03-06T21:22:54Z ,   eventSource :  ec2. amazonaws. com ,   eventName :  StartInstances ,   awsRegion :  us-east-2 ,   sourceIPAddress :  205. 251. 233. 176 ,   userAgent :  ec2-api-tools 1. 6. 12. 2 ,   requestParameters : { instancesSet : { items : [{ instanceId :  i-ebeaf9e2 }]}},   responseElements : { instancesSet : { items : [{     instanceId :  i-ebeaf9e2 ,     currentState : {       code : 0,       name :  pending     },     previousState : {       code : 80,       name :  stopped     }  }]}}}]}Kết luậnTrên đây chúng ta cùng nhau điểm qua kha khá các vấn đề về quản lý tài khoản. Thực ra chỉ 4 điểm có thể là chưa bao quát hết, nhưng cũng hầu như là nắm trọn mảng này. Một số vấn đề thú vị khác như RAM, AWS Config, … chúng ta sẽ đề cập khi có dịp. Tài liệu tham khảoTrauring, M. 1963. Automatic comparison of finger-ridge patterns. Nature. 197, 4871 (1963), 938–940. DetailsJain, A. K. , Nandakumar, K. and Ross, A. 2016. 50 years of biometric research: Accomplishments, challenges, and opportunities. Pattern recognition letters. 79, (2016), 80–105. DetailsHoldsworth, J. 2008. Token for use in online electronic transactions. Google Patents. DetailsGrother, P. , Ngan, M. , Hanaoka, K. , Yang, J. C. and Hom, A. 2022. Ongoing face recognition vendor test (FRVT) part 1: Verification. US Department of Commerce, National Institute of Standards and Technology. DetailsBoyd, C. , Mathuria, A. and Stebila, D. 2003. Protocols for authentication and key establishment. Springer. DetailsPankanti, S. , Prabhakar, S. and Jain, A. K. 2002. On the individuality of fingerprints. Pattern Analysis and Machine Intelligence, IEEE Transactions on. 24, 8 (2002), 1010–1025. DetailsOmetov, A. , Bezzateev, S. , Mäkitalo, N. , Andreev, S. , Mikkonen, T. and Koucheryavy, Y. 2018. Multi-factor authentication: A survey. Cryptography. 2, 1 (2018), 1. DetailsNgu, A. H. , Gutierrez, M. , Metsis, V. , Nepal, S. and Sheng, Q. Z. 2016. IoT middleware: A survey on issues and enabling technologies. IEEE Internet of Things Journal. 4, 1 (2016), 1–20. DetailsMahakian, J. , Holmdahl, S. , Bada, Q. , Silva, S. and Tretler, Z. 2020. AWS GovCloud Resource and Cost Analysis. The MITRE Corporation. Details"
    }, {
    "id": 293,
    "url": "https://wanted2.github.io/pay/",
    "title": "Cán cân thu nhập: hàn lâm, khởi nghiệp và công ty",
    "body": "2022/01/10 -  Cộng đồng mạng xã hội hiện đại gần đây có nổ ra tranh cãi về câu nói Có làm thì mới có ăn, cái loại không làm mà lại muốn có ăn thì chỉ có ăn … của tác giả Huấn Hoa Hồng. Những bô lão của cộng đồng hàm lâm như Giáo sư kiêm lính thủy đánh bạc Tiến Bịp cũng nhanh chóng xuất bản các papers để phản bác Huấn.  Chú ý: video chứa nội dung và ngôn từ nhạy cảm! Nghe thì chả có vẻ liên quan gì nhưng những chân lý do các vị giáo sư “tự phong” của cộng đồng mạng này cũng có sức nặng nhất định: Có làm thì mới có ăn thì đã là nguyên lý của lao động sản xuất có hệ thống trong xã hội. Nhưng vấn đề là làm gì và làm thế nào?Định hướng nghề nghiệp chính là một khâu quan trọng giúp các bạn trẻ phát triển sự nghiệp. Tất nhiên ngoài hai vị “giáo sư” kể trên thì còn vô số học thuyết và lý thuyết trong cái mảng này với hàng ngàn cuốn sách đủ thể loại của các tác giả trên thế giới để định hướng các bạn trẻ. Nhưng thôi chúng ta cứ đưa ra góc nhìn thiết thực nhất với mọi người lao động bình thường: thu nhập trước đã nhé! Lựa chọn sự nghiệpTất nhiên mức lương tối thiểu vùng miền là đã có quy định, mức đóng các khoản như bảo hiểm, thuế thu nhập cá nhân thì cũng đã có quy định công thức, cứ bỏ vào mấy cái Excel là nó tính rẹc phát ra ngay nên chúng ta cũng không quan tâm sâu tới những vấn đề đó mà chỉ chú ý là lương cao thì trách nhiệm thuế sẽ cao theo là thiết kế của khá nhiều hệ thống thuế TNCN của nhiều nước. Vậy giờ có mấy con đường?Xin hãy nhìn vào biểu đồ bên dưới: hầu như chỉ có 2 nhánh  Làm thuê: thì lại phân nhánh làm 4 con đường con     Làm cho hàn lâm như làm giảng viên, các vị trí trong trường đại học, nghiên cứu tại viện, …   Làm cho chính phủ/NGO. Tuy nhiên hướng này hơi khó vì ít vị trí nên trong bài điều tra này xin phép không bàn về con đường này.    Làm cho công ty lớn. Đây là hướng chủ đạo của mọi anh em không đi hai con đường trên: kiếm doanh nghiệp kiểu quốc doanh, phúc lợi dồi dào ổn định để mưu cầu sự nghiệp … an bài.    Làm cho công ty nhỏ/ khởi nghiệp. Đây là con đường mạo hiểm bởi không biết nó sập lúc nào. Chúng ta sẽ đi sâu vào sau, nhưng nhìn chung cty nhỏ hay khởi nghiệp vốn không thể lớn như công ty lớn. Có một dạng thú vị là các công ty khởi nghiệp xuất phát từ 1 nghiên cứu trong academics mà tôi sẽ bàn trong bài viết này.     Khởi nghiệp: tức là không làm thuê cho người khác mà tự mở ra mà làm lấy. Làm thuêThực ra mấy cái mảng này thì cũng có nhiều surveys có sẵn rồi và với các bạn trẻ cũng chỉ quan trọng là nhìn thấy mấy con số đáng tin cậy để quyết định hướng đi sự nghiệp nên tôi cứ phang thẳng các bài survey có nhiều citations vào nhé. Làm cho khởi nghiệp và công ty nhỏ vừa: Hướng đi mang tính entrepreneur này có vẻ mạo hiểm với cả chủ lẫn tớ: công ty chả biết lúc nào “sập”?Một bài survey dưới góc độ employee xem tại sao họ lại chọn hướng đi làm thuê cho khởi nghiệp mà tôi thích là bài của Nystrӧm [1] ngay vừa 2021 rồi. Hiểm nguy đi cùng khởi nghiệp sẽ bao gồm:  Great uncertainty tức là bấp bênh, lúc có việc, lúc rảnh thôi rồi.  Low wages lương thấp tẹt vì bản thân khởi nghiệp cũng đang chờ vốn.  Và khả năng công ty không sống sót. Có suy thoái kiểu 2008 hay dịch Covid 19 là một loạt chết trắng bụng!Vậy những tên dở người (insane) nào lại đi làm cho khởi nghiệp và các công ty nhỏ? Đầu tiên chúng ta cũng cần hiểu quy trình tuyển dụng dù công ty nhỏ hay lớn thì cũng sẽ đại loại là trước khi hai bên bắt tay nhau thì phải có một quá trình matching. Vấn đề là employer cũng không có ngay được thông tin về skill cũng như abilities của employee và ngược lại employee cũng không biết được là cái khởi nghiệp này nó có skill và tiềm năng ra sao. Cái này trong lĩnh vực này gọi là information assymmetry, tức là sự thiếu thông tin về nhau của hai bên khi tiếp xúc. Tất nhiên khi hai bên đang thiếu thông tin về nhau như vậy, việc tìm điểm cân bằng equibilirum là cần thiết. Theo [1] thì trong một survey ở labor market Thụy Điển thì sinh viên đại học bên đó đặt các yếu tố sau lên đầu khi tìm việc:  Lương khởi điểm cao Cơ hội phát triển bản thân và có training Cơ hội làm việc lâu dài Môi trường làm việc năng động và phát triển tốt. Một điểm thú vị [1] là trong những người làm việc R&amp;D (cả chuyển việc lẫn mới tốt nghiệp) thì yếu tố quan trọng nhất với họ không phải lương hay job security mà là independence và responsibilty (sự độc lập và trách nhiệm). Tức là lương cao và chuyện không hợp hoặc công ty chết thì nhảy việc thì không quan trọng với người làm R&amp;D, mà quan trọng với họ là được làm việc độc lập (được làm chủ nghiên cứu của mình và toàn quyền quyết định) và trách nhiệm rõ ràng. Ngoài việc lương bèo thì những nguy cơ tiềm ẩn như làm việc nhiều giờ, stress cũng dai dẳng với các nhân viên của công ty khởi nghiệp. Và Nystrӧm cũng chỉ ra kết quả thú vị: hầu như khởi nghiệp và cty vừa nhỏ chỉ thuê được các vị trí yếu hơn so với các công ty lớn. Doner và cộng sự [2] cũng nghiên cứu về lương khởi nghiệp có thể trả nhưng tập trung vào academics spin-offs tức là khởi nghiệp xuất phát từ academics. Những nhà sáng lập xuất thân từ academics hoặc từ 1 nghiên cứu nào đó trong academics. Câu hỏi nghiên cứu ở đây là liệu spin-offs có sẵn sàng trả cao cho nhân viên không?Các tác giả tập trung vào bộ dữ liệu spin-offs ở Đức và thật thú vị sau khi họ làm mấy cái regression test linh tinh và đưa ra kết quả cũng không mới lắm: spin-offs dù nhận vốn academics (có thể dồi dào hay không biết) nhưng cũng không trả cao đâu!Họ cũng chỉ ra rằng một nhận định cũ rằng spin-offs có tốc độ mở rộng quy mô nhân sự cao hơn các khởi nghiệp khác là sai vì số liệu của họ cũng không chỉ ra significance nào. Mất công làm một đống regression tests mà kết quả là lương cũng không cao hơn là bao thì quả cũng của đáng tội! Nhìn con số từ Đức và Thụy Điển có vẻ không khả quan lắm, nên tôi chuyển hướng nhìn sang Mỹ xem sao. Thế là có ngay bài điều tra của Kim [3] ngay năm 2018 thôi nên số liệu thực tế và rất mới. Dữ liệu dựa trên khởi nghiệp xuất phát từ OB của MIT. Thì thật thú vị là nhóm VC-backed tức là được nhận đầu tư của VC thì có thu nhập khá hơn 10% (non-founder employees) so với mặt bằng chung. Sau khi thêm hiệu ứng cố định (fixed-effect) dựa trên quan sát là nhiều employees nhận multi-offers thì con số lại không significant lắm, chứng tỏ là việc được VC đầu tư sẽ dẫn tới lương trả cao lên. Và điều đó cho thấy ở Mỹ thì nên tìm vào khởi nghiệp có VC! Một bài điều tra thú vị khác về chất lượng của job từ khởi nghiệp được Block và cộng sự [4] hoàn thành cũng vào năm 2018. Chủ yếu là vì khởi nghiệp thì tạo ra công ăn việc làm, nhưng công ăn việc làm ấy chất lượng có cao không?Thì kết quả là chất lượng thấp: phần lớn là lương thấp, bonus bèo hoặc không có, bảo hiểm cũng bấp bênh, công việc cũng không biết công ty chết lúc nào. Block nói chung cũng không đưa ra được dấu hiệu cho thấy đãi ngộ khấm khá hơn là bao. Tôi nghĩ mấy cái Block này chắc cũng là tình hình chung của mảng này rồi nên thôi chắc mình cũng không nên mất công vào kẻo lại của đáng tội! Thôi điều tra một hồi thấy đến cả mấy cái work của Block [4] mà cũng chỉ được bèo như vậy thì chắc làm thuê cho khởi nghiệp mình đọc đến đây thôi!Đổi mới sáng tạo thì cũng thú vị lắm nhưng nghèo thì gượm để suy nghĩ đã :)) Làm cho hàn lâm:  Làm cho hàn lâm có mong giàu không? Nhìn chung là cũng có lý do tại sao đi dạy đi nghiên cứu lại mong giàu: Nghiên cứu của Currall và cộng sự [5] vào năm 2005 trên tập giáo viên từ gần 7,000 trường học ở Mỹ cho thấy, độ thỏa mãn về lương lậu có tương quan dương với hiệu suất làm việc ở trường và tương quan âm với ý định bỏ việc của giáo viên. Tức là lương lậu OK thì sẽ không bỏ việc và hiệu suất lại tốt hơn. Tất nhiên độ thỏa mãn về lương lậu cũng chỉ là survey kiểu lương có đủ sống không em? chứ chưa nói đến giàu, nhưng qua đây cũng thấy là lương mà không cao là giáo viên cũng bỏ dạy đấy. Đấy là ngành dạy dỗ nhé, nhưng còn ngạch nghiên cứu thì sao?Lại có bài của Stern [6] năm 2004. Ô đọc xong mà lại thấy nghèo quá!Kết quả chỉ ra 1 tương quan âm giữa lương và độ khoa học trong tổ chức: những cơ quan nghiên cứu mà cho phép nhà nghiên cứu xuất bản bài báo và hội nghị thì nhận được 25% discount trong lương. Tức là nhà nghiên cứu sẵn sàng nhận lương thấp đi 25% nếu cho phép họ xuất bản bài báo lên tạp chí khoa học uy tín hoặc hội nghị lớn. Thế thì nghèo!Thế nên xuất bản papers là chấp nhận nghèo đi đấy anh em ạ! Mấy cái nghiên cứu này cũng dựa trên giả thuyết multi-offers rồi lại làm mấy cái fixed-effect regression tests, thế mà xong lại ra lương không cao hơn mà lại thấp đi 25% thế này thì có lẽ cũng không cần điều tra hướng này sâu thêm nữa!Mà lại còn nhiều thử thách, ví dụ như muốn hợp tác nghiên cứu với industry mà hay gọi là University-Industry (UI) collaboration, thì cái UI này cũng tù lắm: vừa bị control của trường đại học (university administration) lại còn vấn đề sở hữu trí tuệ (IP) của doanh nghiệp. Nói chung là có nhiều thử thách, mà thế mới đúng vì có làm thì mới có ăn. Làm cho công ty lớn: Đây là hướng đi còn lại trong nhánh Làm thuê và cũng là phổ biến nhất trong nhóm lao động trẻ mới tốt nghiệp ra trường. Nhìn chung vì nó là đại trà nên lương ở mức mặt bằng chung, phúc lợi thì công ty này công ty kia nó cũng same same. Anh em trải qua hết rồi cũng chả có thấy điểm ưu trội nào mấy. Thôi thì xem thử có bài nào hay hay thì thấy có bài của Andersson và cộng sự [7] xuất bản năm 2009 về câu hỏi những công ty nào sẽ trả tiền thuê talents?Thì thu nhập cũng phải hiểu là có thu nhập khởi điểm và thu nhập khi đã có kinh nghiệm. Ngoài ra còn stock options nữa cũng là một yếu tốt trong thu nhập khi đi làm thuê. Hay là nghiên cứu này lại tổ chức trên đúng tập dữ liệu là các công ty software ở Mỹ nên có lẽ rất phù hợp cho ngành IT. Thì câu hỏi là những công ty như thế nào sẽ trả lương cao và họ sẽ trả cao cho nhân viên như thế nào?. Nhóm của Andersson chỉ ra rằng những công ty ở khu vực đầu tư mạo hiểm (thắng thì sẽ thắng lớn nhưng thua thì cũng dặt dẹo) thì sẵn sàng trả cao để thu hút nhân tài. Thế nên là anh em thấy những dự án thử thách mạo hiểm thì cứ nhảy vào chiến thôi, đừng lo “sập”!Chỉ cần lo chiến đấu thôi! Khởi nghiệpLàm thuê thì có vẻ cũng hòm hòm vậy, đi vào chỗ nào lương sẽ như thế nào là đã có hình dung trong đầu nên tôi nghĩ chắc cũng chả có gì mới nữa. Xem khởi nghiệp tức là mình mở hẳn công ty của mình xem có khá khẩm hơn không nào? Đặc điểm của khởi nghiệp: Đầu tiên là vấn đề ý tưởng thì có bài của Homfeldt và cộng sự [8] ngay năm 2019. Họ trả lời câu hỏi liệu ý tưởng của startups có thực sự mới mẻ hơn của các công ty lớn không?  We find that start-ups’ ideas are characterized by a higher degree of novelty and to some extent higher benefit for end customers but, on the downside, are less likely to be implemented than suppliers’ ideas. Câu trả lời là ý tưởng thì đúng là có vẻ tân tiến nhưng lại kiểu ít có khả năng thực thi hơn của công ty lớn. Tức là mới nhưng mà hơi mơ mộng. Thì đúng là vậy, ý tưởng mới sẽ khó được đón nhận ngay và thường bị xem là mơ mộng, viển vông. Nhưng qua thời gian nếu startup trụ vững và chứng minh được thì nó lại thành hiện thực và startup sẽ cất cánh. Rủi ro lớn nhất là startup không thực hiện được thôi, nhưng đó không phải vấn đề mới mà là vấn đề chung của mọi startup hiện nay! Khi khởi nghiệp thì nếu xuất phát từ 1 nghiên cứu hàn lâm thì startups sẽ được gọi là spin-off [9], [10]. Khi xây dựng spin-off thì sẽ phải chú ý vấn đề hướng và chiến lược (EO) cũng như xây dựng đội ngũ. [10] cũng chỉ ra một số yếu tố hỗ trợ vấn đề hướng là  Sự có mặt của 1 quản lý không phải academics (non-academics manager) trong đội ngũ quản lý Có vốn của VC Hỗ trợ của tổ chức chuyên tài trợ spin-off trong chuyển giao công nghệTrên đây có vẻ là yếu tố chiến lược hỗ trợ spin-off phát triển. Rồi làm khởi nghiệp còn phải đau đầu lo vấn đề hợp tác mà thực ra là mua affiliation [11]. Không có affiliation thì chẳng có publish gì cả vì reputation thấp. Muốn reputation cao thì lại phải dựa vào những affiliation là VC có reputation cao. Đấy là nếu gọi vốn VC, còn nếu gọi vốn crowdfunding [12] thì cũng là hướng mới mà nhiều anh em đang làm nhưng nói chung gian nan lắm. Thu nhập của nhà khởi nghiệp: Quay lại chủ để chính là thu nhập. Thì có bài của Åstebro và cộng sự [13] năm 2013 cũng nghiên cứu trên tập các nhà sáng lập xuất thân từ academics xem thu nhập của họ có khá lên sau khi rời academics không?Đau cái là nó lại không khá lên, qua thống kê của Åstebro và cộng sự thì thu nhập before/after khởi nghiệp nó lại như nhau: trước khi khởi nghiệp thì thu nhập trung bình là 397,000 (39. 7 man) còn sau khi khởi nghiệp bình quân là 450,000 (45 man). Mà phương sai lại cao gấp 3 lần tức là sau khi khởi nghiệp thu nhập lại “bấp bênh” hơn. Ngoài ra 60% những nhà khởi nghiệp này lại từ bỏ khởi nghiệp trong vòng 2 năm và 66% lại quay trở về academics! Kết luậnNói chung Có làm thì mới có ăn là chân lý của lao động rồi. Bài điều tra điểm qua hầu hết mọi hướng đi khả thi, trừ hướng chính phủ/NGO chưa muốn động vào. Nhưng nhìn chung là làm thuê thì chấp nhận là lương sẽ chỉ cao nếu đi đúng đường. Còn tự thân khởi nghiệp thì nghĩ béo bở nhưng đau đầu và thực tế là cũng chả tăng thêm thu nhập bao nhiêu (từ 39. 7 man lên 45 man), mà phần lớn (60%) là thất bại sau 2 năm [13]. Thế nên quay lại câu hỏi là nếu làm R&amp;D khởi nghiệp mà không béo bằng đi làm thuê phát triển thì có nên làm nghiên cứu không? thì tôi nghĩ là tùy mỗi người thôi, nhưng nhìn quan điểm là thu nhập thì có lẽ con đường đi nghiên cứu nó không thông minh lắm đâu! Tài liệu tham khảoNyström, K. 2021. Working for an entrepreneur: heaven or hell? Small Business Economics. 56, 2 (2021), 919–931. DetailsDorner, M. , Fryges, H. and Schopen, K. 2017. Wages in high-tech start-ups–Do academic spin-offs pay a wage premium? Research Policy. 46, 1 (2017), 1–18. DetailsKim, J. D. 2018. Is there a startup wage premium? Evidence from MIT graduates. Research Policy. 47, 3 (2018), 637–649. DetailsBlock, J. H. , Fisch, C. O. and Van Praag, M. 2018. Quantity and quality of jobs by entrepreneurial firms. Oxford Review of Economic Policy. 34, 4 (2018), 565–583. DetailsCurrall, S. C. , Towler, A. J. , Judge, T. A. and Kohn, L. 2005. Pay satisfaction and organizational outcomes. Personnel psychology. 58, 3 (2005), 613–640. DetailsStern, S. 2004. Do scientists pay to be scientists? Management science. 50, 6 (2004), 835–853. DetailsAndersson, F. , Freedman, M. , Haltiwanger, J. , Lane, J. and Shaw, K. 2009. Reaching for the stars: who pays for talent in innovative industries? The Economic Journal. 119, 538 (2009), F308–F332. DetailsHomfeldt, F. , Rese, A. and Simon, F. 2019. Suppliers versus start-ups: Where do better innovation ideas come from? Research policy. 48, 7 (2019), 1738–1757. DetailsRodrı́guez-Gulı́as Marı́a Jesús, Fernández-López, S. , Rodeiro-Pazos, D. , Corsi, C. and Prencipe, A. 2018. The role of knowledge spillovers on the university spin-offs innovation. Science and Public Policy. 45, 6 (2018), 875–883. DetailsDiánez-González, J. P. , Camelo-Ordaz, C. and Fernández-Alles, M. 2021. Drivers and implications of entrepreneurial orientation for academic spin-offs. International Entrepreneurship and Management Journal. 17, 2 (2021), 1007–1035. DetailsHsu, D. H. 2004. What do entrepreneurs pay for venture capital affiliation? The journal of finance. 59, 4 (2004), 1805–1844. DetailsMollick, E. 2014. The dynamics of crowdfunding: An exploratory study. Journal of business venturing. 29, 1 (2014), 1–16. DetailsÅstebro, T. , Braunerhjelm, P. and Broström, A. 2013. Does academic entrepreneurship pay? Industrial and Corporate Change. 22, 1 (2013), 281–311. Details"
    }, {
    "id": 294,
    "url": "https://wanted2.github.io/rapidapi/",
    "title": "RapidAPI and RapidAPI Hub",
    "body": "2022/01/09 - Image Credit: FinanceFeeds Rakuten launched RapidAPI Marketplace in 2018 as a result of the collaboration between Japan’s Rakuten Inc and San Francisco-based startup RapidAPI. The API marketplace aims to provide software developers in Japan and Asia unified access to more than 8,000 APIs with localized documentation and resources in Japan’s language and English. The API marketplace platform will connect API providers and developers. Developers in Japan and across Asia will be able to find, test, and connect to thousands of APIs for their applications. The marketplace will also allow API providers to connect with the global developer community through personalized API portals.  What is RapidAPI?Let us assume that you have an API that is ready for production. You need to add authentication like API key, OAuth 2, or something else. You need to deploy your API to somewhere that is stable and reliable.  What is the shortest path to achieving your goal? You are an application developer, and you need to manage the records of some data for the app. For example, you need to maintain the list of public holidays in your app. You don’t want to hardcode those things in the code. Note that the public holidays change between countries and sometimes due to the law it will change between years. It is somewhat troublesome to maintain the records in your database as it will make you allocate some effort and human resources there.  What is the most convenient way to maintain such data? In both scenarios, Rakuten RapidAPI Marketplace gives you excellent solutions. Either maintenance of the data (public holidays) or publishing a new API, you can do all of the lifecycles in one platform. For example, when you want to check a day is a holiday or not, you can thus search for a free API like this one and make a request. Because all maintenance is up on the providers, this solution costs you nothing: you don’t need to worry about maintaining the records of holidays data (which shouldn’t be your matter in any way) and focus on your own application logic. Note that the Public Holidays API has low latency (59ms) and is completely free. Another solution is to build an endpoint in your own API like /api/v1/holidays to validate the holidays, but while such a ready-to-use solution is there, why should you waste time and money to build/manage/maintain on your own? RapidAPI helps your API to distribute and monetize. Adding your API to the RapidAPI Hub gets you instant exposure to our growing user base, a search-engine-optimized profile page for your API, as well as features like user management and billing services. RapidAPI also serves functional testings, API monitoring dashboards, and many other premiere features like API authentication. RapidAPI for API VendorsThe workflow between an app developer’s client to a vendor API can be as follows:  An API Key is generated and appended to the request’s header to RapidAPI servers.  RapidAPI authenticate the request (using API Key and optionally a configured authentication method like OAuth 2). Then it modifies the requests header to append X-RapidAPI-* headers.  The vendor API (destination API in the diagram) checks the X-RapidAPI-* headers and authenticates the modified requests.  A response is generated according to the requested information and is then returned to RapidAPI.  RapidAPI modifies the response from vendor servers. It appends Rapid API headers (for example, headers about rate limits) or generates a new response. As you can see, RapidAPI Marketplace acts as a proxy between app servers (client in the diagram) and the vendor API servers. The vendors register their APIs and fine-tune the settings in RapidAPI dashboard. All API endpoints are relative to a base URL, which is added as a “prefix” to all API endpoints. This approach avoids the need to define absolute URLs for endpoints every time and increases API portability by changing the base URL. API vendors can add basic authentication or OAuth 2 to their APIs. RapidAPI supports automatic API provisioning using OpenAPI and custom transformations. RapidAPI has basic plan options so app developers can choose among these options to pay:       API Type   Description         Free APIs   APIs that do not require a credit card or subscription to consume.        Pay Per Use   APIs that don’t have a subscription fee associated with them. A credit card is required as you pay for what you use on the API.        Freemium APIs   Paid APIs that also include a limited free tier. These require a credit card, even for the free plan.        Paid APIs   APIs that require a paid subscription plan and credit card to consume.    Some notes on security: RapidAPI supports secret headers and parameters:  RapidAPI allows you to add secret headers and/or query string parameters to API requests. The RapidAPI proxy adds these secrets to every request but is hidden from the API consumers. Note that even the consumers who make the requests do not know about these secrets. This differs from header and query authentication methods where consumers know all secrets in the requests they make to RapidAPI. Users should configure RapidAPI security features like firewalls, threat protection, schema validation, and request size limit (which returns error code 413). Vendors can set their API to private where only invited users can access. Audit and marketing tools: RapidAPI provides Provider Dashboard where vendors can monitor their API usages. Another nice thing is that as a vendor, you can make your monetization more useful using Marketing API. When you have an API, you should make sure you don’t miss a checklist when publishing your solution: This checklist helps you have a better SEO for your API. API Testing: Testing is quite tedious!RapidAPI helps vendors reduce testing costs with their API testing feature.  If you are already familiar with postman-tool you are ready to go with RapidAPI advanced testing.  RapidAPI for App DevelopersAs an app developer, you can find that RapidAPI Hub now has more than 10,000 APIs. Even you want to develop an OCR app or a Translation app, you can find your API right away. All you need is to register a RapidAPI account, choose your API and then make a payment. Finally, you can connect to your paid API using the API key.  ConclusionIt is worth noting that RapidAPI supports not only REST API but also GraphQL, SOAP, and Kafka APIs. We did not touch RapidAPI for Teams, but it might be useful at the organization level. "
    }, {
    "id": 295,
    "url": "https://wanted2.github.io/new-year/",
    "title": "Chào 2022 và câu chuyện khoảng cách công nghệ giữa các quốc gia, tổ chức",
    "body": "2022/01/01 - Năm 2021 đã kết thúc và cũng là lúc để nghĩ đến dự định cho năm 2022. Bản thân AiFi luôn nhắm đến mục tiêu lấy chứng chỉ Project Manager (PM) trong thời gian ngắn nhất có thể. Ngoài ra, tất nhiên nâng cao năng lực quản lý cũng là một bước chuẩn bị tốt nhưng quan trọng hơn vẫn là nhanh chóng xây dựng roadmap để sớm launch một cái gì đó thú vị, ví dụ như 1 công ty chẳng hạn. Có lẽ thời điểm đầu xuân cũng là lúc phù hợp để chốt các mục tiêu cho năm 2022 và lên kế hoạch. Tất nhiên cũng cần hiểu là năm 2022 vẫn chỉ là một năm chuẩn bị thôi. Cuối cùng là một chút tản mạn về chủ để khoảng cách công nghệ giữa các quốc gia, firm. Dự định 2022Trong công việc: Trong công việc thì cứ tiến hành như bình thường. Cố gắng duy trì nhịp độ làm việc và sớm chuyển sang Nhật Bản. Phát triển bản thân: Về mặt quản lý: Bản thân AiFi luôn nhắm đến mục tiêu lấy chứng chỉ Project Manager (PM) trong thời gian ngắn nhất có thể. Tuy nhiên, đó là một việc không thể nhanh chóng vì PMI [1] đòi hỏi:  36 tháng (3 năm) kinh nghiệm PM (PM experience, không nhất thiết vị trí PM). Tuy nhiên, có vẻ là thường những người dự thi đều có khoảng 7-10 năm kinh nghiệm PM. Tức là các bác có nhiều năm kinh nghiệm mới đi thi. Nên một giá trị phù hợp là làm PM khoảng 3 năm thì nghĩ đến chuẩn bị PMP, rồi khoảng năm thứ 4 hoặc thứ 5 thì đi thi là tốt, còn bình thường chắc tầm năm thứ 7 trở ra đi thi thì chắc ăn hơn.  35 giờ học hướng dẫn (contact hours, hay 35 PDUs). Việc lấy 35 PDUs có thể hoàn thành thông qua 1 khóa khoảng chục triệu của 1 đối tác của PMI ngay tại Hà Nội nên cũng sẽ nhanh chóng thôi và lấy lúc nào cũng được. Có nhiều bạn sẽ thắc mắc là cứ làm việc thôi chứ cần gì phải lấy chứng chỉ PMP?Thực ra thì cũng đúng vì nếu đã có kinh nghiệm 7-10 năm làm PM rồi thì chứng chỉ mang tính chất vật biểu trưng việc mình là professional nhiều hơn. Tuy nhiên, theo thống kê của PMI bên Mỹ thì những PM có chứng chỉ PMP thì thu nhập tăng lên 25% so với các bạn PM không có PMP. Do đó, theo tôi nghĩ vẫn nên có chứng chỉ PMP!Bạn cũng nên biết là PMI cũng khá khắt khe trong tiêu chí dự thi, nếu 3 năm kinh nghiệm mà không phải kinh nghiệm PM thì họ cũng không chấp nhận cho thi. Vì vậy, lấy được chứng chỉ PMP của PMI tôi nghĩ là một achievement không nhỏ!Ít nhất là chúng ta cũng đã hiểu được góc nhìn của PM rất khác so với Dev và vì vậy, bắt buộc phải chuẩn bị kinh nghiệm PM thì mới được thi PMP. Bản thân tôi ở vị trí BrSE là một vị trí mà nghiệp vụ thì nói chung là overlap khá nhiều với PM, tức là có PM experience. Năm 2022 chắc sẽ là 1 năm dài chuẩn bị cho PMP. Mục tiêu là hè 2023 có thể bắt đầu tính đến dự thi PMP. Năm 2021 cũng đã là 1 năm khá dài và cũng có ích:  Việc học sách PMBok mất khoảng nửa năm cũng có giá trị.  Việc thực hành quản lý các dự án nội bộ của công ty cũ cũng có giá trị kinh nghiệm nhất định. Về mặt kinh doanh, khởi nghiệp: Làm dev thì nói chung là “tù”, vì đôi khi kiểu “chỉ đâu đánh đấy”, bao nằm nghiêng thì nghiêng mà nằm ngửa thì ngửa. Tức là không có bức tranh lớn, nghe theo sự sai bảo của quản lý. Có câu chuyện hài hước là có lần tôi làm quản lý mà có cậu dev làm lead mà cứ kiên quyết đòi làm 1 chức năng mà thực ra có lẽ không làm thì tốt hơn. Bởi vì là bỏ thì thương mà vương thì tội, làm thì mất công mà thu lại chả được mấy đồng bạc. Nhưng vì cậu là lead nên cũng ậm ừ để cho cậu có thể diện mà nói chuyện với đàn em, chứ còn nói thực là có khi không sửa cứ để thế nó còn tốt hơn. Khổ nỗi nếu sửa thì em lại phải theo nó đến cùng em ạ!Những trường hợp này ấy thì theo kinh nghiệm của tôi cứ đẩy hết về owner, bởi trong hệ thống tự nhiên có 1 cái gì đó nó bất hợp lý thì chắc chắn là nên để cái ông nắm business chịu trách nhiệm. Đấy, nên nói chung làm dev là “tù” lắm, không đi đến đâu cả đâu. Năm 2022, mặt quản lý thì chắc lại tiếp tục thực hành thực chiến tích lũy tự tin để năm sau nữa đi thi PMP thôi. Còn làm dev thì không cần. Vì vậy, chỉ còn một chuẩn bị là mặt kinh doanh, khởi nghiệp. Có lẽ bước chuẩn bị trong năm 2022 sẽ là tập dượt xây dựng một community theo chủ đề nhất định. Có lẽ trong năm 2022 sẽ khám phá “lại” một lĩnh vực công nghệ nào đó, theo kiểu đào sâu và tìm mới. Khoảng cách công nghệCâu chuyện 7 năm trước:  Knowledge is inherently a public good. (Jaffe, 1986 [2]) Tri thức về cơ bản là một tài sản chung (trích Jaffe &lt;a class= citation  href= #jaffe1986technological &gt;[2]&lt;/a&gt;). Nó mang hai hàm nghĩa:  Thứ nhất, không thể giấu giếm tri thức làm của riêng (nó khác với trí tuệ là thứ có thể được đăng ký bảo hộ).  Thứ hai, tri thức có thể lan tỏa như thông tin. Câu chuyện về khoảng cách công nghệ có nguồn gốc từ 7 năm trước, khi tôi còn tham gia một chương trình lãnh đạo trẻ. Thật thú vị là trong một bài thuyết trình cuối khóa về thành tích thực tập tại các công ty. Khi đó một điều kiện bắt buộc tham gia chương trình lãnh đạo trẻ là sẽ phải tham gia thực tập vài tháng tại 1 doanh nghiệp ở nước ngoài (nhưng không được là doanh nghiệp ở quốc gia của chính mình, tránh cảnh tranh thủ về nước). Có nhiều người xin sang châu Âu, Mỹ để làm intern ngắn hạn. Trong các bạn lúc đó phát biểu có một sinh viên PhD khi đó lên thuyết trình, nhưng chỉ sau 2 slide giới thiệu cậu ta kết thúc rằng vì đã ký NDA với doanh nghiệp lớn ở Mỹ về lĩnh vực phần mềm (lớn nhất thế giới) nên không thể trình bày tiếp. Tất nhiên là thanh niên đó đã lĩnh đủ của các giáo sư vì ở trong trường đại học cái quan trọng nhất chính là tri thức, mà tri thức thì là public good.  Đến khi nào anh hiểu được rằng những tri thức vĩ đại và to lớn mà người ta hay gọi là trí tuệ ấy, luôn tồn tại dưới vỏ bọc tầm thường và vớ vẩn, thì anh mới hành động như người có tri thức được. Bây giờ tôi thấy cái trường hợp này đúng là cần phải hiểu là chỉ cần làm mấy cái vớ vẩn, cũng không cần phải to tát rồi không dám chia sẻ mất đi ý nghĩa tri thức trong hàn lâm. Và có lẽ cũng đúng như lời người thày lúc ấy nói, thực ra những công nghệ to tát và vĩ đại có khi thực ra là những thứ vớ vẩn thôi mà phải không? Đến câu chuyện R&amp;D spillovers và knowledge diffusion: Các nghiên cứu về mối tương quan giữa không gian công nghệ, lợi nhuận và giá trị thị trường của các firm đã có từ khá lâu. Thật thú vị là câu chuyện kể trên lại khá liên quan bởi công nghệ chốt trong phần nghiên cứu PhD đó lại vốn là một tri thức đã phổ biến và được đào sâu nghiên cứu ở trong hàn lâm. Do vậy, ở mức độ nào đó dù là đăng ký bản quyền cho một thứ mà giới hàn lâm đã coi là public good thì nó rất là … vớ vẩn. Tất nhiên chuyện đăng ký bản quyền là thể hiện giá trị R&amp;D trong các doanh nghiệp, và là một phần quan trọng trong cái gọi là tương tác khoa học giữa hàn lâm và giới công nghiệp. Trong nhánh nghiên cứu này có thể kể đến công trình của Jaffe [2], [3] và rất nhiều công trình sau đó của các nhà nghiên cứu khác. Thì có lẽ có một khái niệm khá quan trọng là technological space tức là không gian công nghệ. Ở đây, Jaffe đã xây dựng 1 vector 49 chiều (thu gọn từ 328 classes trong hệ thống patent toàn cầu) để biểu diễn vị trí của 1 firm trong không gian công nghệ. Ví dụ, hệ thống patent toàn cầu có phân nhóm lĩnh vực thành 328 classes, thì tác giả Jaffe đã group lại thành 49 categories bao quát nhất mọi lĩnh vực công nghệ. Giả sử công ty $A$ có $N$ patent thuộc 49 categories trên (đánh số từ 1) thì $f_i(A),~i=1,2, \ldots $ là số lượng pattern của $A$ trong lĩnh vực $i$, thì $\sum_{i=1}^{49} f_i(A)=N$ và vector biểu diễn của công ty A (technological vector) là $F_A=\begin{bmatrix}f_1 \newlinef_2 \newline\vdots \newlinef_{49}\end{bmatrix}$ với $f_i=\frac{f_i(A)}{N},~i=1, 2, \ldots $. Cứ như vậy, các điểm vector đều nằm trên một mặt phẳng (hyperplane) 49 chiều $\sum_{i=1}^{49}x_i=1$. Khi 2 công ty có cùng một mối quan tâm về 1 công nghệ nào đó thì bằng chứng sẽ là về mặt R&amp;D ở lĩnh vực đó ($i$ chả hạn) chỉ số sẽ cao lên. Jaffe đã nghiên cứu về một hiện tượng thú vị trong innovation đó là R&amp;D spillovers [2], [3], hay là sự khuếch tán của tri thức R&amp;D, hay là knowledge diffusion. Nghiên cứu của Jaffe vào năm 1986 chủ yếu dựa trên quan sát của những người đi trước rằng khi có một công ty trong một lĩnh vực nào đó nâng cao đầu tư vào R&amp;D thì đột nhiên những công ty xung quanh cũng bắt đầu phải chạy theo đầu tư vào mảng đó.  Firms whose research is in areas where there is much research by other firms have, on average, more patents per dollar of R&amp;D and a higher return to R&amp;D in terms of accounting profits or market value, though firms with very low own—R&amp;D suffer lower profits and market value if their neighbors do a lot. Tức là nếu trong cùng 1 mảng mà cty đầu tư nhiều hơn vào R&amp;D so với các công ty khác cùng lĩnh vực thì sẽ có giá trị thị thường lợi nhuận cao hơn. Và ngược lại nếu đầu tư ít hơn các công ty neighbors thì sẽ bị thụt lùi về lợi nhuận lẫn giá trị thị trường. Điều này cũng giải thích tại sao các tập đoàn công nghệ lớn không tiếc tiền đầu tư để đứng đầu một lĩnh vực nào đó so với các công ty lân cận. Ở đây chúng ta cũng cần hiểu khái niệm neighbor (lân cận) là hiểu theo nghĩa địa lý (geographical). Rất nhiều nghiên cứu theo sau Jaffe về sau đều chỉ ra mối correlation mạnh giữa khoảng cách địa lý và khoảng cách trong không gian công nghệ (đo bằng vector 49 chiều) [3], [4]. R&amp;D spillovers không chỉ tồn tại trong các firms cùng lĩnh vực mà còn tồn tại giữa hàn lâm và công nghiệp theo Jaffe, 1989 [3]. Thì nghiên cứu hàn lâm lại có vẻ thúc đẩy tiến bộ trong các công ty xung quanh (gần về địa lý) hoặc có hợp tác với trường đại học ấy [3]. Khá nhiều nghiên cứu về spillovers (knowledge diffusion) đã trải thành một mạch dài từ sau Jaffe, 1986 [2]:David và cộng sự [5] thì nghiên cứu về tác động của public R&amp;D trong việc kích hoạt private R&amp;D. Baptista và Swann [6] cũng chỉ ra khá nhiều bằng chứng cho thấy “tốt nhất là đi cùng nhau” giữa các firm trong cùng cluster. Những nghiên cứu về open innovation [7], [8] cũng cho thấy benefits của kinh tế từ R&amp;D trong các trường đại học. Trên đây là để hiểu rõ nguồn gốc của đống nghiên cứu đã có. Tại sao lại có cái đống này, và có căn bản. Gần đây từ những năm 2020 trở ra có cái gì thì cũng chịu khó xem thì thấy vẫn có người làm theo hướng này kha khá:Sun và cộng sự [9] thì tập trung vào vấn đề tối ưu hiệu suất sử dụng năng lượng như 1 benefit của R&amp;D spillover. Fini và cộng sự [10] thì cho thấy là nếu nhà nghiên cứu khởi nghiệp và đóng góp cho việc diffuse tri thức thì sẽ tăng hiệu suất nghiên cứu lên. Ufuk và cộng sự [11] thì nghiên cứu trên tập dữ liệu của Pháp thì thấy rõ spillovers đang bị lệch về phía nghiên cứu ứng dụng mà ít về phía nghiên cứu cơ bản. Hsu và cộng sự [12] thì nghiên cứu về vấn đề Trung Quốc: spillovers tại Trung Quốc. Martinez và cộng sự [13] thì trả lời vấn đề crowdfunding ảnh hưởng tới spillovers ra sao. Nhìn chung là  Đến khi nào anh hiểu được rằng những tri thức vĩ đại và to lớn mà người ta hay gọi là trí tuệ ấy, luôn tồn tại dưới vỏ bọc tầm thường và vớ vẩn, thì anh mới hành động như người có tri thức được. Kết luậnChào 2022! Và coi như bắt đầu một năm mới nhiều dự định cũng như kế hoạch. Luôn có những quy luật xã hội nhất định chi phối cộng đồng của chúng ta: ví dụ như các công ty trong giới công nghiệp cũng như trường đại học sẽ có những tương tác qua lại, tạo nên một mô hình spillover (diffusion) tồn tại mãi mãi trong chúng ta. Tương tác qua lại giữa các firm trong cùng một cluster đôi khi có ích: 1 tiến bộ R&amp;D từ 1 cty có thể tạo ra lợi ích cho các công ty khác. Điều đó có cái tốt mà cũng đôi khi không: khi có một công ty gia nhập vào 1 lĩnh vực, nếu công ty đó cùng stack công nghệ với cty bạn thì nên welcome, còn không thì phải đối xử với nó như rival. Bởi vì nếu cùng stack công nghệ thì R&amp;D của công ty đó có tiến bộ gì thì mình sẽ được hưởng lợi. Ngược lại, nếu khác stack công nghệ và lại cùng bán 1 sản phẩm thì rõ ràng tiến bộ của họ không hề có ích gì cho mình mà lại tranh giành thị trường với mình. Do đó, phần lớn các công ty giống nhau cả về sản phẩm lẫn stack công nghệ thì cuối cùng cứ tập trung lại thành 1 cluster và spillover (diffuse) cùng nhau. Tài liệu tham khảoPMA PMP Certification Requirements | Project Management Certification &amp; PMP Certification Eligibility. DetailsJaffe, A. B. 1986. Technological Opportunity and Spillovers of R&amp;D: Evidence from Firms’ Patents, Profits, and Market Value. The American Economic Review. 76, 5 (1986), 984–1001. DetailsJaffe, A. B. 1989. Real effects of academic research. The American economic review. (1989), 957–970. DetailsAudretsch, D. B. and Feldman, M. P. 1996. R&amp;D spillovers and the geography of innovation and production. The American economic review. 86, 3 (1996), 630–640. DetailsDavid, P. A. , Hall, B. H. and Toole, A. A. 2000. Is public R&amp;D a complement or substitute for private R&amp;D? A review of the econometric evidence. Research policy. 29, 4-5 (2000), 497–529. DetailsBaptista, R. and Swann, P. 1998. Do firms in clusters innovate more? Research policy. 27, 5 (1998), 525–540. DetailsSalter, A. J. and Martin, B. R. 2001. The economic benefits of publicly funded basic research: a critical review. Research policy. 30, 3 (2001), 509–532. DetailsPerkmann, M. and Walsh, K. 2007. University–industry relationships and open innovation: Towards a research agenda. International journal of management reviews. 9, 4 (2007), 259–280. DetailsSun, H. , Edziah, B. K. , Kporsu, A. K. , Sarkodie, S. A. and Taghizadeh-Hesary, F. 2021. Energy efficiency: The role of technological innovation and knowledge spillover. Technological Forecasting and Social Change. 167, (2021), 120659. DetailsFini, R. , Perkmann, M. and Michael Ross, J. 2021. Attention to exploration: The effect of academic entrepreneurship on the production of scientific knowledge. Organization Science. (2021). DetailsAkcigit, U. , Hanley, D. and Serrano-Velarde, N. 2021. Back to basics: Basic research spillovers, innovation policy, and growth. The Review of Economic Studies. 88, 1 (2021), 1–43. DetailsHsu, D. H. , Hsu, P. -H. and Zhao, Q. 2021. Rich on paper? Chinese firms’ academic publications, patents, and market value. Research Policy. 50, 9 (2021), 104319. DetailsMartı́nez-Climent Carla, Mastrangelo, L. and Ribeiro-Soriano, D. 2021. The knowledge spillover effect of crowdfunding. Knowledge Management Research &amp; Practice. 19, 1 (2021), 106–116. Details"
    }, {
    "id": 296,
    "url": "https://wanted2.github.io/year-end/",
    "title": "Chia tay 2021!",
    "body": "2021/12/31 - Đây là bài post thứ 61 của blog AiFi trong năm 2021, cũng là bài viết chia tay 2021, trong tâm thế đón chờ 2022 tươi mới hơn. Theo quan điểm làm việc scrum, thì coi như đây là thời điểm kết thúc 1 chu kỳ, cũng là lúc làm một số việc để nhìn lại một năm đã qua (bao gồm cả GKPT hay Good, Keep, Problem, Try). 2021年中61番目の投稿です．2021年と別れて，2022年を迎える時期の投稿です．一年間を1スプリントとすると，いろいろなことができたと思いますので，スクラムの行事として，レビューとレトロ会をここで開催したいと思います．Good, Keep, Problem, Try も含めてやります． Nhìn lại năm 2021 của blog AiFiNhìn từ thống kê người dùng: Hiện tại AiFi blog sử dụng Google Analytics để track và lấy thống kê người dùng. Các sự kiện như view, scroll, referal, … được báo cáo theo phút lên server của Google. Đầu tiên là thống kê về người dùng và nguồn giới thiệu. Trong năm 2021, blog tuy mới ra mắt và còn nhiều khó khăn vất vả nhưng đã thu hút được 552 user mới từ khắp nơi trên thế giới. 552 người dùng này đã ghi lại 7309 sự kiện. Một con số đáng khích lệ với blog mới 1 năm tuổi đời.  Một điểm đáng chú ý là dù facebook. com là nơi tác giả hay chia sẻ bài viết, nhưng user lại phần lớn đến từ 2 nguồn: google và direct. Về yếu tố địa lý thì đa phần người dùng đến từ Việt Nam, Mỹ và Nhật Bản. Các nước khác vẫn chưa đóng tỷ trọng lớn trong cơ cấu người dùng của AiFi.  Tỷ lệ người dùng của AiFi gia tăng tính từ tháng 7. Trong năm 2021, số lượng sự kiện user engagement là 1852, và số page view là 2622 lượt. Ngoài ra, 3 bài viết đạt số lượng truy cập cao nhất (không tính trang chủ) là:  mOCR: A real-time application of OCR with Google MLKit and Android CameraX Adobe Creative Cloud: An All-in-One Platform for Creators Implementing a complex system in AWS Lambda: Should or shouldn’t?Sự “vùng lên” của bài viết Adobe Creative Cloud: An All-in-One Platform for Creators thật thú vị vì bài viết được xuất bản trên blog AiFi vào tháng cuối năm nhưng lại đứng thứ nhì.  Về hệ điều hành, trình duyệt và ngôn ngữ đầu vẫn là Windows, Chrome và English. Theo sau lần lượt là MacOS, Safari và tiếng Nhật.  Nhìn từ kết quả tìm kiếm: Kết quả tìm kiếm về “AiFi Caineng” trên google. com và Bing Search trong ngày 31 tháng 12 năm 2021 như sau: Kết quả tìm kiếm từ khóa “aifi” và thậm chí “aifi caineng” quả là hơi nghèo nàn và dễ bị lẫn vào các từ khóa tìm kiếm khác như “wifi” chẳng hạn. Đây cũng là 1 thiếu sót do blog mới chỉ 1 năm, và tác giả vẫn đang bận bịu công việc chính cuả tác giả. Tuy nhiên, từ năm 2022, ở mức độ nhất định việc nâng rank trong các cỗ máy tìm kiếm từ khóa sẽ được tối ưu hóa nhằm đưa tri thức của AiFi đến với đông đảo bạn đọc và nâng cao chất lượng phục vụ. Good, Keep, Problem, TryViệc chạy sprint kéo dài 1 năm quả là hơi lạ, tuy nhiên là cũng dễ hiểu vì viết blog chỉ là việc phụ làm trong thời gian rảnh rỗi của tác giả.       Good   Keep   Problem   Try         Đã tạo được và thu hút lượng người dùng nhất định.    Duy trì tần suất chia sẻ bài viết.    Thứ hạng trên search engine chưa cao.    Tối ưu hóa SEO                   Tối ưu hóa từ khóa                   Tối ưu thẻ HTML, …               Chưa tạo ra thu nhập từ blog   Xem xét đưa vào và tối ưu hóa quảng cáo.        Các nguồn Google và Facebook đã đem đến lượng người dùng nhất định.    Tiếp tục duy trì quảng bá trên Google và Facebook.    Nguồn Facebook chưa đem lại nhiều người dùng mới.    Tối ưu hóa quảng bá blog trên Facebook.                Một số nguồn cấp khác như Twitter và LinkedIn vẫn chưa đem lại nhiều người dùng.    Lên chiến lược quảng bá trên các nền tảng này.    Tổng kếtKết thúc Sprint 2021, hướng tới Sprint 2022, blog AiFi xin cám ơn đông đảo bạn đọc, đặc biệt là 552 người dùng đã có, vì sự quan tâm và thịnh tình trong năm qua. Trong năm 2022, AiFi sẽ tiếp tục cập nhật và mong muốn lan tỏa tri thức cho anh em, với phương châm, troll trước học sau. "
    }];

var idx = lunr(function () {
    this.ref('id')
    this.field('title')
    this.field('body')

    documents.forEach(function (doc) {
        this.add(doc)
    }, this)
});
function lunr_search(term) {
    document.getElementById('lunrsearchresults').innerHTML = '<ul></ul>';
    if(term) {
        document.getElementById('lunrsearchresults').innerHTML = "<p>Search results for '" + term + "'</p>" + document.getElementById('lunrsearchresults').innerHTML;
        //put results on the screen.
        var results = idx.search(term);
        if(results.length>0){
            //console.log(idx.search(term));
            //if results
            for (var i = 0; i < results.length; i++) {
                // more statements
                var ref = results[i]['ref'];
                var url = documents[ref]['url'];
                var title = documents[ref]['title'];
                var body = documents[ref]['body'].substring(0,160)+'...';
                document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML + "<li class='lunrsearchresult'><a href='" + url + "'><span class='title'>" + title + "</span><br /><span class='body'>"+ body +"</span><br /><span class='url'>"+ url +"</span></a></li>";
            }
        } else {
            document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = "<li class='lunrsearchresult'>No results found...</li>";
        }
    }
    return false;
}

function lunr_search(term) {
    $('#lunrsearchresults').show( 400 );
    $( "body" ).addClass( "modal-open" );
    
    document.getElementById('lunrsearchresults').innerHTML = '<div id="resultsmodal" class="modal fade show d-block"  tabindex="-1" role="dialog" aria-labelledby="resultsmodal"> <div class="modal-dialog shadow-lg" role="document"> <div class="modal-content"> <div class="modal-header" id="modtit"> <button type="button" class="close" id="btnx" data-dismiss="modal" aria-label="Close"> &times; </button> </div> <div class="modal-body"> <ul class="mb-0"> </ul>    </div> <div class="modal-footer"><button id="btnx" type="button" class="btn btn-danger btn-sm" data-dismiss="modal">Close</button></div></div> </div></div>';
    if(term) {
        document.getElementById('modtit').innerHTML = "<h5 class='modal-title'>Search results for '" + term + "'</h5>" + document.getElementById('modtit').innerHTML;
        //put results on the screen.
        var results = idx.search(term);
        if(results.length>0){
            //console.log(idx.search(term));
            //if results
            for (var i = 0; i < results.length; i++) {
                // more statements
                var ref = results[i]['ref'];
                var url = documents[ref]['url'];
                var title = documents[ref]['title'];
                var body = documents[ref]['body'].substring(0,160)+'...';
                document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML + "<li class='lunrsearchresult'><a href='" + url + "'><span class='title'>" + title + "</span><br /><small><span class='body'>"+ body +"</span><br /><span class='url'>"+ url +"</span></small></a></li>";
            }
        } else {
            document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = "<li class='lunrsearchresult'>Sorry, no results found. Close & try a different search!</li>";
        }
    }
    return false;
}
    
$(function() {
    $("#lunrsearchresults").on('click', '#btnx', function () {
        $('#lunrsearchresults').hide( 5 );
        $( "body" ).removeClass( "modal-open" );
    });
});